{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400\n"
     ]
    }
   ],
   "source": [
    "with open('./train.txt') as train_speed_file:\n",
    "    speed_ground=train_speed_file.readlines()\n",
    "print (len(speed_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20400"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./trainSemseg.csv')\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brightness_augmentation(img,brightness_factor):\n",
    "    hsv_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "#     print hsv_image.shape\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2]*brightness_factor\n",
    "    img = np.array(hsv_image, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def batch_shuffle(dframe):\n",
    "    dframe_for_split=dframe[:-1]\n",
    "    \n",
    "    kfold = KFold(len(dframe_for_split), 4, True)\n",
    "    \n",
    "    trainS=[]\n",
    "    validationS=[]\n",
    "        \n",
    "    for train, validation in kfold:\n",
    "    \n",
    "        train_data = []\n",
    "        validation_data = []\n",
    "\n",
    "        train_set=set()\n",
    "\n",
    "        for i in train:\n",
    "            row=dframe.iloc[[i]]\n",
    "            idx1=int(row['frame'])\n",
    "            idx2=idx1+1\n",
    "            train_data.append((idx1,idx2))\n",
    "\n",
    "            train_set.add(idx1)\n",
    "            train_set.add(idx2)\n",
    "\n",
    "        for i in validation:\n",
    "            row=dframe.iloc[[i]]\n",
    "            idx1=int(row['frame'])\n",
    "            idx2=idx1+1\n",
    "            if idx1 not in train_set and idx2 not in train_set:\n",
    "                validation_data.append((idx1,idx2))\n",
    "\n",
    "#         print \"train\",train_data\n",
    "        trainS.append(train_data)\n",
    "        validationS.append(validation_data)\n",
    "#         print \"validation\",validation_data\n",
    "    \n",
    "    return zip(trainS,validationS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(image_path, brightness_factor=None):\n",
    "    img=cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if brightness_factor:\n",
    "        img = brightness_augmentation(img, brightness_factor)\n",
    "    img = cv2.resize(img[100:440, :-90], (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeOpticalFlow(img1,img2):  #Dense Optical Flow\n",
    "    \n",
    "    gray1=cv2.cvtColor(img1,cv2.COLOR_RGB2GRAY)\n",
    "    gray2=cv2.cvtColor(img2,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    hsv = np.zeros_like(img1)\n",
    "    hsv[...,1] = 255\n",
    "    \n",
    "    # 2-channel array with optical flow vectors\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, flow=None, pyr_scale=0.5, \n",
    "                                        levels=3, winsize=15, iterations=3, \n",
    "                                        poly_n=5, poly_sigma=1.2, flags=0)\n",
    "    \n",
    "    # find their magnitude and direction\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    \n",
    "    # color code the result for better visualization. \n",
    "    \n",
    "    # Direction corresponds to Hue value of the image.\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    \n",
    "    # Magnitude corresponds to Value plane. \n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "# img1=preprocessing('../data/IMG/10.jpg')\n",
    "# img2=preprocessing('../data/IMG/11.jpg')\n",
    "# computeOpticalFlow(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def generate_training_data(tuples, data, batch_size=32):\n",
    "    channels=3\n",
    "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    batch_data = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    for j in range(len(tuples) * 2 //batch_size): #*2\n",
    "        for i in range(0,batch_size,2): #,2\n",
    "            idx = np.random.randint(1, len(tuples) - 1)\n",
    "\n",
    "            brightness_factor=0.2 + np.random.uniform()\n",
    "\n",
    "            row1=data.iloc[[tuples[idx][0]]] #idx\n",
    "            row2=data.iloc[[tuples[idx][1]]] #idx\n",
    "            \n",
    "            #print(row1['image_path'])\n",
    "            img1 = preprocessing(row1['image_path'].values[0],brightness_factor)\n",
    "            img2 = preprocessing(row2['image_path'].values[0],brightness_factor)\n",
    "            #print row1['image_path']\n",
    "            #print row2['image_path']\n",
    "            \n",
    "            speed1 = row1['speed'].values[0]\n",
    "            speed2 = row2['speed'].values[0]\n",
    "\n",
    "            resimg = computeOpticalFlow(img1,img2)\n",
    "            speed = np.mean([speed1, speed2])\n",
    "            \n",
    "            image_batch[i] = resimg\n",
    "            label_batch[i] = speed\n",
    "            \n",
    "            # flip the same image and save with same label\n",
    "            \n",
    "            ## flipping the image pair\n",
    "            aug_img1 = np.flip(img1, 1)\n",
    "            aug_img2 = np.flip(img2, 1)\n",
    "            aug_resimg = computeOpticalFlow(aug_img1,aug_img2)\n",
    "\n",
    "            image_batch[i+1] = aug_resimg\n",
    "            label_batch[i+1] = speed # speed remains the same\n",
    "            \n",
    "        img_batch=image_batch\n",
    "        img_batch = np.reshape(img_batch, (batch_size, channels, 66, 220))\n",
    "        \n",
    "        batch_data.append(copy.deepcopy(torch.from_numpy(img_batch)))\n",
    "        batch_labels.append(copy.deepcopy(torch.DoubleTensor(label_batch)))\n",
    "    \n",
    "    return zip(batch_data, batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_validation_data(tuples,data,batch_size=32):\n",
    "    channels=3\n",
    "    val_image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    val_label_batch = np.zeros((batch_size))\n",
    "    batch_data_val = []\n",
    "    batch_labels_val = []\n",
    "    output = []\n",
    "    \n",
    "    for j in range(len(tuples)//batch_size):\n",
    "        for i in range(0,batch_size):\n",
    "            idx = np.random.randint(1, len(tuples) - 1)\n",
    "            \n",
    "            brightness_factor=0.2 + np.random.uniform()\n",
    "            \n",
    "            row1=data.iloc[[tuples[idx][0]]] #idx\n",
    "            row2=data.iloc[[tuples[idx][1]]] #idx\n",
    "\n",
    "            img1 = preprocessing(row1['image_path'].values[0],brightness_factor)\n",
    "            img2 = preprocessing(row2['image_path'].values[0],brightness_factor)\n",
    "            \n",
    "            speed1 = row1['speed'].values[0]\n",
    "            speed2 = row2['speed'].values[0]\n",
    "            \n",
    "            resimg = computeOpticalFlow(img1,img2)\n",
    "            \n",
    "            speed = np.mean([speed1, speed2])\n",
    "            \n",
    "            val_image_batch[i] = resimg\n",
    "            val_label_batch[i] = speed\n",
    "        \n",
    "        val_img_batch=val_image_batch\n",
    "        val_img_batch = np.reshape(val_img_batch, (batch_size, channels, 66, 220))\n",
    "        \n",
    "        batch_data_val.append(copy.deepcopy(torch.from_numpy(val_img_batch)))\n",
    "        batch_labels_val.append(copy.deepcopy(torch.DoubleTensor(val_label_batch)))\n",
    "        \n",
    "    return zip(batch_data_val, batch_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "img_size=(66,220,3)\n",
    "\n",
    "class NvidiaNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NvidiaNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 24, kernel_size=5,stride=2)\n",
    "        self.conv2 = nn.Conv2d(24, 36, kernel_size=5,stride=2)\n",
    "        self.conv3 = nn.Conv2d(36, 48, kernel_size=5,stride=2)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.conv4 = nn.Conv2d(48, 64, kernel_size=3,stride=1)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3,stride=1)\n",
    "        self.fc1 = nn.Linear(1280, 1164)\n",
    "        self.fc2 = nn.Linear(1164, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        self.fc5 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.conv3_drop(F.elu(self.conv3(x)))\n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = F.elu(self.conv5(x))\n",
    "        x = x.view(-1, 1280)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = F.elu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading 956 minibatches(=32) of training samples.\n",
      "Finish loading 10 minibatches(=32) of validation samples.\n",
      "Finish loading 956 minibatches(=32) of training samples.\n",
      "Finish loading 8 minibatches(=32) of validation samples.\n",
      "Finish loading 956 minibatches(=32) of training samples.\n",
      "Finish loading 9 minibatches(=32) of validation samples.\n",
      "Finish loading 956 minibatches(=32) of training samples.\n",
      "Finish loading 10 minibatches(=32) of validation samples.\n",
      "Finished Training .. saved model \n",
      "------------------------------------------------------------\n",
      "time taken to TRAIN for DenseOpticalFlowSemseg  in seconds 1780.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrinand_thakkar/anaconda3/lib/python3.5/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type NvidiaNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "train_start_time = time.time()\n",
    "\n",
    "model_save_path=\"./\"\n",
    "\n",
    "# temp=train_df.head(500)\n",
    "xyS = batch_shuffle(train_df)\n",
    "\n",
    "net = NvidiaNet().cuda()\n",
    "net = net.double()\n",
    "\n",
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "train_loss_k_folds = []\n",
    "val_loss_k_folds = []\n",
    "\n",
    "for j, (x,y) in enumerate(xyS):    \n",
    "    batch_size=32\n",
    "    \n",
    "    train_loss = []\n",
    "    val_losses = []\n",
    "\n",
    "    trainloader=list(generate_training_data(x,train_df,batch_size))\n",
    "    train_num = len(trainloader)\n",
    "    print(\"Finish loading %d minibatches(=%d) of training samples.\" % (train_num, batch_size))\n",
    "    \n",
    "    validationloader=list(generate_validation_data(y,train_df,batch_size))\n",
    "    validation_num = len(validationloader)\n",
    "    print(\"Finish loading %d minibatches(=%d) of validation samples.\" % (validation_num, batch_size))\n",
    "    print \n",
    "\n",
    "    for epoch in range(5):  # loop over the dataset multiple times        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs.cuda())\n",
    "\n",
    "            labels=labels.view(-1,1)\n",
    "            loss = criterion(outputs, labels.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "    \n",
    "    for i, dataval in enumerate(validationloader, 0):\n",
    "        inputs, labels = dataval\n",
    "        \n",
    "        outputs = net(inputs.cuda())\n",
    "        labels=labels.view(-1,1)\n",
    "        \n",
    "        val_loss = criterion(outputs, labels.cuda())\n",
    "\n",
    "        val_losses.append(val_loss.item())\n",
    "        \n",
    "    train_loss_k_folds.append(copy.deepcopy(train_loss))\n",
    "    val_loss_k_folds.append(copy.deepcopy(val_losses))\n",
    "\n",
    "torch.save(net, model_save_path+\"dense_optical_flow_semseg.pkl\")\n",
    "print('Finished Training .. saved model ')\n",
    "\n",
    "train_end_time = time.time() - train_start_time\n",
    "print('------------------------------------------------------------')\n",
    "print(\"time taken to TRAIN for DenseOpticalFlowSemseg  in seconds {:.3f}\".format(train_end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_k_train_loss  12.865934997205928\n",
      "avg_k_val_loss  11.996383491186414\n"
     ]
    }
   ],
   "source": [
    "avg_k_train_loss=0.0\n",
    "avg_k_val_loss=0.0\n",
    "for i in range(4):\n",
    "    avg_k_train_loss+=np.mean(train_loss_k_folds[i])\n",
    "    avg_k_val_loss+=np.mean(val_loss_k_folds[i])\n",
    "#     print (\"train_loss \", i, \" \", np.mean(train_loss_k_folds[i]))\n",
    "#     print (\"val_loss \", i, \" \", np.mean(val_loss_k_folds[i]))\n",
    "print (\"avg_k_train_loss \",avg_k_train_loss/4.)\n",
    "print (\"avg_k_val_loss \",avg_k_val_loss/4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
