{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paths\n",
    "train1_img_path = '../data/train/semseg_imgs/'\n",
    "test_img_path = '../data/test/semseg_imgs/'\n",
    "\n",
    "train1_txt_path = '../data/train/files/train1.txt'\n",
    "train1_csv_path = '../data/train/files/train1_semseg.csv'\n",
    "train1_mp4_path = '../data/train/videos/train1.mp4'\n",
    "model_save_path = '../data/models/sprs15ss-opflw.pkl'\n",
    "\n",
    "test_csv_path = '../data/test/files/driving_semseg.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper-parameters\n",
    "num_trn_epochs = 15\n",
    "num_batch_size = 32\n",
    "learning_rate = 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400\n"
     ]
    }
   ],
   "source": [
    "with open(train1_txt_path) as train_speed_file:\n",
    "    speed_ground=train_speed_file.readlines()\n",
    "print(len(speed_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>frame</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train/semseg_imgs/0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>28.105569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train/semseg_imgs/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>28.105569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train/semseg_imgs/2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>28.106527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train/semseg_imgs/3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>28.130404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train/semseg_imgs/4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>28.109243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image_path  frame      speed\n",
       "0  ../data/train/semseg_imgs/0.jpg      0  28.105569\n",
       "1  ../data/train/semseg_imgs/1.jpg      1  28.105569\n",
       "2  ../data/train/semseg_imgs/2.jpg      2  28.106527\n",
       "3  ../data/train/semseg_imgs/3.jpg      3  28.130404\n",
       "4  ../data/train/semseg_imgs/4.jpg      4  28.109243"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train1_csv_path)\n",
    "train_df.head(5)\n",
    "#len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>frame</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/test/semseg_imgs/0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.022715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/test/semseg_imgs/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2.040872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/test/semseg_imgs/2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2.062394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/test/semseg_imgs/3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2.076283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/test/semseg_imgs/4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.077074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image_path  frame     speed\n",
       "0  ../data/test/semseg_imgs/0.jpg      0  2.022715\n",
       "1  ../data/test/semseg_imgs/1.jpg      1  2.040872\n",
       "2  ../data/test/semseg_imgs/2.jpg      2  2.062394\n",
       "3  ../data/test/semseg_imgs/3.jpg      3  2.076283\n",
       "4  ../data/test/semseg_imgs/4.jpg      4  2.077074"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sub-set of images for code debug purposes  ****** DEBUG ONLY ******** COMMENT\n",
    "#train_df=train_df.head(322) #161\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIDEO TO (IMAGES AND CSV FILE)\n",
    "# only if images have not been extracted then this code block gets executed to generate jpgs from mp4\n",
    "# make sure that 'train1_img_path' has no jpgs if running for first time \n",
    "\n",
    "def write_image_to_disk(idx, cap, writer, item):\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "    \n",
    "    #read in the image\n",
    "    success, image = cap.read()\n",
    "    print success\n",
    "\n",
    "    if success:\n",
    "        image_path = os.path.join(train1_img_path, str(idx) + '.jpg')\n",
    "\n",
    "        #save image to IMG folder\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        #write row to train1.csv\n",
    "        writer.writerow({'image_path': image_path,\n",
    "                  'frame': idx,\n",
    "                  'speed':float(item),\n",
    "                 })\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images extracted..\n"
     ]
    }
   ],
   "source": [
    "last_count = 0\n",
    "if not any(fname.endswith('.jpg') for fname in os.listdir(train1_img_path)):\n",
    "\n",
    "    with open(train1_csv_path, 'w') as csvfile:\n",
    "         fieldnames = ['image_path', 'frame', 'speed']\n",
    "         writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "         writer.writeheader()\n",
    "\n",
    "         #Path to raw image folder\n",
    "         abs_path_to_IMG = os.path.join(train1_img_path)\n",
    "\n",
    "         cap = cv2.VideoCapture(train1_mp4_path)\n",
    "         cap.set(cv2.CAP_PROP_FRAME_COUNT, len(speed_ground))\n",
    "\n",
    "         for idx, item in enumerate(speed_ground):\n",
    "            \n",
    "            if idx % 100 == 0:\n",
    "                print idx , 'images extracted .... '\n",
    "            \n",
    "            write_image_to_disk(idx, cap, writer, item)\n",
    "        \n",
    "         last_count = idx\n",
    "         \n",
    "                \n",
    "            \n",
    "print('images extracted..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take care of regenerating the last image 1 more time to fix the pairs of image count\n",
    "\n",
    "if last_count != 0 and idx%2 != 0 :\n",
    "    idx +=1\n",
    "    print idx\n",
    "    shutil.copyfile(train1_img_path+ str(idx-1) + '.jpg', train1_img_path + str(idx) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness_augmentation(img,brightness_factor):\n",
    "    hsv_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "#     print hsv_image.shape\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2]*brightness_factor\n",
    "    img = np.array(hsv_image, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def batch_shuffle(dframe):\n",
    "    dframe_for_split=dframe[:-1]\n",
    "    train_data = []\n",
    "    validation_data = []\n",
    "    \n",
    "    train,validation=train_test_split(dframe_for_split, shuffle=False, test_size=0.2) # shuffle false will ensure the logic below of idx2 = idx + 1  will work\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"train length \", len(train))\n",
    "    print(\"validation length \", len(validation))\n",
    "    print('===================================')\n",
    "    print(\"training data \", train)\n",
    "    print('===================================')\n",
    "    print(\"validation data \", validation)\n",
    "    \n",
    "    print('----------  TRAINING PAIRS --------------------')\n",
    "    for _,row in train.iterrows():\n",
    "        idx1=row['frame']\n",
    "        idx2=idx1+1\n",
    "        #print('idx1 =%s idx2=%s'%(idx1,idx2))\n",
    "        \n",
    "        train_data.append((idx1,idx2))\n",
    "        \n",
    "    print('----------  VALIDATION PAIRS --------------------')\n",
    "    for _,row in validation.iterrows():\n",
    "        idx1=row['frame']\n",
    "        idx2=idx1+1\n",
    "        #print('idx1 =%s idx2=%s'%(idx1,idx2))\n",
    "        \n",
    "        validation_data.append((idx1,idx2))\n",
    "    return train_data, validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "('train length ', 16319)\n",
      "('validation length ', 4080)\n",
      "===================================\n",
      "('training data ',                                 image_path  frame      speed\n",
      "0          ../data/train/semseg_imgs/0.jpg      0  28.105569\n",
      "1          ../data/train/semseg_imgs/1.jpg      1  28.105569\n",
      "2          ../data/train/semseg_imgs/2.jpg      2  28.106527\n",
      "3          ../data/train/semseg_imgs/3.jpg      3  28.130404\n",
      "4          ../data/train/semseg_imgs/4.jpg      4  28.109243\n",
      "5          ../data/train/semseg_imgs/5.jpg      5  28.088572\n",
      "6          ../data/train/semseg_imgs/6.jpg      6  28.034211\n",
      "7          ../data/train/semseg_imgs/7.jpg      7  28.018491\n",
      "8          ../data/train/semseg_imgs/8.jpg      8  27.986624\n",
      "9          ../data/train/semseg_imgs/9.jpg      9  28.016352\n",
      "10        ../data/train/semseg_imgs/10.jpg     10  27.981986\n",
      "11        ../data/train/semseg_imgs/11.jpg     11  27.978625\n",
      "12        ../data/train/semseg_imgs/12.jpg     12  28.032331\n",
      "13        ../data/train/semseg_imgs/13.jpg     13  27.960219\n",
      "14        ../data/train/semseg_imgs/14.jpg     14  27.937178\n",
      "15        ../data/train/semseg_imgs/15.jpg     15  27.940599\n",
      "16        ../data/train/semseg_imgs/16.jpg     16  27.908579\n",
      "17        ../data/train/semseg_imgs/17.jpg     17  27.898606\n",
      "18        ../data/train/semseg_imgs/18.jpg     18  27.855982\n",
      "19        ../data/train/semseg_imgs/19.jpg     19  27.795581\n",
      "20        ../data/train/semseg_imgs/20.jpg     20  27.850634\n",
      "21        ../data/train/semseg_imgs/21.jpg     21  27.839349\n",
      "22        ../data/train/semseg_imgs/22.jpg     22  27.824348\n",
      "23        ../data/train/semseg_imgs/23.jpg     23  27.759608\n",
      "24        ../data/train/semseg_imgs/24.jpg     24  27.830055\n",
      "25        ../data/train/semseg_imgs/25.jpg     25  27.761886\n",
      "26        ../data/train/semseg_imgs/26.jpg     26  27.694763\n",
      "27        ../data/train/semseg_imgs/27.jpg     27  27.761203\n",
      "28        ../data/train/semseg_imgs/28.jpg     28  27.691932\n",
      "29        ../data/train/semseg_imgs/29.jpg     29  27.666086\n",
      "...                                    ...    ...        ...\n",
      "16289  ../data/train/semseg_imgs/16289.jpg  16289  10.978453\n",
      "16290  ../data/train/semseg_imgs/16290.jpg  16290  10.905011\n",
      "16291  ../data/train/semseg_imgs/16291.jpg  16291  10.910149\n",
      "16292  ../data/train/semseg_imgs/16292.jpg  16292  10.866553\n",
      "16293  ../data/train/semseg_imgs/16293.jpg  16293  10.787989\n",
      "16294  ../data/train/semseg_imgs/16294.jpg  16294  10.793201\n",
      "16295  ../data/train/semseg_imgs/16295.jpg  16295  10.701097\n",
      "16296  ../data/train/semseg_imgs/16296.jpg  16296  10.685049\n",
      "16297  ../data/train/semseg_imgs/16297.jpg  16297  10.662905\n",
      "16298  ../data/train/semseg_imgs/16298.jpg  16298  10.603743\n",
      "16299  ../data/train/semseg_imgs/16299.jpg  16299  10.584126\n",
      "16300  ../data/train/semseg_imgs/16300.jpg  16300  10.573514\n",
      "16301  ../data/train/semseg_imgs/16301.jpg  16301  10.483322\n",
      "16302  ../data/train/semseg_imgs/16302.jpg  16302  10.492700\n",
      "16303  ../data/train/semseg_imgs/16303.jpg  16303  10.427550\n",
      "16304  ../data/train/semseg_imgs/16304.jpg  16304  10.360746\n",
      "16305  ../data/train/semseg_imgs/16305.jpg  16305  10.386008\n",
      "16306  ../data/train/semseg_imgs/16306.jpg  16306  10.289215\n",
      "16307  ../data/train/semseg_imgs/16307.jpg  16307  10.229025\n",
      "16308  ../data/train/semseg_imgs/16308.jpg  16308  10.165880\n",
      "16309  ../data/train/semseg_imgs/16309.jpg  16309  10.178103\n",
      "16310  ../data/train/semseg_imgs/16310.jpg  16310  10.114327\n",
      "16311  ../data/train/semseg_imgs/16311.jpg  16311  10.082663\n",
      "16312  ../data/train/semseg_imgs/16312.jpg  16312  10.087258\n",
      "16313  ../data/train/semseg_imgs/16313.jpg  16313  10.041319\n",
      "16314  ../data/train/semseg_imgs/16314.jpg  16314   9.979821\n",
      "16315  ../data/train/semseg_imgs/16315.jpg  16315   9.985245\n",
      "16316  ../data/train/semseg_imgs/16316.jpg  16316   9.897348\n",
      "16317  ../data/train/semseg_imgs/16317.jpg  16317   9.817884\n",
      "16318  ../data/train/semseg_imgs/16318.jpg  16318   9.839633\n",
      "\n",
      "[16319 rows x 3 columns])\n",
      "===================================\n",
      "('validation data ',                                 image_path  frame     speed\n",
      "16319  ../data/train/semseg_imgs/16319.jpg  16319  9.759789\n",
      "16320  ../data/train/semseg_imgs/16320.jpg  16320  9.713289\n",
      "16321  ../data/train/semseg_imgs/16321.jpg  16321  9.715314\n",
      "16322  ../data/train/semseg_imgs/16322.jpg  16322  9.621404\n",
      "16323  ../data/train/semseg_imgs/16323.jpg  16323  9.604698\n",
      "16324  ../data/train/semseg_imgs/16324.jpg  16324  9.558088\n",
      "16325  ../data/train/semseg_imgs/16325.jpg  16325  9.525750\n",
      "16326  ../data/train/semseg_imgs/16326.jpg  16326  9.513733\n",
      "16327  ../data/train/semseg_imgs/16327.jpg  16327  9.428186\n",
      "16328  ../data/train/semseg_imgs/16328.jpg  16328  9.375038\n",
      "16329  ../data/train/semseg_imgs/16329.jpg  16329  9.275301\n",
      "16330  ../data/train/semseg_imgs/16330.jpg  16330  9.283223\n",
      "16331  ../data/train/semseg_imgs/16331.jpg  16331  9.215256\n",
      "16332  ../data/train/semseg_imgs/16332.jpg  16332  9.099360\n",
      "16333  ../data/train/semseg_imgs/16333.jpg  16333  9.123953\n",
      "16334  ../data/train/semseg_imgs/16334.jpg  16334  9.029621\n",
      "16335  ../data/train/semseg_imgs/16335.jpg  16335  8.935130\n",
      "16336  ../data/train/semseg_imgs/16336.jpg  16336  8.960606\n",
      "16337  ../data/train/semseg_imgs/16337.jpg  16337  8.838398\n",
      "16338  ../data/train/semseg_imgs/16338.jpg  16338  8.725480\n",
      "16339  ../data/train/semseg_imgs/16339.jpg  16339  8.763651\n",
      "16340  ../data/train/semseg_imgs/16340.jpg  16340  8.663380\n",
      "16341  ../data/train/semseg_imgs/16341.jpg  16341  8.585938\n",
      "16342  ../data/train/semseg_imgs/16342.jpg  16342  8.615946\n",
      "16343  ../data/train/semseg_imgs/16343.jpg  16343  8.478958\n",
      "16344  ../data/train/semseg_imgs/16344.jpg  16344  8.406431\n",
      "16345  ../data/train/semseg_imgs/16345.jpg  16345  8.323467\n",
      "16346  ../data/train/semseg_imgs/16346.jpg  16346  8.294794\n",
      "16347  ../data/train/semseg_imgs/16347.jpg  16347  8.249919\n",
      "16348  ../data/train/semseg_imgs/16348.jpg  16348  8.096785\n",
      "...                                    ...    ...       ...\n",
      "20369  ../data/train/semseg_imgs/20369.jpg  20369  3.167466\n",
      "20370  ../data/train/semseg_imgs/20370.jpg  20370  3.104029\n",
      "20371  ../data/train/semseg_imgs/20371.jpg  20371  3.073875\n",
      "20372  ../data/train/semseg_imgs/20372.jpg  20372  3.069786\n",
      "20373  ../data/train/semseg_imgs/20373.jpg  20373  3.015492\n",
      "20374  ../data/train/semseg_imgs/20374.jpg  20374  2.979671\n",
      "20375  ../data/train/semseg_imgs/20375.jpg  20375  2.913276\n",
      "20376  ../data/train/semseg_imgs/20376.jpg  20376  2.941836\n",
      "20377  ../data/train/semseg_imgs/20377.jpg  20377  2.867819\n",
      "20378  ../data/train/semseg_imgs/20378.jpg  20378  2.825360\n",
      "20379  ../data/train/semseg_imgs/20379.jpg  20379  2.837424\n",
      "20380  ../data/train/semseg_imgs/20380.jpg  20380  2.795000\n",
      "20381  ../data/train/semseg_imgs/20381.jpg  20381  2.724942\n",
      "20382  ../data/train/semseg_imgs/20382.jpg  20382  2.746720\n",
      "20383  ../data/train/semseg_imgs/20383.jpg  20383  2.686178\n",
      "20384  ../data/train/semseg_imgs/20384.jpg  20384  2.662286\n",
      "20385  ../data/train/semseg_imgs/20385.jpg  20385  2.667574\n",
      "20386  ../data/train/semseg_imgs/20386.jpg  20386  2.594662\n",
      "20387  ../data/train/semseg_imgs/20387.jpg  20387  2.564792\n",
      "20388  ../data/train/semseg_imgs/20388.jpg  20388  2.559002\n",
      "20389  ../data/train/semseg_imgs/20389.jpg  20389  2.498684\n",
      "20390  ../data/train/semseg_imgs/20390.jpg  20390  2.479404\n",
      "20391  ../data/train/semseg_imgs/20391.jpg  20391  2.435836\n",
      "20392  ../data/train/semseg_imgs/20392.jpg  20392  2.422405\n",
      "20393  ../data/train/semseg_imgs/20393.jpg  20393  2.407294\n",
      "20394  ../data/train/semseg_imgs/20394.jpg  20394  2.364811\n",
      "20395  ../data/train/semseg_imgs/20395.jpg  20395  2.329180\n",
      "20396  ../data/train/semseg_imgs/20396.jpg  20396  2.289795\n",
      "20397  ../data/train/semseg_imgs/20397.jpg  20397  2.292917\n",
      "20398  ../data/train/semseg_imgs/20398.jpg  20398  2.260600\n",
      "\n",
      "[4080 rows x 3 columns])\n",
      "----------  TRAINING PAIRS --------------------\n",
      "----------  VALIDATION PAIRS --------------------\n",
      "train_pairs\n",
      "16319\n",
      "\n",
      "validation_pairs\n",
      "4080\n"
     ]
    }
   ],
   "source": [
    "x,y = batch_shuffle(train_df)\n",
    "print \"train_pairs\"\n",
    "print len(x)\n",
    "print \"\"\n",
    "print \"validation_pairs\"\n",
    "print len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image_path, brightness_factor=None):\n",
    "    img=cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#\n",
    "    if brightness_factor:\n",
    "        img = brightness_augmentation(img, brightness_factor)\n",
    "    img = cv2.resize(img[100:440, :-90], (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def computeOpticalFlow(img1,img2):  #Sparse Optical Flow\n",
    "    \n",
    "    gray1=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    gray2=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    frame=img1 #gray1\n",
    "    p0 = cv2.goodFeaturesToTrack(gray1, mask = None, **feature_params)\n",
    "    #print('p0 >>> ',p0)\n",
    "    \n",
    "    result = np.zeros((frame.shape[0], frame.shape[1],3), np.uint8)\n",
    "    if p0 is not None:\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(gray1, gray2, p0, None, **lk_params)\n",
    "    \n",
    "        mask = np.zeros_like(gray1)\n",
    "        color = np.random.randint(0,255,(100,3))\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "        # draw the tracks\n",
    "        for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "            a,b = new.ravel()\n",
    "            c,d = old.ravel()\n",
    "            mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "\n",
    "        #print frame.shape\n",
    "        #print mask.shape\n",
    "        #img = cv2.add(frame,mask)\n",
    "        result = cv2.bitwise_and(frame,frame,mask = mask)\n",
    "\n",
    "        #print result.shape\n",
    "        #plt.imshow(result)\n",
    "        #plt.show()\n",
    "        # Now update the previous frame and previous points\n",
    "        #old_gray = gray2.copy()\n",
    "        #p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ..., \n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1=preprocessing('../data/train/imgs/0.jpg')\n",
    "img2=preprocessing('../data/train/imgs/1.jpg')\n",
    "\n",
    "computeOpticalFlow(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading 509 minibatches(=32) of training samples.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "def generate_training_data(tuples, data, batch_size=num_batch_size):\n",
    "    channels=3\n",
    "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    batch_data = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    for j in range(len(tuples) /batch_size): #*2\n",
    "        for i in range(0,batch_size): #,2\n",
    "            idx = np.random.randint(1, len(tuples) - 1)\n",
    "\n",
    "            brightness_factor=0.2 + np.random.uniform()\n",
    "\n",
    "            row1=data.iloc[[tuples[idx][0]]] #idx\n",
    "            row2=data.iloc[[tuples[idx][1]]] #idx\n",
    "            \n",
    "            #print(row1['image_path'])\n",
    "            img1 = preprocessing(row1['image_path'].values[0],brightness_factor)\n",
    "            img2 = preprocessing(row2['image_path'].values[0],brightness_factor)\n",
    "            #print row1['image_path']\n",
    "            #print row2['image_path']\n",
    "            \n",
    "            speed1 = row1['speed'].values[0]\n",
    "            speed2 = row2['speed'].values[0]\n",
    "\n",
    "            resimg = computeOpticalFlow(img1,img2)\n",
    "            speed = np.mean([speed1, speed2])\n",
    "            \n",
    "            image_batch[i] = resimg\n",
    "            label_batch[i] = speed\n",
    "            \n",
    "            # flip the same image and save with same label\n",
    "            \n",
    "            ## flipping the image pair\n",
    "            #aug_img1 = np.flip(img1, 0)\n",
    "            #aug_img2 = np.flip(img2, 0)\n",
    "            #aug_resimg = computeOpticalFlow(aug_img1,aug_img2)\n",
    "\n",
    "            #image_batch[i+1] = aug_resimg\n",
    "            #label_batch[i+1] = speed # speed remains the same\n",
    "            \n",
    "        img_batch=image_batch\n",
    "        img_batch = np.reshape(img_batch, (batch_size, channels, 66, 220))\n",
    "        \n",
    "        \n",
    "            \n",
    "        batch_data.append(copy.deepcopy(torch.from_numpy(img_batch)))\n",
    "        batch_labels.append(copy.deepcopy(torch.DoubleTensor(label_batch)))\n",
    "    \n",
    "    return zip(batch_data, batch_labels)\n",
    "\n",
    "batch_size=num_batch_size\n",
    "\n",
    "trainloader=list(generate_training_data(x,train_df))\n",
    "train_num = len(trainloader)\n",
    "print(\"Finish loading %d minibatches(=%d) of training samples.\" % (train_num, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading 127 minibatches(=32) of validation samples.\n"
     ]
    }
   ],
   "source": [
    "def generate_validation_data(tuples,data,batch_size=num_batch_size):\n",
    "    channels=3\n",
    "    val_image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    val_label_batch = np.zeros((batch_size))\n",
    "    batch_data_val = []\n",
    "    batch_labels_val = []\n",
    "    output = list()\n",
    "    \n",
    "    for j in range(len(tuples)/batch_size):\n",
    "        for i in range(0,batch_size):\n",
    "            idx = np.random.randint(1, len(tuples) - 1)\n",
    "            \n",
    "            brightness_factor=0.2 + np.random.uniform()\n",
    "            \n",
    "            row1=data.iloc[[tuples[idx][0]]] #idx\n",
    "            row2=data.iloc[[tuples[idx][1]]] #idx\n",
    "\n",
    "            img1 = preprocessing(row1['image_path'].values[0],brightness_factor)\n",
    "            img2 = preprocessing(row2['image_path'].values[0],brightness_factor)\n",
    "            \n",
    "            #print row1['image_path']\n",
    "            #print row2['image_path']\n",
    "            speed1 = row1['speed'].values[0]\n",
    "            speed2 = row2['speed'].values[0]\n",
    "            \n",
    "            #print speed1\n",
    "            #print speed2\n",
    "\n",
    "            resimg = computeOpticalFlow(img1,img2)\n",
    "            #resimg = resimg.reshape(1, resimg.shape[0], resimg.shape[1], resimg.shape[2])\n",
    "            \n",
    "            \n",
    "            speed = np.mean([speed1, speed2])\n",
    "            #speed = np.array([[speed]])\n",
    "            #print \"speed \", speed\n",
    "            \n",
    "            val_image_batch[i] = resimg\n",
    "            val_label_batch[i] = speed\n",
    "            \n",
    "            #print i\n",
    "            #print \"resimg \", resimg\n",
    "            #print \"val_image_batch[i] >>>>> \",val_image_batch[i]\n",
    "            #print val_label_batch[i]\n",
    "            #print \"*****************************\"\n",
    "            \n",
    "        \n",
    "        val_img_batch=val_image_batch\n",
    "        val_img_batch = np.reshape(val_img_batch, (batch_size, channels, 66, 220))\n",
    "        #print \"val_img_batch\" ,val_img_batch\n",
    "        \n",
    "        batch_data_val.append(copy.deepcopy(torch.from_numpy(val_img_batch)))\n",
    "        batch_labels_val.append(copy.deepcopy(torch.DoubleTensor(val_label_batch)))\n",
    "        \n",
    "    return zip(batch_data_val, batch_labels_val)\n",
    "\n",
    "batch_size=num_batch_size\n",
    "\n",
    "validatnloader=list(generate_validation_data(y,train_df))\n",
    "validation_num = len(validatnloader)\n",
    "print(\"Finish loading %d minibatches(=%d) of validation samples.\" % (validation_num, batch_size))\n",
    "#print \"validatnloader >> \",validatnloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "img_size=(66,220,3)\n",
    "\n",
    "class NvidiaNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NvidiaNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 24, kernel_size=5,stride=2)\n",
    "        self.conv2 = nn.Conv2d(24, 36, kernel_size=5,stride=2)\n",
    "        self.conv3 = nn.Conv2d(36, 48, kernel_size=5,stride=2)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.conv4 = nn.Conv2d(48, 64, kernel_size=3,stride=1)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3,stride=1)\n",
    "        self.fc1 = nn.Linear(1280, 1164)\n",
    "        self.fc2 = nn.Linear(1164, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        self.fc5 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.conv3_drop(F.elu(self.conv3(x)))\n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = F.elu(self.conv5(x))\n",
    "        x = x.view(-1, 1280)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = F.elu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "net = NvidiaNet()\n",
    "net = net.double()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1,    10] loss: 0.109\n",
      "[1,    20] loss: 0.125\n",
      "[1,    30] loss: 0.055\n",
      "[1,    40] loss: 0.061\n",
      "[1,    50] loss: 0.043\n",
      "[1,    60] loss: 0.037\n",
      "[1,    70] loss: 0.031\n",
      "[1,    80] loss: 0.041\n",
      "[1,    90] loss: 0.040\n",
      "[1,   100] loss: 0.031\n",
      "[1,   110] loss: 0.026\n",
      "[1,   120] loss: 0.028\n",
      "[1,   130] loss: 0.033\n",
      "[1,   140] loss: 0.030\n",
      "[1,   150] loss: 0.034\n",
      "[1,   160] loss: 0.030\n",
      "[1,   170] loss: 0.025\n",
      "[1,   180] loss: 0.025\n",
      "[1,   190] loss: 0.031\n",
      "[1,   200] loss: 0.031\n",
      "[1,   210] loss: 0.020\n",
      "[1,   220] loss: 0.041\n",
      "[1,   230] loss: 0.038\n",
      "[1,   240] loss: 0.025\n",
      "[1,   250] loss: 0.034\n",
      "[1,   260] loss: 0.029\n",
      "[1,   270] loss: 0.035\n",
      "[1,   280] loss: 0.029\n",
      "[1,   290] loss: 0.024\n",
      "[1,   300] loss: 0.032\n",
      "[1,   310] loss: 0.032\n",
      "[1,   320] loss: 0.027\n",
      "[1,   330] loss: 0.027\n",
      "[1,   340] loss: 0.032\n",
      "[1,   350] loss: 0.026\n",
      "[1,   360] loss: 0.026\n",
      "[1,   370] loss: 0.027\n",
      "[1,   380] loss: 0.035\n",
      "[1,   390] loss: 0.024\n",
      "[1,   400] loss: 0.032\n",
      "[1,   410] loss: 0.025\n",
      "[1,   420] loss: 0.023\n",
      "[1,   430] loss: 0.022\n",
      "[1,   440] loss: 0.033\n",
      "[1,   450] loss: 0.021\n",
      "[1,   460] loss: 0.022\n",
      "[1,   470] loss: 0.026\n",
      "[1,   480] loss: 0.017\n",
      "[1,   490] loss: 0.020\n",
      "[1,   500] loss: 0.031\n",
      "1\n",
      "[2,    10] loss: 0.022\n",
      "[2,    20] loss: 0.024\n",
      "[2,    30] loss: 0.025\n",
      "[2,    40] loss: 0.027\n",
      "[2,    50] loss: 0.019\n",
      "[2,    60] loss: 0.018\n",
      "[2,    70] loss: 0.023\n",
      "[2,    80] loss: 0.029\n",
      "[2,    90] loss: 0.029\n",
      "[2,   100] loss: 0.024\n",
      "[2,   110] loss: 0.021\n",
      "[2,   120] loss: 0.021\n",
      "[2,   130] loss: 0.022\n",
      "[2,   140] loss: 0.019\n",
      "[2,   150] loss: 0.028\n",
      "[2,   160] loss: 0.022\n",
      "[2,   170] loss: 0.020\n",
      "[2,   180] loss: 0.018\n",
      "[2,   190] loss: 0.022\n",
      "[2,   200] loss: 0.029\n",
      "[2,   210] loss: 0.022\n",
      "[2,   220] loss: 0.031\n",
      "[2,   230] loss: 0.031\n",
      "[2,   240] loss: 0.021\n",
      "[2,   250] loss: 0.022\n",
      "[2,   260] loss: 0.018\n",
      "[2,   270] loss: 0.025\n",
      "[2,   280] loss: 0.023\n",
      "[2,   290] loss: 0.024\n",
      "[2,   300] loss: 0.025\n",
      "[2,   310] loss: 0.021\n",
      "[2,   320] loss: 0.027\n",
      "[2,   330] loss: 0.026\n",
      "[2,   340] loss: 0.021\n",
      "[2,   350] loss: 0.016\n",
      "[2,   360] loss: 0.021\n",
      "[2,   370] loss: 0.023\n",
      "[2,   380] loss: 0.028\n",
      "[2,   390] loss: 0.023\n",
      "[2,   400] loss: 0.024\n",
      "[2,   410] loss: 0.020\n",
      "[2,   420] loss: 0.020\n",
      "[2,   430] loss: 0.016\n",
      "[2,   440] loss: 0.027\n",
      "[2,   450] loss: 0.017\n",
      "[2,   460] loss: 0.020\n",
      "[2,   470] loss: 0.022\n",
      "[2,   480] loss: 0.015\n",
      "[2,   490] loss: 0.016\n",
      "[2,   500] loss: 0.025\n",
      "2\n",
      "[3,    10] loss: 0.014\n",
      "[3,    20] loss: 0.018\n",
      "[3,    30] loss: 0.017\n",
      "[3,    40] loss: 0.016\n",
      "[3,    50] loss: 0.014\n",
      "[3,    60] loss: 0.019\n",
      "[3,    70] loss: 0.020\n",
      "[3,    80] loss: 0.023\n",
      "[3,    90] loss: 0.026\n",
      "[3,   100] loss: 0.015\n",
      "[3,   110] loss: 0.017\n",
      "[3,   120] loss: 0.014\n",
      "[3,   130] loss: 0.017\n",
      "[3,   140] loss: 0.018\n",
      "[3,   150] loss: 0.019\n",
      "[3,   160] loss: 0.018\n",
      "[3,   170] loss: 0.014\n",
      "[3,   180] loss: 0.015\n",
      "[3,   190] loss: 0.021\n",
      "[3,   200] loss: 0.026\n",
      "[3,   210] loss: 0.017\n",
      "[3,   220] loss: 0.021\n",
      "[3,   230] loss: 0.029\n",
      "[3,   240] loss: 0.016\n",
      "[3,   250] loss: 0.022\n",
      "[3,   260] loss: 0.012\n",
      "[3,   270] loss: 0.019\n",
      "[3,   280] loss: 0.021\n",
      "[3,   290] loss: 0.016\n",
      "[3,   300] loss: 0.018\n",
      "[3,   310] loss: 0.019\n",
      "[3,   320] loss: 0.025\n",
      "[3,   330] loss: 0.019\n",
      "[3,   340] loss: 0.018\n",
      "[3,   350] loss: 0.013\n",
      "[3,   360] loss: 0.013\n",
      "[3,   370] loss: 0.020\n",
      "[3,   380] loss: 0.021\n",
      "[3,   390] loss: 0.022\n",
      "[3,   400] loss: 0.023\n",
      "[3,   410] loss: 0.016\n",
      "[3,   420] loss: 0.016\n",
      "[3,   430] loss: 0.014\n",
      "[3,   440] loss: 0.022\n",
      "[3,   450] loss: 0.010\n",
      "[3,   460] loss: 0.013\n",
      "[3,   470] loss: 0.022\n",
      "[3,   480] loss: 0.011\n",
      "[3,   490] loss: 0.013\n",
      "[3,   500] loss: 0.022\n",
      "3\n",
      "[4,    10] loss: 0.008\n",
      "[4,    20] loss: 0.018\n",
      "[4,    30] loss: 0.012\n",
      "[4,    40] loss: 0.015\n",
      "[4,    50] loss: 0.010\n",
      "[4,    60] loss: 0.012\n",
      "[4,    70] loss: 0.018\n",
      "[4,    80] loss: 0.021\n",
      "[4,    90] loss: 0.020\n",
      "[4,   100] loss: 0.011\n",
      "[4,   110] loss: 0.015\n",
      "[4,   120] loss: 0.008\n",
      "[4,   130] loss: 0.013\n",
      "[4,   140] loss: 0.018\n",
      "[4,   150] loss: 0.017\n",
      "[4,   160] loss: 0.013\n",
      "[4,   170] loss: 0.015\n",
      "[4,   180] loss: 0.012\n",
      "[4,   190] loss: 0.019\n",
      "[4,   200] loss: 0.022\n",
      "[4,   210] loss: 0.013\n",
      "[4,   220] loss: 0.018\n",
      "[4,   230] loss: 0.026\n",
      "[4,   240] loss: 0.010\n",
      "[4,   250] loss: 0.020\n",
      "[4,   260] loss: 0.013\n",
      "[4,   270] loss: 0.015\n",
      "[4,   280] loss: 0.019\n",
      "[4,   290] loss: 0.017\n",
      "[4,   300] loss: 0.019\n",
      "[4,   310] loss: 0.016\n",
      "[4,   320] loss: 0.023\n",
      "[4,   330] loss: 0.017\n",
      "[4,   340] loss: 0.015\n",
      "[4,   350] loss: 0.010\n",
      "[4,   360] loss: 0.013\n",
      "[4,   370] loss: 0.017\n",
      "[4,   380] loss: 0.018\n",
      "[4,   390] loss: 0.022\n",
      "[4,   400] loss: 0.016\n",
      "[4,   410] loss: 0.014\n",
      "[4,   420] loss: 0.014\n",
      "[4,   430] loss: 0.013\n",
      "[4,   440] loss: 0.017\n",
      "[4,   450] loss: 0.010\n",
      "[4,   460] loss: 0.011\n",
      "[4,   470] loss: 0.022\n",
      "[4,   480] loss: 0.014\n",
      "[4,   490] loss: 0.011\n",
      "[4,   500] loss: 0.019\n",
      "4\n",
      "[5,    10] loss: 0.011\n",
      "[5,    20] loss: 0.018\n",
      "[5,    30] loss: 0.010\n",
      "[5,    40] loss: 0.012\n",
      "[5,    50] loss: 0.009\n",
      "[5,    60] loss: 0.010\n",
      "[5,    70] loss: 0.015\n",
      "[5,    80] loss: 0.017\n",
      "[5,    90] loss: 0.019\n",
      "[5,   100] loss: 0.011\n",
      "[5,   110] loss: 0.014\n",
      "[5,   120] loss: 0.009\n",
      "[5,   130] loss: 0.012\n",
      "[5,   140] loss: 0.015\n",
      "[5,   150] loss: 0.013\n",
      "[5,   160] loss: 0.011\n",
      "[5,   170] loss: 0.014\n",
      "[5,   180] loss: 0.010\n",
      "[5,   190] loss: 0.013\n",
      "[5,   200] loss: 0.016\n",
      "[5,   210] loss: 0.014\n",
      "[5,   220] loss: 0.014\n",
      "[5,   230] loss: 0.023\n",
      "[5,   240] loss: 0.009\n",
      "[5,   250] loss: 0.019\n",
      "[5,   260] loss: 0.011\n",
      "[5,   270] loss: 0.011\n",
      "[5,   280] loss: 0.017\n",
      "[5,   290] loss: 0.012\n",
      "[5,   300] loss: 0.015\n",
      "[5,   310] loss: 0.014\n",
      "[5,   320] loss: 0.018\n",
      "[5,   330] loss: 0.017\n",
      "[5,   340] loss: 0.013\n",
      "[5,   350] loss: 0.008\n",
      "[5,   360] loss: 0.012\n",
      "[5,   370] loss: 0.020\n",
      "[5,   380] loss: 0.016\n",
      "[5,   390] loss: 0.015\n",
      "[5,   400] loss: 0.016\n",
      "[5,   410] loss: 0.013\n",
      "[5,   420] loss: 0.015\n",
      "[5,   430] loss: 0.008\n",
      "[5,   440] loss: 0.016\n",
      "[5,   450] loss: 0.008\n",
      "[5,   460] loss: 0.010\n",
      "[5,   470] loss: 0.018\n",
      "[5,   480] loss: 0.014\n",
      "[5,   490] loss: 0.011\n",
      "[5,   500] loss: 0.016\n",
      "5\n",
      "[6,    10] loss: 0.006\n",
      "[6,    20] loss: 0.017\n",
      "[6,    30] loss: 0.007\n",
      "[6,    40] loss: 0.012\n",
      "[6,    50] loss: 0.008\n",
      "[6,    60] loss: 0.009\n",
      "[6,    70] loss: 0.011\n",
      "[6,    80] loss: 0.014\n",
      "[6,    90] loss: 0.014\n",
      "[6,   100] loss: 0.013\n",
      "[6,   110] loss: 0.011\n",
      "[6,   120] loss: 0.007\n",
      "[6,   130] loss: 0.011\n",
      "[6,   140] loss: 0.011\n",
      "[6,   150] loss: 0.014\n",
      "[6,   160] loss: 0.009\n",
      "[6,   170] loss: 0.009\n",
      "[6,   180] loss: 0.007\n",
      "[6,   190] loss: 0.009\n",
      "[6,   200] loss: 0.012\n",
      "[6,   210] loss: 0.011\n",
      "[6,   220] loss: 0.011\n",
      "[6,   230] loss: 0.019\n",
      "[6,   240] loss: 0.009\n",
      "[6,   250] loss: 0.019\n",
      "[6,   260] loss: 0.009\n",
      "[6,   270] loss: 0.012\n",
      "[6,   280] loss: 0.013\n",
      "[6,   290] loss: 0.009\n",
      "[6,   300] loss: 0.013\n",
      "[6,   310] loss: 0.014\n",
      "[6,   320] loss: 0.012\n",
      "[6,   330] loss: 0.016\n",
      "[6,   340] loss: 0.010\n",
      "[6,   350] loss: 0.008\n",
      "[6,   360] loss: 0.010\n",
      "[6,   370] loss: 0.015\n",
      "[6,   380] loss: 0.015\n",
      "[6,   390] loss: 0.010\n",
      "[6,   400] loss: 0.009\n",
      "[6,   410] loss: 0.012\n",
      "[6,   420] loss: 0.012\n",
      "[6,   430] loss: 0.009\n",
      "[6,   440] loss: 0.012\n",
      "[6,   450] loss: 0.008\n",
      "[6,   460] loss: 0.009\n",
      "[6,   470] loss: 0.015\n",
      "[6,   480] loss: 0.011\n",
      "[6,   490] loss: 0.009\n",
      "[6,   500] loss: 0.015\n",
      "6\n",
      "[7,    10] loss: 0.006\n",
      "[7,    20] loss: 0.011\n",
      "[7,    30] loss: 0.007\n",
      "[7,    40] loss: 0.012\n",
      "[7,    50] loss: 0.006\n",
      "[7,    60] loss: 0.008\n",
      "[7,    70] loss: 0.010\n",
      "[7,    80] loss: 0.012\n",
      "[7,    90] loss: 0.015\n",
      "[7,   100] loss: 0.012\n",
      "[7,   110] loss: 0.012\n",
      "[7,   120] loss: 0.007\n",
      "[7,   130] loss: 0.010\n",
      "[7,   140] loss: 0.009\n",
      "[7,   150] loss: 0.010\n",
      "[7,   160] loss: 0.008\n",
      "[7,   170] loss: 0.009\n",
      "[7,   180] loss: 0.008\n",
      "[7,   190] loss: 0.008\n",
      "[7,   200] loss: 0.010\n",
      "[7,   210] loss: 0.010\n",
      "[7,   220] loss: 0.011\n",
      "[7,   230] loss: 0.017\n",
      "[7,   240] loss: 0.008\n",
      "[7,   250] loss: 0.014\n",
      "[7,   260] loss: 0.011\n",
      "[7,   270] loss: 0.008\n",
      "[7,   280] loss: 0.011\n",
      "[7,   290] loss: 0.007\n",
      "[7,   300] loss: 0.010\n",
      "[7,   310] loss: 0.010\n",
      "[7,   320] loss: 0.012\n",
      "[7,   330] loss: 0.011\n",
      "[7,   340] loss: 0.007\n",
      "[7,   350] loss: 0.008\n",
      "[7,   360] loss: 0.010\n",
      "[7,   370] loss: 0.013\n",
      "[7,   380] loss: 0.013\n",
      "[7,   390] loss: 0.012\n",
      "[7,   400] loss: 0.012\n",
      "[7,   410] loss: 0.008\n",
      "[7,   420] loss: 0.011\n",
      "[7,   430] loss: 0.006\n",
      "[7,   440] loss: 0.008\n",
      "[7,   450] loss: 0.004\n",
      "[7,   460] loss: 0.009\n",
      "[7,   470] loss: 0.012\n",
      "[7,   480] loss: 0.010\n",
      "[7,   490] loss: 0.007\n",
      "[7,   500] loss: 0.012\n",
      "7\n",
      "[8,    10] loss: 0.005\n",
      "[8,    20] loss: 0.011\n",
      "[8,    30] loss: 0.008\n",
      "[8,    40] loss: 0.006\n",
      "[8,    50] loss: 0.006\n",
      "[8,    60] loss: 0.004\n",
      "[8,    70] loss: 0.009\n",
      "[8,    80] loss: 0.010\n",
      "[8,    90] loss: 0.013\n",
      "[8,   100] loss: 0.014\n",
      "[8,   110] loss: 0.010\n",
      "[8,   120] loss: 0.007\n",
      "[8,   130] loss: 0.012\n",
      "[8,   140] loss: 0.009\n",
      "[8,   150] loss: 0.010\n",
      "[8,   160] loss: 0.006\n",
      "[8,   170] loss: 0.008\n",
      "[8,   180] loss: 0.008\n",
      "[8,   190] loss: 0.007\n",
      "[8,   200] loss: 0.009\n",
      "[8,   210] loss: 0.009\n",
      "[8,   220] loss: 0.013\n",
      "[8,   230] loss: 0.018\n",
      "[8,   240] loss: 0.008\n",
      "[8,   250] loss: 0.013\n",
      "[8,   260] loss: 0.008\n",
      "[8,   270] loss: 0.007\n",
      "[8,   280] loss: 0.011\n",
      "[8,   290] loss: 0.003\n",
      "[8,   300] loss: 0.007\n",
      "[8,   310] loss: 0.009\n",
      "[8,   320] loss: 0.011\n",
      "[8,   330] loss: 0.012\n",
      "[8,   340] loss: 0.005\n",
      "[8,   350] loss: 0.009\n",
      "[8,   360] loss: 0.008\n",
      "[8,   370] loss: 0.009\n",
      "[8,   380] loss: 0.013\n",
      "[8,   390] loss: 0.011\n",
      "[8,   400] loss: 0.005\n",
      "[8,   410] loss: 0.015\n",
      "[8,   420] loss: 0.007\n",
      "[8,   430] loss: 0.006\n",
      "[8,   440] loss: 0.006\n",
      "[8,   450] loss: 0.006\n",
      "[8,   460] loss: 0.006\n",
      "[8,   470] loss: 0.014\n",
      "[8,   480] loss: 0.008\n",
      "[8,   490] loss: 0.006\n",
      "[8,   500] loss: 0.011\n",
      "8\n",
      "[9,    10] loss: 0.005\n",
      "[9,    20] loss: 0.010\n",
      "[9,    30] loss: 0.007\n",
      "[9,    40] loss: 0.007\n",
      "[9,    50] loss: 0.005\n",
      "[9,    60] loss: 0.002\n",
      "[9,    70] loss: 0.006\n",
      "[9,    80] loss: 0.007\n",
      "[9,    90] loss: 0.011\n",
      "[9,   100] loss: 0.008\n",
      "[9,   110] loss: 0.007\n",
      "[9,   120] loss: 0.005\n",
      "[9,   130] loss: 0.012\n",
      "[9,   140] loss: 0.007\n",
      "[9,   150] loss: 0.006\n",
      "[9,   160] loss: 0.004\n",
      "[9,   170] loss: 0.008\n",
      "[9,   180] loss: 0.007\n",
      "[9,   190] loss: 0.004\n",
      "[9,   200] loss: 0.007\n",
      "[9,   210] loss: 0.007\n",
      "[9,   220] loss: 0.008\n",
      "[9,   230] loss: 0.018\n",
      "[9,   240] loss: 0.008\n",
      "[9,   250] loss: 0.011\n",
      "[9,   260] loss: 0.008\n",
      "[9,   270] loss: 0.006\n",
      "[9,   280] loss: 0.008\n",
      "[9,   290] loss: 0.004\n",
      "[9,   300] loss: 0.005\n",
      "[9,   310] loss: 0.008\n",
      "[9,   320] loss: 0.008\n",
      "[9,   330] loss: 0.010\n",
      "[9,   340] loss: 0.004\n",
      "[9,   350] loss: 0.006\n",
      "[9,   360] loss: 0.007\n",
      "[9,   370] loss: 0.007\n",
      "[9,   380] loss: 0.012\n",
      "[9,   390] loss: 0.012\n",
      "[9,   400] loss: 0.005\n",
      "[9,   410] loss: 0.010\n",
      "[9,   420] loss: 0.005\n",
      "[9,   430] loss: 0.004\n",
      "[9,   440] loss: 0.007\n",
      "[9,   450] loss: 0.004\n",
      "[9,   460] loss: 0.006\n",
      "[9,   470] loss: 0.011\n",
      "[9,   480] loss: 0.007\n",
      "[9,   490] loss: 0.005\n",
      "[9,   500] loss: 0.009\n",
      "9\n",
      "[10,    10] loss: 0.005\n",
      "[10,    20] loss: 0.008\n",
      "[10,    30] loss: 0.007\n",
      "[10,    40] loss: 0.005\n",
      "[10,    50] loss: 0.004\n",
      "[10,    60] loss: 0.003\n",
      "[10,    70] loss: 0.002\n",
      "[10,    80] loss: 0.007\n",
      "[10,    90] loss: 0.010\n",
      "[10,   100] loss: 0.006\n",
      "[10,   110] loss: 0.005\n",
      "[10,   120] loss: 0.004\n",
      "[10,   130] loss: 0.009\n",
      "[10,   140] loss: 0.005\n",
      "[10,   150] loss: 0.006\n",
      "[10,   160] loss: 0.005\n",
      "[10,   170] loss: 0.003\n",
      "[10,   180] loss: 0.005\n",
      "[10,   190] loss: 0.005\n",
      "[10,   200] loss: 0.006\n",
      "[10,   210] loss: 0.008\n",
      "[10,   220] loss: 0.007\n",
      "[10,   230] loss: 0.016\n",
      "[10,   240] loss: 0.009\n",
      "[10,   250] loss: 0.007\n",
      "[10,   260] loss: 0.009\n",
      "[10,   270] loss: 0.006\n",
      "[10,   280] loss: 0.009\n",
      "[10,   290] loss: 0.002\n",
      "[10,   300] loss: 0.005\n",
      "[10,   310] loss: 0.009\n",
      "[10,   320] loss: 0.007\n",
      "[10,   330] loss: 0.007\n",
      "[10,   340] loss: 0.004\n",
      "[10,   350] loss: 0.005\n",
      "[10,   360] loss: 0.006\n",
      "[10,   370] loss: 0.007\n",
      "[10,   380] loss: 0.007\n",
      "[10,   390] loss: 0.005\n",
      "[10,   400] loss: 0.002\n",
      "[10,   410] loss: 0.007\n",
      "[10,   420] loss: 0.007\n",
      "[10,   430] loss: 0.004\n",
      "[10,   440] loss: 0.005\n",
      "[10,   450] loss: 0.004\n",
      "[10,   460] loss: 0.005\n",
      "[10,   470] loss: 0.010\n",
      "[10,   480] loss: 0.006\n",
      "[10,   490] loss: 0.004\n",
      "[10,   500] loss: 0.008\n",
      "10\n",
      "[11,    10] loss: 0.003\n",
      "[11,    20] loss: 0.006\n",
      "[11,    30] loss: 0.007\n",
      "[11,    40] loss: 0.003\n",
      "[11,    50] loss: 0.004\n",
      "[11,    60] loss: 0.002\n",
      "[11,    70] loss: 0.003\n",
      "[11,    80] loss: 0.005\n",
      "[11,    90] loss: 0.007\n",
      "[11,   100] loss: 0.006\n",
      "[11,   110] loss: 0.006\n",
      "[11,   120] loss: 0.005\n",
      "[11,   130] loss: 0.007\n",
      "[11,   140] loss: 0.007\n",
      "[11,   150] loss: 0.004\n",
      "[11,   160] loss: 0.003\n",
      "[11,   170] loss: 0.005\n",
      "[11,   180] loss: 0.005\n",
      "[11,   190] loss: 0.003\n",
      "[11,   200] loss: 0.008\n",
      "[11,   210] loss: 0.004\n",
      "[11,   220] loss: 0.007\n",
      "[11,   230] loss: 0.011\n",
      "[11,   240] loss: 0.006\n",
      "[11,   250] loss: 0.005\n",
      "[11,   260] loss: 0.007\n",
      "[11,   270] loss: 0.004\n",
      "[11,   280] loss: 0.008\n",
      "[11,   290] loss: 0.003\n",
      "[11,   300] loss: 0.004\n",
      "[11,   310] loss: 0.005\n",
      "[11,   320] loss: 0.005\n",
      "[11,   330] loss: 0.005\n",
      "[11,   340] loss: 0.003\n",
      "[11,   350] loss: 0.005\n",
      "[11,   360] loss: 0.005\n",
      "[11,   370] loss: 0.005\n",
      "[11,   380] loss: 0.008\n",
      "[11,   390] loss: 0.007\n",
      "[11,   400] loss: 0.003\n",
      "[11,   410] loss: 0.011\n",
      "[11,   420] loss: 0.006\n",
      "[11,   430] loss: 0.002\n",
      "[11,   440] loss: 0.004\n",
      "[11,   450] loss: 0.003\n",
      "[11,   460] loss: 0.004\n",
      "[11,   470] loss: 0.008\n",
      "[11,   480] loss: 0.006\n",
      "[11,   490] loss: 0.004\n",
      "[11,   500] loss: 0.007\n",
      "11\n",
      "[12,    10] loss: 0.003\n",
      "[12,    20] loss: 0.007\n",
      "[12,    30] loss: 0.007\n",
      "[12,    40] loss: 0.003\n",
      "[12,    50] loss: 0.004\n",
      "[12,    60] loss: 0.003\n",
      "[12,    70] loss: 0.004\n",
      "[12,    80] loss: 0.006\n",
      "[12,    90] loss: 0.006\n",
      "[12,   100] loss: 0.008\n",
      "[12,   110] loss: 0.004\n",
      "[12,   120] loss: 0.004\n",
      "[12,   130] loss: 0.008\n",
      "[12,   140] loss: 0.006\n",
      "[12,   150] loss: 0.003\n",
      "[12,   160] loss: 0.002\n",
      "[12,   170] loss: 0.003\n",
      "[12,   180] loss: 0.003\n",
      "[12,   190] loss: 0.003\n",
      "[12,   200] loss: 0.006\n",
      "[12,   210] loss: 0.006\n",
      "[12,   220] loss: 0.007\n",
      "[12,   230] loss: 0.008\n",
      "[12,   240] loss: 0.005\n",
      "[12,   250] loss: 0.007\n",
      "[12,   260] loss: 0.009\n",
      "[12,   270] loss: 0.004\n",
      "[12,   280] loss: 0.005\n",
      "[12,   290] loss: 0.002\n",
      "[12,   300] loss: 0.003\n",
      "[12,   310] loss: 0.005\n",
      "[12,   320] loss: 0.006\n",
      "[12,   330] loss: 0.004\n",
      "[12,   340] loss: 0.003\n",
      "[12,   350] loss: 0.003\n",
      "[12,   360] loss: 0.004\n",
      "[12,   370] loss: 0.003\n",
      "[12,   380] loss: 0.008\n",
      "[12,   390] loss: 0.003\n",
      "[12,   400] loss: 0.002\n",
      "[12,   410] loss: 0.007\n",
      "[12,   420] loss: 0.006\n",
      "[12,   430] loss: 0.003\n",
      "[12,   440] loss: 0.004\n",
      "[12,   450] loss: 0.002\n",
      "[12,   460] loss: 0.003\n",
      "[12,   470] loss: 0.007\n",
      "[12,   480] loss: 0.005\n",
      "[12,   490] loss: 0.003\n",
      "[12,   500] loss: 0.004\n",
      "12\n",
      "[13,    10] loss: 0.002\n",
      "[13,    20] loss: 0.005\n",
      "[13,    30] loss: 0.006\n",
      "[13,    40] loss: 0.003\n",
      "[13,    50] loss: 0.003\n",
      "[13,    60] loss: 0.002\n",
      "[13,    70] loss: 0.002\n",
      "[13,    80] loss: 0.004\n",
      "[13,    90] loss: 0.006\n",
      "[13,   100] loss: 0.004\n",
      "[13,   110] loss: 0.006\n",
      "[13,   120] loss: 0.005\n",
      "[13,   130] loss: 0.004\n",
      "[13,   140] loss: 0.004\n",
      "[13,   150] loss: 0.003\n",
      "[13,   160] loss: 0.003\n",
      "[13,   170] loss: 0.003\n",
      "[13,   180] loss: 0.003\n",
      "[13,   190] loss: 0.003\n",
      "[13,   200] loss: 0.006\n",
      "[13,   210] loss: 0.004\n",
      "[13,   220] loss: 0.003\n",
      "[13,   230] loss: 0.007\n",
      "[13,   240] loss: 0.005\n",
      "[13,   250] loss: 0.005\n",
      "[13,   260] loss: 0.007\n",
      "[13,   270] loss: 0.003\n",
      "[13,   280] loss: 0.007\n",
      "[13,   290] loss: 0.003\n",
      "[13,   300] loss: 0.003\n",
      "[13,   310] loss: 0.005\n",
      "[13,   320] loss: 0.005\n",
      "[13,   330] loss: 0.005\n",
      "[13,   340] loss: 0.003\n",
      "[13,   350] loss: 0.003\n",
      "[13,   360] loss: 0.003\n",
      "[13,   370] loss: 0.002\n",
      "[13,   380] loss: 0.007\n",
      "[13,   390] loss: 0.003\n",
      "[13,   400] loss: 0.002\n",
      "[13,   410] loss: 0.005\n",
      "[13,   420] loss: 0.004\n",
      "[13,   430] loss: 0.003\n",
      "[13,   440] loss: 0.003\n",
      "[13,   450] loss: 0.002\n",
      "[13,   460] loss: 0.002\n",
      "[13,   470] loss: 0.006\n",
      "[13,   480] loss: 0.005\n",
      "[13,   490] loss: 0.002\n",
      "[13,   500] loss: 0.004\n",
      "13\n",
      "[14,    10] loss: 0.002\n",
      "[14,    20] loss: 0.003\n",
      "[14,    30] loss: 0.005\n",
      "[14,    40] loss: 0.004\n",
      "[14,    50] loss: 0.003\n",
      "[14,    60] loss: 0.002\n",
      "[14,    70] loss: 0.003\n",
      "[14,    80] loss: 0.002\n",
      "[14,    90] loss: 0.004\n",
      "[14,   100] loss: 0.003\n",
      "[14,   110] loss: 0.003\n",
      "[14,   120] loss: 0.003\n",
      "[14,   130] loss: 0.007\n",
      "[14,   140] loss: 0.002\n",
      "[14,   150] loss: 0.002\n",
      "[14,   160] loss: 0.002\n",
      "[14,   170] loss: 0.003\n",
      "[14,   180] loss: 0.003\n",
      "[14,   190] loss: 0.002\n",
      "[14,   200] loss: 0.005\n",
      "[14,   210] loss: 0.004\n",
      "[14,   220] loss: 0.002\n",
      "[14,   230] loss: 0.007\n",
      "[14,   240] loss: 0.004\n",
      "[14,   250] loss: 0.003\n",
      "[14,   260] loss: 0.005\n",
      "[14,   270] loss: 0.005\n",
      "[14,   280] loss: 0.004\n",
      "[14,   290] loss: 0.002\n",
      "[14,   300] loss: 0.002\n",
      "[14,   310] loss: 0.003\n",
      "[14,   320] loss: 0.005\n",
      "[14,   330] loss: 0.002\n",
      "[14,   340] loss: 0.002\n",
      "[14,   350] loss: 0.003\n",
      "[14,   360] loss: 0.003\n",
      "[14,   370] loss: 0.002\n",
      "[14,   380] loss: 0.006\n",
      "[14,   390] loss: 0.002\n",
      "[14,   400] loss: 0.002\n",
      "[14,   410] loss: 0.004\n",
      "[14,   420] loss: 0.004\n",
      "[14,   430] loss: 0.002\n",
      "[14,   440] loss: 0.002\n",
      "[14,   450] loss: 0.003\n",
      "[14,   460] loss: 0.002\n",
      "[14,   470] loss: 0.006\n",
      "[14,   480] loss: 0.003\n",
      "[14,   490] loss: 0.003\n",
      "[14,   500] loss: 0.004\n",
      "14\n",
      "[15,    10] loss: 0.003\n",
      "[15,    20] loss: 0.002\n",
      "[15,    30] loss: 0.004\n",
      "[15,    40] loss: 0.003\n",
      "[15,    50] loss: 0.003\n",
      "[15,    60] loss: 0.002\n",
      "[15,    70] loss: 0.001\n",
      "[15,    80] loss: 0.001\n",
      "[15,    90] loss: 0.006\n",
      "[15,   100] loss: 0.001\n",
      "[15,   110] loss: 0.003\n",
      "[15,   120] loss: 0.002\n",
      "[15,   130] loss: 0.003\n",
      "[15,   140] loss: 0.004\n",
      "[15,   150] loss: 0.002\n",
      "[15,   160] loss: 0.002\n",
      "[15,   170] loss: 0.002\n",
      "[15,   180] loss: 0.001\n",
      "[15,   190] loss: 0.002\n",
      "[15,   200] loss: 0.004\n",
      "[15,   210] loss: 0.003\n",
      "[15,   220] loss: 0.003\n",
      "[15,   230] loss: 0.007\n",
      "[15,   240] loss: 0.003\n",
      "[15,   250] loss: 0.006\n",
      "[15,   260] loss: 0.005\n",
      "[15,   270] loss: 0.005\n",
      "[15,   280] loss: 0.004\n",
      "[15,   290] loss: 0.002\n",
      "[15,   300] loss: 0.003\n",
      "[15,   310] loss: 0.003\n",
      "[15,   320] loss: 0.004\n",
      "[15,   330] loss: 0.002\n",
      "[15,   340] loss: 0.001\n",
      "[15,   350] loss: 0.003\n",
      "[15,   360] loss: 0.002\n",
      "[15,   370] loss: 0.003\n",
      "[15,   380] loss: 0.004\n",
      "[15,   390] loss: 0.002\n",
      "[15,   400] loss: 0.001\n",
      "[15,   410] loss: 0.007\n",
      "[15,   420] loss: 0.003\n",
      "[15,   430] loss: 0.001\n",
      "[15,   440] loss: 0.001\n",
      "[15,   450] loss: 0.002\n",
      "[15,   460] loss: 0.001\n",
      "[15,   470] loss: 0.005\n",
      "[15,   480] loss: 0.003\n",
      "[15,   490] loss: 0.002\n",
      "[15,   500] loss: 0.004\n",
      "('Finished Training .. saved model ', '../data/models/sprs15ss-opflw.pkl')\n",
      "------------------------------------------------------------\n",
      "time taken to TRAIN for DenseOpticalFlow  in seconds 8362.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shayan_ray/anaconda2/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type NvidiaNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "### Training starts\n",
    "train_start_time = time.time()\n",
    "net.train()\n",
    "trn_losses = list()\n",
    "for epoch in range(num_trn_epochs):  # loop over the dataset multiple times\n",
    "    print epoch\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        labels=labels.view(-1,1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        trn_losses.append(loss.item())\n",
    "        if (i+1) % 10 == 0:    # print every 2000 steps\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "\n",
    "#save the model\n",
    "torch.save(net, model_save_path)\n",
    "print('Finished Training .. saved model ',model_save_path)\n",
    "\n",
    "train_end_time = time.time() - train_start_time\n",
    "print('------------------------------------------------------------')\n",
    "print(\"time taken to TRAIN for DenseOpticalFlow  in seconds {:.3f}\".format(train_end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NvidiaNet(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv2): Conv2d(24, 36, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv3): Conv2d(36, 48, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv3_drop): Dropout2d(p=0.5)\n",
       "  (conv4): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1280, out_features=1164, bias=True)\n",
       "  (fc2): Linear(in_features=1164, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (fc4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (fc5): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "net_val = torch.load(model_save_path)\n",
    "net_val.eval()\n",
    "#net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y = batch_shuffle(train_df)\n",
    "#print \"train_pairs\"\n",
    "#print train_num * batch_size\n",
    "#print \"\"\n",
    "#print \"validation_pairs\"\n",
    "#print len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss  tensor(102.9460, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(59.1379, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,     2] loss: 0.030\n",
      "val_loss  tensor(81.2092, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(65.9863, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,     4] loss: 0.033\n",
      "val_loss  tensor(48.3217, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(86.8917, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,     6] loss: 0.043\n",
      "val_loss  tensor(81.7322, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(60.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,     8] loss: 0.030\n",
      "val_loss  tensor(57.5310, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(49.9741, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    10] loss: 0.025\n",
      "val_loss  tensor(101.1410, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(77.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    12] loss: 0.039\n",
      "val_loss  tensor(85.8302, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(45.3737, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    14] loss: 0.023\n",
      "val_loss  tensor(64.7208, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(81.9240, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    16] loss: 0.041\n",
      "val_loss  tensor(76.8806, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(37.5911, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    18] loss: 0.019\n",
      "val_loss  tensor(75.7563, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(81.5418, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    20] loss: 0.041\n",
      "val_loss  tensor(58.4028, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(48.3299, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    22] loss: 0.024\n",
      "val_loss  tensor(57.5696, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(59.4961, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    24] loss: 0.030\n",
      "val_loss  tensor(65.8982, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(67.5822, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    26] loss: 0.034\n",
      "val_loss  tensor(75.6617, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(82.8300, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    28] loss: 0.041\n",
      "val_loss  tensor(69.9764, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(79.7027, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    30] loss: 0.040\n",
      "val_loss  tensor(88.3152, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(56.3926, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    32] loss: 0.028\n",
      "val_loss  tensor(91.3204, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(94.2930, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    34] loss: 0.047\n",
      "val_loss  tensor(59.3951, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(58.9904, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    36] loss: 0.029\n",
      "val_loss  tensor(49.2956, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(60.7340, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    38] loss: 0.030\n",
      "val_loss  tensor(76.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(79.6842, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    40] loss: 0.040\n",
      "val_loss  tensor(60.1631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(51.8528, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    42] loss: 0.026\n",
      "val_loss  tensor(83.9017, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(105.1407, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    44] loss: 0.053\n",
      "val_loss  tensor(64.3904, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(80.9554, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    46] loss: 0.040\n",
      "val_loss  tensor(67.9853, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(55.4323, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    48] loss: 0.028\n",
      "val_loss  tensor(59.5336, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(88.6949, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    50] loss: 0.044\n",
      "val_loss  tensor(40.4694, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(56.3759, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    52] loss: 0.028\n",
      "val_loss  tensor(82.7952, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(64.0447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    54] loss: 0.032\n",
      "val_loss  tensor(84.7424, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(43.7453, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    56] loss: 0.022\n",
      "val_loss  tensor(92.1502, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(79.8984, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    58] loss: 0.040\n",
      "val_loss  tensor(75.6972, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(73.5707, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    60] loss: 0.037\n",
      "val_loss  tensor(70.2285, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(85.5972, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    62] loss: 0.043\n",
      "val_loss  tensor(55.6242, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(96.2542, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    64] loss: 0.048\n",
      "val_loss  tensor(55.3626, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(71.4454, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    66] loss: 0.036\n",
      "val_loss  tensor(76.3793, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(74.4755, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    68] loss: 0.037\n",
      "val_loss  tensor(57.8333, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(92.2795, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    70] loss: 0.046\n",
      "val_loss  tensor(73.6366, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(76.4398, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    72] loss: 0.038\n",
      "val_loss  tensor(73.6576, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(91.9482, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    74] loss: 0.046\n",
      "val_loss  tensor(73.9781, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(67.9504, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    76] loss: 0.034\n",
      "val_loss  tensor(57.2853, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(82.4233, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    78] loss: 0.041\n",
      "val_loss  tensor(51.1823, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(79.7271, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    80] loss: 0.040\n",
      "val_loss  tensor(69.0841, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(70.3682, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    82] loss: 0.035\n",
      "val_loss  tensor(60.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(43.5959, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    84] loss: 0.022\n",
      "val_loss  tensor(80.5312, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(83.9624, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    86] loss: 0.042\n",
      "val_loss  tensor(54.4260, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(67.9330, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    88] loss: 0.034\n",
      "val_loss  tensor(55.6715, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(76.0941, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    90] loss: 0.038\n",
      "val_loss  tensor(60.7589, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(88.4263, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    92] loss: 0.044\n",
      "val_loss  tensor(93.4366, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(50.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    94] loss: 0.025\n",
      "val_loss  tensor(55.5332, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(59.6210, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    96] loss: 0.030\n",
      "val_loss  tensor(57.1905, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(82.5797, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    98] loss: 0.041\n",
      "val_loss  tensor(58.9046, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(79.2955, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   100] loss: 0.040\n",
      "val_loss  tensor(68.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(59.3895, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   102] loss: 0.030\n",
      "val_loss  tensor(61.5784, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(65.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   104] loss: 0.033\n",
      "val_loss  tensor(48.9656, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(84.5665, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   106] loss: 0.042\n",
      "val_loss  tensor(85.0716, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(95.9866, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   108] loss: 0.048\n",
      "val_loss  tensor(80.9971, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(87.6343, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   110] loss: 0.044\n",
      "val_loss  tensor(86.1411, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(60.5879, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   112] loss: 0.030\n",
      "val_loss  tensor(88.7738, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(64.3967, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   114] loss: 0.032\n",
      "val_loss  tensor(93.5152, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(71.1727, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   116] loss: 0.036\n",
      "val_loss  tensor(81.8220, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(59.4472, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   118] loss: 0.030\n",
      "val_loss  tensor(69.8743, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(76.4162, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   120] loss: 0.038\n",
      "val_loss  tensor(78.8695, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(72.8845, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   122] loss: 0.036\n",
      "val_loss  tensor(99.5930, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(72.8649, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   124] loss: 0.036\n",
      "val_loss  tensor(71.5548, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(86.7038, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   126] loss: 0.043\n",
      "val_loss  tensor(70.1913, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Validation done\n",
      "------------------------------------------------------------\n",
      "time taken to VALIDATE for DenseOpticalFlow  in seconds 39.726\n"
     ]
    }
   ],
   "source": [
    "### Validation starts\n",
    "val_start_time = time.time()\n",
    "running_val_loss = 0.0\n",
    "val_losses = list()\n",
    "for i, dataval in enumerate(validatnloader, 0):\n",
    "    #print dataval\n",
    "    inputs, labels = dataval\n",
    "    #print i\n",
    "    #print \"inputs >> \", inputs\n",
    "    outputs = net_val(inputs)\n",
    "    labels=labels.view(-1,1)\n",
    "    #print \"outputs \", outputs\n",
    "    #print \"labels \", labels\n",
    "    val_loss = criterion(outputs, labels)\n",
    "    print \"val_loss \", val_loss\n",
    "    running_val_loss += val_loss.item()\n",
    "    val_losses.append(val_loss.item())\n",
    "    if (i+1) % 2 == 0:    # print every 10 steps\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "          (epoch + 1, i + 1, running_val_loss / 2000))\n",
    "    running_val_loss = 0.0\n",
    "          \n",
    "print('Validation done')\n",
    "val_end_time = time.time() - val_start_time\n",
    "print('------------------------------------------------------------')\n",
    "print(\"time taken to VALIDATE for DenseOpticalFlow  in seconds {:.3f}\".format(val_end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print \"training loss \"\n",
    "# print np.mean(trn_losses)\n",
    "# print \"----------------------------------------------------------------------\"\n",
    "\n",
    "# #print \"validation loss\"\n",
    "# #print np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4FFXWBvD3AIGwyWZkFYKIS4IQY0BxARUX8HMEERUUZBwVR9FBcZngzDiIOoPL6CgjKioILiiKCCqijvsyggHZt0TWQAgBlFUiIef741bR3Ukn6XR3pbq73t/z1FNVt6pun6Q7fVK3bt0SVQUREVE4arkdABERxS8mESIiChuTCBERhY1JhIiIwsYkQkREYWMSISKisDGJEBFR2JhEiIgobEwiREQUtjpuBxCJo48+WlNTU90Og4gorixcuHCHqqZEo664TiKpqanIyclxOwwiorgiIhujVRebs4iIKGxMIkREFDYmESIiCltcXxMhothx6NAh5Ofn4+DBg26HQpbk5GS0a9cOSUlJjr0GkwgRRUV+fj4aN26M1NRUiIjb4XieqmLnzp3Iz89Hx44dHXsdNmcRUVQcPHgQLVq0YAKJESKCFi1aOH5myCRCRFHDBBJbauL98G4S+eorYNUqt6MgIopr3k0ivXsDaWluR0FEUbJz505kZGQgIyMDrVq1Qtu2bY+s//bbbyHVcf3112PNmjWV7vPMM8/gtddei0bIOPvss7F48eKo1OUWXlgnooTQokWLI1/IY8eORaNGjXD33XcH7KOqUFXUqhX8/+cpU6ZU+TojR46MPNgE4t0zEQCoW9ftCIjIYXl5eUhLS8O1116L9PR0FBQUYMSIEcjKykJ6ejrGjRt3ZF/7zKCkpARNmzZFdnY2unXrhp49e2L79u0AgL/+9a/497//fWT/7Oxs9OjRAyeeeCK+++47AMD+/ftxxRVXIC0tDYMGDUJWVlbIZxy//vorhg8fjlNOOQWZmZn46quvAADLli1D9+7dkZGRga5du2LdunXYu3cv+vXrh27duqFLly54++23o/mrC4l3z0Tuvx9o397tKIgS17nnli+79FLAPjuo7vYvvgg7lNWrV2PatGnIysoCAIwfPx7NmzdHSUkJzjvvPAwaNAhpZZq3d+/ejd69e2P8+PEYPXo0Jk+ejOzs7HJ1qyoWLFiAOXPmYNy4cZg3bx4mTJiAVq1aYebMmViyZAkyMzNDjvXpp59GvXr1sGzZMqxYsQKXXHIJcnNzMXHiRNx99924+uqrUVxcDFXF7NmzkZqaig8//PBIzDXNu2cit9wCDBzodhREVAM6dep0JIEAwPTp05GZmYnMzEysWrUKK1euLHdM/fr10a9fPwDAaaedhg0bNgSte6D1PeK/zzfffIPBgwcDALp164b09PSQY/3mm28wdOhQAEB6ejratGmDvLw8nHnmmXjooYfw6KOPYvPmzUhOTkbXrl0xb948ZGdn49tvv0WTJk1Cfp1o8e6ZyOmnA+ecA7z6qtuRECWmqs4cIt1eDQ0bNjyynJubi6eeegoLFixA06ZNMXTo0KD3UtT1a+6uXbs2SkpKgtZdr169KveJhmHDhqFnz5744IMP0LdvX0yePBm9evVCTk4O5s6di+zsbPTr1w/33XefYzEE490zkU2bgCj1sCCi+LFnzx40btwYRx11FAoKCvDRRx9F/TXOOusszJgxA4C5lhHsTKci55xzzpHeX6tWrUJBQQGOP/54rFu3DscffzxGjRqFSy+9FEuXLsWWLVvQqFEjDBs2DHfddRcWLVoU9Z+lKt49EyEiT8rMzERaWhpOOukkdOjQAWeddVbUX+P222/Hddddh7S0tCNTRU1NF1988ZGxrc455xxMnjwZN998M0455RQkJSVh2rRpqFu3Ll5//XVMnz4dSUlJaNOmDcaOHYvvvvsO2dnZqFWrFurWrYvnnnsu6j9LVURVa/xFoyUrK0vDfiiVfSdnHP/8RLFk1apVOPnkk90OIyaUlJSgpKQEycnJyM3NxUUXXYTc3FzUqVPz/7cHe19EZKGqZlVwSLXwTISIKMr27duHPn36oKSkBKqK559/3pUEUhMS86cKVYK+qUTkrqZNm2LhwoVuh1EjvPst+sADQOvWbkdBlFBUlYMwxpCauFzh3SQyYgRgdc0josglJydj586dHA4+RtjPE0lOTnb0dbybRLKygPPPB6ZNczsSooTQrl075Ofno6ioyO1QyGI/2dBJ7J0Vxz8/EVE4otk7y7GbDUUkWUQWiMgSEVkhIg9Y5R1FZL6I5InImyJS1yqvZ63nWdtTnYqNiIiiw8k71osBnK+q3QBkAOgrImcAeATAk6p6PICfAdxg7X8DgJ+t8iet/YiIKIY5lkTU2GetJlmTAjgfgD1e8VQAA6zl/tY6rO19hFfniIhimqNjZ4lIbRFZDGA7gE8A/ATgF1W1RynLB9DWWm4LYDMAWNt3A2jhZHyoXdvR6omIEp2jvbNU9TCADBFpCmAWgJMirVNERgAYAQDtI3keyLhxwDHHRBoOEZGn1UgXX1X9RUQ+B9ATQFMRqWOdbbQDsMXabQuAYwHki0gdAE0A7AxS1yQAkwDTOyvsoG68EXC4/zQRUaJzsndWinUGAhGpD+BCAKsAfA5gkLXbcACzreU51jqs7Z+pk/2PTz0VuOsux6onIvICJ6+JtAbwuYgsBfADgE9U9X0AfwYwWkTyYK55vGTt/xKAFlb5aADln0MZTYWFwJQpjr4EEVGic6w5S1WXAjg1SPk6AD2ClB8EcKVT8RARUfR598mGREQUMSYRIiIKm7eTCO9lJCKKiHdH8X34YaBZM7ejICKKa948E/nlF2DGDKB3b7cjISKKa95MInPmAEuWAOnpbkdCRBTXvJlETop49BUiIoJXkwgREUWFN5PIokVuR0BElBC8mUTqeLdTGhFRNHkziTRs6HYEREQJwZtJZP9+tyMgIkoI3kwimzebeb167sZBRBTnvJlEkpLMvLjY3TiIiOKcN5NIhw5uR0BElBC8mUSOPtrtCIiIEoI3k0hOjtsREBElBG8mkcJCtyMgIkoI3kwinTu7HQERUULwZhKxe2cREVFEvJlE1q83cz6UiogoIo4lERE5VkQ+F5GVIrJCREZZ5WNFZIuILLamS/yOGSMieSKyRkQudio2JCeb+c8/O/YSRERe4ORIhCUA7lLVRSLSGMBCEfnE2vakqj7uv7OIpAEYDCAdQBsA/xWRE1T1cNQjO/nkqFdJRORFjp2JqGqBqi6ylvcCWAWgbSWH9AfwhqoWq+p6AHkAejgSHHtnERFFRY1cExGRVACnAphvFd0mIktFZLKI2Bcm2gLY7HdYPipPOuF77TVHqiUi8hrHk4iINAIwE8AdqroHwLMAOgHIAFAA4F/VrG+EiOSISE5RUVF4QW3ZEt5xREQUwNEkIiJJMAnkNVV9BwBUtVBVD6tqKYAX4Guy2gLgWL/D21llAVR1kqpmqWpWSkpKeIHxPhEioqhwsneWAHgJwCpVfcKvvLXfbpcDWG4tzwEwWETqiUhHAJ0BLHAkuNq1HamWiMhrnOyddRaAYQCWichiq+w+AENEJAOAAtgA4GYAUNUVIjIDwEqYnl0jHemZBQA//eRItUREXuNYElHVbwBIkE1zKznmYQAPOxXTEddcAzzyiOMvQ0SU6Lx5x3oPZ3oOExF5jTeTyI4dbkdARJQQvJlEpk1zOwIiooTgzSSyeXPV+xARUZW8mUQ6dXI7AiKihODNJFLLmz82EVG0efPbdPVqtyMgIkoI3kwiQ4a4HQERUULwZhLp1cvtCIiIEoI3k8iuXW5HQESUELyZRF5+2e0IiIgSgjeTyIYNbkdARJQQvJlEOnZ0OwIiooTgzSRCRERR4c0kwvtEiIiiwptJZPBgtyMgIkoI3kwi553ndgRERAnBm0lk9263IyAiSgjeTCKTJ7sdARFRQvBmElm3zu0IiIgSgjeTSGqq2xEQESUEx5KIiBwrIp+LyEoRWSEio6zy5iLyiYjkWvNmVrmIyNMikiciS0Uk06nYiIgoOpw8EykBcJeqpgE4A8BIEUkDkA3gU1XtDOBTax0A+gHobE0jADzrWGRr1zpWNRGRlziWRFS1QFUXWct7AawC0BZAfwBTrd2mAhhgLfcHME2N7wE0FZHWjgR31VWOVEtE5DU1ck1ERFIBnApgPoCWqlpgbdoGoKW13BbAZr/D8q2y6OvTx5FqiYi8xvEkIiKNAMwEcIeq7vHfpqoKQKtZ3wgRyRGRnKKiovCC6tAhvOOIiCiAo0lERJJgEshrqvqOVVxoN1NZ8+1W+RYAx/od3s4qC6Cqk1Q1S1WzUlJSnAueiIiq5GTvLAHwEoBVqvqE36Y5AIZby8MBzPYrv87qpXUGgN1+zV7RtaVcbiIiojDUcbDuswAMA7BMRBZbZfcBGA9ghojcAGAjAPsq91wAlwDIA3AAwPWORda+vWNVExF5iWNJRFW/ASAVbC53Zdu6PjLSqXjKvFiNvAwRUaLz5h3rubluR0BElBC8mUQOHvQt86yEiChs3kwijRr5lplEiIjC5s0k4j8AI5MIEVHYvJlEiIgoKryZRGrXDr5MRETVElIXXxHpBCBfVYtF5FwAXWEGS/zFyeAck5YGvPACkJTkdiRERHEt1DORmQAOi8jxACbBDE/yumNR1YT69YGXXwYOHXI7EiKiuBVqEilV1RIAlwOYoKr3AHBmmPaasnEj8MUXQGmp25EQEcWtUJPIIREZAjPW1ftWWXy3BYl1Mz17ZxERhS3UJHI9gJ4AHlbV9SLSEcArzoVVA5hEiIgiFtKFdVVdCeBPAGA9E72xqj7iZGCOYxIhIopYSGciIvKFiBwlIs0BLALwgog8UdVxMa15czP/+mt34yAiimOhNmc1sZ5KOBCma+/pAC5wLqwa0KuXmQ8c6G4cRERxLNQkUsd6CuFV8F1Yj28ffGDmBw64GwcRURwLNYmMA/ARgJ9U9QcROQ5AfI+nftddbkdARBT3Qr2w/haAt/zW1wG4wqmgiIgoPoR6Yb2diMwSke3WNFNE2jkdHBERxbZQm7OmAJgDoI01vWeVxb+WLd2OgIgoboWaRFJUdYqqlljTywBSHIzLeZmZZj5pkrtxEBHFsVCTyE4RGSoita1pKICdTgbmuP/7PzPftMndOIiI4lioSeQPMN17twEoADAIwO8rO0BEJlvXT5b7lY0VkS0istiaLvHbNkZE8kRkjYhcXO2fpLqGDDHze+5x/KWIiBJVSElEVTeq6mWqmqKqx6jqAFTdO+tlAH2DlD+pqhnWNBcARCQNwGAA6dYxE0XE2adFzZtn5gcPOvoyRESJLJInG46ubKOqfgVgV4h19QfwhqoWq+p6AHkAekQQW9XuvtvR6omIvCCSJCJhHnebiCy1mruaWWVtAWz22yffKnMOnyNCRBSxSJJIOMPfPgugE4AMmGsr/6puBSIyQkRyRCSnqKgojBAsN90U/rFERASgiiQiIntFZE+QaS/M/SLVoqqFqnpYVUsBvABfk9UWmEfu2tpZZcHqmKSqWaqalZISQS/jwYPN/Oyzw6+DiMjjKk0iqtpYVY8KMjVW1ZCGTPFnDeJouxyA3XNrDoDBIlLPeuBVZwALqlt/NYMx8wcfdPRliIgSWbUTQahEZDqAcwEcLSL5AP4O4FwRyYBpCtsA4GYAUNUVIjIDwEoAJQBGquphp2IDABx3nLlbfd064NxzHX0pIqJEJRrHT/bLysrSnJyc8A7euxc46iizHMe/AyKi6hKRhaqaFY26IrmwHt8WLnQ7AiKiuOfdJJKX53YERERxz7tJ5LCzl1yIiLzAu0lk40a3IyAiinveTSJ167odARFR3PNuEunc2cyvucbdOIiI4ph3k0j79mb++uvuxkFEFMe8m0R++83tCIiI4p53kwh7ZxERRcy7SYS9s4iIIubdJMIzESKiiHk3iWza5HYERERxz7tJJDnZ7QiIiOKed5NIly5uR0BEFPe8m0TaOvsIdyIiL/BuEtm92+0IiIjinneTyKFDbkdARBT3vJtECgrcjoCIKO55N4kkJbkdARFR3PNuEune3e0IiIjinneTSJ06vmVV9+IgIopjjiUREZksIttFZLlfWXMR+UREcq15M6tcRORpEckTkaUikulUXEfUr+9bXr3a8ZcjIkpETp6JvAygb5mybACfqmpnAJ9a6wDQD0BnaxoB4FkH4yrvs89q9OWIiBKFY0lEVb8CsKtMcX8AU63lqQAG+JVPU+N7AE1FpLVTsQEAfv3Vt8wzESKisNT0NZGWqmr3rd0GoKW13BbAZr/98q0y5zRo4Gj1RERe4NqFdVVVANW+oi0iI0QkR0RyioqKwg+gaVPf8pVXhl8PEZGH1XQSKbSbqaz5dqt8C4Bj/fZrZ5WVo6qTVDVLVbNSUlLCj8T/eSJpaeHXQ0TkYTWdROYAGG4tDwcw26/8OquX1hkAdvs1eznD/471rl2BhQsdfTkiokTkZBff6QD+B+BEEckXkRsAjAdwoYjkArjAWgeAuQDWAcgD8AKAW52Kyy9A33JBAXDFFY6/JBFRoqlT9S7hUdUhFWzqE2RfBTDSqViCatQocL19++i/xpw5wIUXBt6TQkSUQLx7x7r/mQgADBoU+rFvvQW8+SawZw8wfTqwcWP5fXJygP79gVGjIouTiCiGeTeJ7NsXuP7OOyaxPPZY1cdedRUweDCwciVwzTXAK6+U36dhQzPv2jXyWImIYpR3k0jduoHrX35p5vfeC2zeXH7/YAoLzXzBgvLb7LG5/LsSExElGO8mkbLXRPwNHRpaHQMGVLzNPtNZtiz0mIiI4ox3k0hlTza88kpgzRrTvDVxYvntqsCmTZXXv3evmf/vf+HHSEQU47ybRLZvr3jb7bcDQ6zOZSNHAluC3PdY2ZkMAJx4oplX54I9EVGc8W4SqeqC948/+pYvuSRwmwjQvLlvvXfv8sfb10TK9gIjIkog3k0i1flyX7q08u2//335sh07zPyHH0J/HSKiOOPdJAKY7rmhGj/ePJd9zZry2/bvL1/2yy9mzmHmiSiBeTuJpKeHvu+YMUBJCXDSSeW3TZlSvsy+T+T66838T38yNykSESUQbyeR0tLo1DN2bPkmrVrWr9a+djJhAvDFF9F5PSKiGOHtJHLCCdGra+rUwHX7LMf/msjEieE9u+Sdd0xHAP+k16QJL9oTkescG4AxLnToEP06v/8e+Pln3/onnwRuty+4V8ewYcCBA2ayuxbv2RN+jEREUeLtMxH74nd1dO9e8bbDh4E//CGwS/CAAUB2dvVfh4goDng7iTRrVv1jKuuyO3YssGpVYNm+fcAjj/jWv/gCuO8+4MUXzbqqublxyZKK673jDjOvV8/Mv/qqulGXF84ZERFRGWIe5RGfsrKyNCcnJ/wK8vOBY4+ter9ItGgB7NwZfJuqeSBWmzZAy5bAtm3B9xMBjjrKNJPVqhV4LSSc92/RIuC008x1nOuuq/7xRBTXRGShqmZFoy5vn4nUru38a1SUQAAzlPyuXWb5wgt95Rs3lh+4cc8e08UYAEaPjiwmu+5PP42sHiLyPG8nkeRkd18/PR3o0sW3bEtNDT4syxNPmLk9jH3ZpzEePgzk5VX9unYzXrt21QqXiKgsbyeRWOoi+/e/V73PmDHArFnm7nnAjCRsDyQ5YwbQubOZ1qwBbr4Z2Lo1eD2pqWZ+2mnARRf5msiCPReFiKgS3u7ie9RR5kv4mGPcjgT47Tdg2jTglFMq32/gwMD1li3NdZGrr/aVTZ4MTJpkfrZZs8rXkZ5urq80aABccYWvvKgo/PiJyJO8nURq1QJSUtyOwmf48MD1X381U1Xmzw9ct3txVXRH/rJlwKmnmmfA+7v0UpNc+DRGIgqRK81ZIrJBRJaJyGIRybHKmovIJyKSa83D6H8bpjoxmksbNDC9u6pyxhm+5fR03/WUk0/2lRcX+56LYied2bOB3/0usC6ejRBRNbh5TeQ8Vc3w62aWDeBTVe0M4FNrvWbYvZ4SwfLl5gxj40bgb38zZWPGmE4E7dqZs5M//tG3/9lnBx4f73fCL1kS/CFiROSIWLqw3h+APQDVVACVPMA8ykL5bz9eiJiziaQk3yCQTz3l2172vpI//zlwPSur4ufC//AD8PTTphcYAHz3XWSDWG7bZuKN5iOEMzLY64yoBrmVRBTAxyKyUERGWGUtVbXAWt4GoGWNRZNod2+3bWtuYOzSBbjnnsDrKqHcnJifb+aFhcBddwG5uWa9Rw9g1ChT/zXXAGedFZig/Kma+2AqU1ho5j/9ZOYHDpgOBpFo29YMPUNENcKtJHK2qmYC6AdgpIj08t+o5jb6oN92IjJCRHJEJKcomu33Dz4Yvbpixbp1wOOPB5a1bl31ccceCzz6KNCqlbk35d13A7cXFvoSS16eSVL22csbb5izi3/9y1yf+fLLil/Hvt8lKcnMGzY0iSkSqrHVdZsowbmSRFR1izXfDmAWgB4ACkWkNQBY8+0VHDtJVbNUNSslmj2rBtRc65mrQjnrEgls5io7zD0A2MPN9OljHrzVtSvw8svAuHGmfOZMM58yJXCgyzfeAD780Czbw7z4N59FMowNYO6NmTw5sjqIKGQ1nkREpKGINLaXAVwEYDmAOQDsPq7DAcyu0cDsJhXy3UVvq1XJx+Tqq839NoBJJvZFe/uMZ+pU4IUXfPsPGWJGOT5wwJfQyj5CeN8+4L33TMIJZ2ywaI4HN2gQz2yIKuFG39aWAGaJ+cOsA+B1VZ0nIj8AmCEiNwDYCOCqGo3Kv5vvAw+Edge5VyxbVvEXaUlJ4PAxb75p5v43OdoX4gFTj6ppujruOFNWWhr47Pr8fOCyy8zytm1mjLMnnjDHrltXdbxlkyAA7N4NHDxobs6sDvuMioiCqvEzEVVdp6rdrCldVR+2yneqah9V7ayqF6jqrhoNrG9fcxF52zZf11hbr17BjyFjwgTf8nffld9ud7m1E4jNTgizZgU+u36X31tfWGieT79hA7B+ffm633or8P1JS/PdH/PWW8C995rl9u3NNZ5Q2B0LnFBaah5UFq2zJfsa0N13R6c+oupS1bidTjvtNHVEaanqhAmqgOorr5gy8+dqpltuUX3iicAyTpVP//xn6Pt+8IFv+eKLfcsnnGDei3vuUT3lFLPcrp3ZZgNUO3VSXb3ad5z/+2crKVHdsKH8e79ihdnv66+DHxep2bNNffPnR6e+0tLoxzhjhuqLL0avPoo5AHI0St/DsXSfSOwQAW67zfxpnn56+S6jEyf6mmIoNGPGlC/LyChf9p//VPy8lEOHgIsvBh57zHcx3v+swb5R8qefAs9sANNxonNn3/rf/mYGoty0KXC/vXsD59Fm90Tz/7mi4aootv4+9hhw//3Rq48SGpNIVWbPNj2MyqrsOSGAaRqjyi1eXL6sTp3AC/kff+xbXr8+cP3AAd/yBx/4rqt07Ogrtx86VlBguiXn5Jhk8s9/mvK1a82xIoGdK8p+yY8ebUY8DuU+lpUrTRNfsOa3Q4fMvLi46npsEyf6erSVJWJ+Z8cdZ2IM5VEAVWnZ0kz794c2dht5W7ROadyYHGvO8jd2rK+5oEsX1QMHTPmePaoPPBDYDHPDDcGbUDhVb/Jviqpsspuy7Omhh8rv07174Htx+ukV1/f996rHHmuWR40yx518cuAxbdqYJqSKLF7s2zc1tfz2224z255+OvTPYGXNVaWlqkcfrXrrrWafv/0t9Hqrej1AtXnzyOujmAM2Z9Ug/2aR5cuB+vXNcuPG5pRf1fx3OnUqcO215gKw/Zz144+v8XATQtmmqIqUvQD+0kvl9/nhB6BDB9962RGP/d14I7B5c2DZqlWBx2zdas5On3vOnAX436S6eLHvvQcC74+x2U11H35obqyMdJyv0lLTVdruXRjtxxrsikL/ltJSMzo0JSQmkapcdRWwcCHwzTfA3LnB90lKMs8qP+8884Vlfwn6N7esXWt6CDVo4HzMXhWs+Qgof92jIsuX+5Z37zbJIpj69YFbbjHL9s2VxcVmeP0hQ3z7XXBB+WPtRzLPm2d6slUW26RJvi7GwZ50Cfia3ezmsdtvr7g+25131uy9Lw8+CDRvbsZd69o18utBmzebYX3s7uTkrmid0rgx1UhzViSWLTPNKUBgE4jbzUWcIpuWLvUt161r3tM9e3xlAwaoXnON6v/+p7puneqf/1y+t1eLFmb+8ceq+/ap/vpr+c+Pve8bb6jeeKOvp6C/334rH19VOnSofD+7nsxM1Usvrbq+qpxySmB8hw9HVp/dZHj77ZHH5lFgc1ac6NIFeOYZM4RIKP/5bd0K/P73wbdVNZghRS6UccWAwIvrv/0GfP99YGeApUvNRe6ffjKjIj/yCHDOOYFnHfbnoaDAnKGOGmVuyty/37dP9+5Av37mzOfFF4Fhw4Cvvw6MRbXiON99N/iZTv/+lT947MILzTNq/vEP83NEql+/wPXKYg6F3Qtv9mzze/zxx8jq8zdhAvDtt9GrzwuilY3cmGL+TKQiwf67tS/CPvhg8O0rV7r3nzenqqc//rHy7UOHVr697H/rubnmgn6fPuX3/d3vzGfl/feD1+X/OWvZUnXHDnMmvGyZub/p5pvNtokTg38+MzPN2UrPnqoXXBD55/2ll8zrXXedqkjk9X39dfnffbQAqnXqRK++GIUononE6CP9PMh+ONRDD5l5ixaB3Yi3bjXzRo3M2FIUW557rvLtr75a+fayz3Dxv6elrPfeM3P/McnS04EVK8x1FH/NmgFHH23+wx492tfFGABuvdUML9O2beAxTZua8cw2bvRdw7Ht22fOAK69tvKfx19qqtm/Tx/z+S1r8WLTAeKmm8wgnhkZwe8hspU9q+/RI/RYKvL11+aMr2XL8o+NpspFKxu5McXtmUjjxqbd/JZbzH8+/t0y7fZqe/rvf81ZSHGx6ogR5r9Je9vMmarvvuvsf9icYnN66qnA9bJnMo8+qpqUFPzYsvt+/rm5LmMbOlT1uON823NzzR3+K1eqnniiKavOHfd2rHaX7IMHA7e3bWvKVX0griwhAAAP70lEQVSvWZklS8w+doyzZoUeS26u6pw55cvt123VSvWmm0Kvzw3+71WYEMUzkahU4tYUt0mkYUPV0aPNcklJ4EX3jRtVp08395y0bRv8+MxM89bt2OEri8YXU0VfOpwSa7rrruDl339f8Wfpq68C1+fPN5+/khIzqZqL/CNHqm7dGvh5vf/+wGN/+kl13Djf594uL7tsy8pS7dbNt751q9nnssvM/NlnQ//bC1Z/sJ85Wr77TnXatOjUtX276quvmviWL4+oqmgmEV5Yd0P9+r4Lm7VrB56et28PDB5sLtRW9OhZexgWe/u8eWZu350NmIuy1RXsznxKPLt3By+/9daK76QvOwjp6aebZrI6dUzX3XHjgBkzTEeSZ57x7Vdc7OsGbevd29xjNX++7yI5UPFoADk5wJIlvnV7CB17xIMGDcwwNaq+/SdO9K276cwzTff/6sjJKX9fzX//a+4Buvlms750aXTii4ZoZSM3prg9E9m7V/XQocr3qew/oldeMdt27y6/b0qKWfbvmjlzprnz2v8/rYIC33KtWma+ZIn57zLYxdxwJruZglN8TJ06hXeciJlnZZl5Wppp+lJV3bat4uOuuipw/YwzzNy/uau01HSjPvHE8n8bZaeHHjLbx40z6/YZkq2oyLdvRX9vgGrHjpX/bYbiwAEzwGdFr1cZQLVr18Cyxx4LjPGddyIKD2zOivMkEoqnnlI9//zQ9vX/oH7zjVk+88zAfRYuNOV16qi+/ropu/de09fevjYzYYIpnzLFrC9YEPjBXblS9e23w/ui4eStqVMnc12msn3uuSd4+THHqPbvb3qh+Zfv2KE6dar5gg12nD0skb2+ZYu5pjhpkmkK8r/OAwTer1K2Ln/Fxar33Wf++Str1y7V668vv61Hj4rrC/XvubjYV/bRR6bslltMUl28uHp1lnsJJhGoJngSqQ7/D6rdXvyf/wTuU1Jiblhbvbr88fZYVXZXyZdfNuvr1qk+/3zwP4Q77vCVN2jga6vlxClWJv9HCgSbsrNVn3wy+Db7LGb1atXLLzdlDz+s+uWXphv+0KFm+8SJvmPsC/br15evr6wPPlBdu7byv+eMDF9ZvXqm7KqrTEvEihWqhYUVfiVUhUlEmUQCFBaaL3xbcXHlgwSW9e235qNwxhlm3R5YcsUKsz52rOqbbwYe8/DDZp8mTQLLf/1V9aijzDa7mQwwZ0DB/ljHjlX97DNzbLDtc+aY5gW3v5A4eW+y72+xp7I94v70J9OsZK8PGFDxWZL99/jWW6p/+UvgtmHDfE3UQGAzn6pp3gtWZ3Z26H/jZTCJKJNIVOXnm4/Ck0+a9f37zYOJKmMPt/HYY+W33Xij2da3r+qaNb5uoatXm9Fr7T+Cf/878Dj/PxD7Py97tNuK/tArejhY2RGWOXFyc9q40dc1uaqpaVPTpHfhheY6jn2tyH9KTjbD6oSJSUSZRKJu//7qnb1Uxr5of+qpZj0vzzSR2ew/hLJ27jRdIlXNmRVgzpJUVTt3NuvFxb7j77gjsD7/ae1a33KvXmberJmv7JxzzPzzz939cuHEKdwpAtFMIuziS0aDBtEb2bVVK2DgQDMGEwB06gQMH+7brhq8+3Lz5kDPnma5Y0ez35lnmvXXXzfD7deta7qo7twJPPlk4PG3327Gq9q719zx3bixKb/pJtP99OefgRNOMPXeeKPZtnq1GaXZNmxY+biuuQZ4/PHq/x6InFTRKNM1LVrZyI2JZyKkqqo//xx446Xtxx9Vr7jC1536tNNM9097G+A788nJMd1RVX1jSzVoYOb2RdabbjLrV14Z+B/hq6+aC672elGRGbnXXn/kkcj+47S7bXPiVHYKExK5OQtAXwBrAOQByK5sXyYRcoR9T82YMaoDB/rK9+83TXQ5OaqbNqm+957q+PG+7e3amQ4Htq1bfXdv5+WZJPXxx6buOXPMdaeOHc3d38OHmy6xv/1m9l+0yPdFkZbmW/7XvwKvK+XkmP03bfI1AVY1/f3vZt67t/tfgpwim8KUsEkEQG0APwE4DkBdAEsApFW0P5MIOWL1ajN8R6TPvYiU/UUxYYKZ79rl21arlrkXoSw7wRQWmg4T69erbt5sttk34dn3GOzebRLU5Zeb0Xr9v5w6dzbDirz5pjmbs8uvv953z0LZ6b33VO+8s/IvPf/eTPY0d67q5Mnhf5G2bu17PovXprA/WombRHoC+MhvfQyAMRXtzyRCCW3TJvMArGBKS6vfEeLQIV/zXTArV6pee23F9y8EM2dOYHJTNT2HRo40N7ju2aM6e7b5qrG7cm/cqPqPf5gx4Py7qX70kRm/y25WzM42TYh/+YvZ1rGjudl10CDfl+j+/WbfkhLVE04wZa1amde2f0eHD/u663bubJoagyWzNm3Mz2M/dsH/DPDTT33L2dmq8+aZs8tIk8DYseXLunevuEu8/2R3OglDNJOImPpig4gMAtBXVW+01ocBOF1Vbwu2f1ZWlubk5NRkiEQUjn37gg8DH64JE8yDviobMj4UJSVmXifMp2IUFZl5SorpuFG7NvD+++YxwPZD6fr2NZ1LbB9/bDqQ2B0/duww4+nVrw+8847plFKrluk8snq1eYzA2rVm/Kz8fNO5pGHDiH6fIrJQVbPCrsC/rnhLIiIyAsAIAGjfvv1pGzdudCVWIqJ4Fc0kEmtdfLcA8BuKFu2ssiNUdZKqZqlqVkpKSo0GR0REgWItifwAoLOIdBSRugAGA5jjckxERFSBmHo8rqqWiMhtAD6C6ak1WVVXuBwWERFVIKaSCACo6lwAc92Og4iIqhZrzVlERBRHmESIiChsTCJERBQ2JhEiIgpbTN1sWF0iUgQg3LsNjwawI4rhRBvjiwzjiwzjC18sxwaY+BqqalRutIvrJBIJEcmJ1h2bTmB8kWF8kWF84Yvl2IDox8fmLCIiChuTCBERhc3LSWSS2wFUgfFFhvFFhvGFL5ZjA6Icn2eviRARUeS8fCZCREQR8mQSEZG+IrJGRPJEJLsGX3eyiGwXkeV+Zc1F5BMRybXmzaxyEZGnrRiXikim3zHDrf1zRWR4lGI7VkQ+F5GVIrJCREbFWHzJIrJARJZY8T1glXcUkflWHG9aoz9DROpZ63nW9lS/usZY5WtE5OJoxOdXd20R+VFE3o+1+ERkg4gsE5HFIpJjlcXE+2vV21RE3haR1SKySkR6xkp8InKi9Xuzpz0ickcMxXen9XexXESmW38vNfPZi9YjEuNlQjWf4x7l1+4FIBPAcr+yRwFkW8vZAB6xli8B8CEAAXAGgPlWeXMA66x5M2u5WRRiaw0g01puDGAtgLQYik8ANLKWkwDMt153BoDBVvlzAG6xlm8F8Jy1PBjAm9ZymvWe1wPQ0fos1I7iezwawOsA3rfWYyY+ABsAHF2mLCbeX6vuqQButJbrAmgaS/H5xVkbwDYAHWIhPgBtAawHUN/vM/f7mvrsRe0XGy8TqvkcdwdePxWBSWQNgNbWcmsAa6zl5wEMKbsfgCEAnvcrD9gvinHOBnBhLMYHoAGARQBOh7mpq07Z9xbmcQI9reU61n5S9v323y8KcbUD8CmA8wG8b71eLMW3AeWTSEy8vwCawHwRSizGVyamiwB8GyvxwSSRzTCJqY712bu4pj57XmzOsn/htnyrzC0tVbXAWt4GoKW1XFGcjsdvnd6eCvPffszEZzUVLQawHcAnMP8p/aKqJUFe60gc1vbdAFo4GR+AfwO4F0Cptd4ixuJTAB+LyEIxj5kGYuf97QigCMAUqznwRRFpGEPx+RsMYLq17Hp8qroFwOMANgEogPksLUQNffa8mERilpr072p3ORFpBGAmgDtUdY//NrfjU9XDqpoB8x9/DwAnuRVLWSJyKYDtqrrQ7VgqcbaqZgLoB2CkiPTy3+jy+1sHpqn3WVU9FcB+mOahI9z+/AGAdV3hMgBvld3mVnzWdZj+MIm4DYCGAPrW1Ot7MYlU+Rz3GlYoIq0BwJpvt8oritOx+EUkCSaBvKaq78RafDZV/QXA5zCn6E1FxH64mv9rHYnD2t4EwE4H4zsLwGUisgHAGzBNWk/FUHz2f6xQ1e0AZsEk4lh5f/MB5KvqfGv9bZikEivx2foBWKSqhdZ6LMR3AYD1qlqkqocAvAPzeayRz54Xk0isPcd9DgC7h8ZwmGsRdvl1Vi+PMwDstk6bPwJwkYg0s/4Ducgqi4iICICXAKxS1SdiML4UEWlqLdeHuV6zCiaZDKogPjvuQQA+s/5TnANgsNVDpSOAzgAWRBqfqo5R1XaqmgrzmfpMVa+NlfhEpKGINLaXYd6X5YiR91dVtwHYLCInWkV9AKyMlfj8DIGvKcuOw+34NgE4Q0QaWH/H9u+uZj570bzgFC8TTM+JtTBt6n+pwdedDtNmeQjmP68bYNoiPwWQC+C/AJpb+wqAZ6wYlwHI8qvnDwDyrOn6KMV2Nsyp+FIAi63pkhiKryuAH634lgO43yo/zvqg58E0MdSzypOt9Txr+3F+df3FinsNgH4OvM/nwtc7Kybis+JYYk0r7M99rLy/Vr0ZAHKs9/hdmN5LsRRfQ5j/2Jv4lcVEfAAeALDa+tt4BaaHVY189njHOhERhc2LzVlERBQlTCJERBQ2JhEiIgobkwgREYWNSYSIiMLGJEKeJiL7rHmqiFwT5brvK7P+XTTrJ4oFTCJERiqAaiURv7uBKxKQRFT1zGrGRBTzmESIjPEAzhHzrIg7rcEeHxORH6znQdwMACJyroh8LSJzYO4Khoi8aw1quMIe2FBExgOob9X3mlVmn/WIVfdyMc/3uNqv7i/E90yN16w7kCEi48U862WpiDxe478dogpU9Z8UkVdkA7hbVS8FACsZ7FbV7iJSD8C3IvKxtW8mgC6qut5a/4Oq7rKGY/lBRGaqaraI3KZmwMiyBsLcnd0NwNHWMV9Z204FkA5gK4BvAZwlIqsAXA7gJFVVe/gXoljAMxGi4C6CGftoMcyQ+C1gxhICgAV+CQQA/iQiSwB8DzOAXWdU7mwA09WMSlwI4EsA3f3qzlfVUpihZ1Jhhuo+COAlERkI4EDEPx1RlDCJEAUnAG5X1Qxr6qiq9pnI/iM7iZwLM4pqT1XtBjO+V3IEr1vst3wY5qFCJTAj7r4N4FIA8yKonyiqmESIjL0wjwW2fQTgFmt4fIjICdbot2U1AfCzqh4QkZNgHoVqO2QfX8bXAK62rrukwDw2ucLRUsU846WJqs4FcCdMMxhRTOA1ESJjKYDDVrPUyzDPAkkFsMi6uF0EYECQ4+YB+KN13WINTJOWbRKApSKySM2w8LZZMM9CWQIzcvK9qrrNSkLBNAYwW0SSYc6QRof3IxJFH0fxJSKisLE5i4iIwsYkQkREYWMSISKisDGJEBFR2JhEiIgobEwiREQUNiYRIiIKG5MIERGF7f8BebKDGDhBxQ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb777793c10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb720ff3d10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss\n",
      "71.392546292\n"
     ]
    }
   ],
   "source": [
    "# Get training and validation loss histories\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(trn_losses) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, trn_losses, 'r--')\n",
    "\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n",
    "\n",
    "epoch_count = range(1, len(val_losses) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, val_losses, 'b-')\n",
    "\n",
    "plt.legend(['Validation Loss'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n",
    "\n",
    "\n",
    "print \"validation loss\"\n",
    "print np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "# run validation accuracy\n",
    "# train validation graph\n",
    "# sparse optical flow\n",
    "# images code made to run without commenting \n",
    "# last image regenerated to account for the pairs and last batch success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss\n",
      "23.0270615771\n"
     ]
    }
   ],
   "source": [
    "print \"training loss\"\n",
    "print np.mean(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading 269 minibatches(=32) of test samples.\n"
     ]
    }
   ],
   "source": [
    "def generate_test_data(tuples,data,batch_size=num_batch_size):\n",
    "    channels=3\n",
    "    test_image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    test_label_batch = np.zeros((batch_size))\n",
    "    batch_data_test = []\n",
    "    batch_labels_test = []\n",
    "    output = list()\n",
    "    \n",
    "    for j in range(len(tuples)/batch_size):\n",
    "        for i in range(0,batch_size):\n",
    "            idx = np.random.randint(1, len(tuples) - 1)\n",
    "\n",
    "            brightness_factor=0.2 + np.random.uniform()\n",
    "            #print(tuples.iloc[idx])\n",
    "            row1=data.iloc[idx] #idx\n",
    "            row2=data.iloc[idx + 1] #idx\n",
    "\n",
    "            img1 = preprocessing(str(row1['image_path']),brightness_factor)\n",
    "            img2 = preprocessing(str(row2['image_path']),brightness_factor)\n",
    "\n",
    "            #print row1['image_path']\n",
    "            #print row2['image_path']\n",
    "            speed1 = row1['speed']\n",
    "            speed2 = row2['speed']\n",
    "\n",
    "            #print speed1\n",
    "            #print speed2\n",
    "\n",
    "            resimg = computeOpticalFlow(img1,img2)\n",
    "            #resimg = resimg.reshape(1, resimg.shape[0], resimg.shape[1], resimg.shape[2])\n",
    "\n",
    "\n",
    "            speed = np.mean([speed1, speed2])\n",
    "            #speed = np.array([[speed]])\n",
    "            #print \"speed \", speed\n",
    "\n",
    "            test_image_batch[i] = resimg\n",
    "            test_label_batch[i] = speed\n",
    "\n",
    "            #print i\n",
    "            #print \"resimg \", resimg\n",
    "            #print \"val_image_batch[i] >>>>> \",val_image_batch[i]\n",
    "            #print val_label_batch[i]\n",
    "            #print \"*****************************\"\n",
    "            \n",
    "        \n",
    "        test_img_batch=test_image_batch\n",
    "        test_img_batch = np.reshape(test_img_batch, (batch_size, channels, 66, 220))\n",
    "        #print \"val_img_batch\" ,val_img_batch\n",
    "        \n",
    "        batch_data_test.append(copy.deepcopy(torch.from_numpy(test_img_batch)))\n",
    "        batch_labels_test.append(copy.deepcopy(torch.DoubleTensor(test_label_batch)))\n",
    "        \n",
    "    return zip(batch_data_test, batch_labels_test)\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "testloader=list(generate_test_data(test_df,test_df))\n",
    "test_num = len(testloader)\n",
    "print(\"Finish loading %d minibatches(=%d) of test samples.\" % (test_num, batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,     2] loss: 0.069\n",
      "[15,     4] loss: 0.071\n",
      "[15,     6] loss: 0.065\n",
      "[15,     8] loss: 0.105\n",
      "[15,    10] loss: 0.068\n",
      "[15,    12] loss: 0.106\n",
      "[15,    14] loss: 0.096\n",
      "[15,    16] loss: 0.081\n",
      "[15,    18] loss: 0.073\n",
      "[15,    20] loss: 0.074\n",
      "[15,    22] loss: 0.056\n",
      "[15,    24] loss: 0.049\n",
      "[15,    26] loss: 0.096\n",
      "[15,    28] loss: 0.064\n",
      "[15,    30] loss: 0.073\n",
      "[15,    32] loss: 0.070\n",
      "[15,    34] loss: 0.052\n",
      "[15,    36] loss: 0.066\n",
      "[15,    38] loss: 0.089\n",
      "[15,    40] loss: 0.074\n",
      "[15,    42] loss: 0.081\n",
      "[15,    44] loss: 0.062\n",
      "[15,    46] loss: 0.063\n",
      "[15,    48] loss: 0.088\n",
      "[15,    50] loss: 0.084\n",
      "[15,    52] loss: 0.060\n",
      "[15,    54] loss: 0.100\n",
      "[15,    56] loss: 0.055\n",
      "[15,    58] loss: 0.079\n",
      "[15,    60] loss: 0.073\n",
      "[15,    62] loss: 0.074\n",
      "[15,    64] loss: 0.079\n",
      "[15,    66] loss: 0.067\n",
      "[15,    68] loss: 0.072\n",
      "[15,    70] loss: 0.110\n",
      "[15,    72] loss: 0.075\n",
      "[15,    74] loss: 0.070\n",
      "[15,    76] loss: 0.067\n",
      "[15,    78] loss: 0.097\n",
      "[15,    80] loss: 0.049\n",
      "[15,    82] loss: 0.096\n",
      "[15,    84] loss: 0.093\n",
      "[15,    86] loss: 0.064\n",
      "[15,    88] loss: 0.081\n",
      "[15,    90] loss: 0.085\n",
      "[15,    92] loss: 0.074\n",
      "[15,    94] loss: 0.085\n",
      "[15,    96] loss: 0.070\n",
      "[15,    98] loss: 0.092\n",
      "[15,   100] loss: 0.074\n",
      "[15,   102] loss: 0.079\n",
      "[15,   104] loss: 0.076\n",
      "[15,   106] loss: 0.096\n",
      "[15,   108] loss: 0.079\n",
      "[15,   110] loss: 0.091\n",
      "[15,   112] loss: 0.088\n",
      "[15,   114] loss: 0.100\n",
      "[15,   116] loss: 0.072\n",
      "[15,   118] loss: 0.068\n",
      "[15,   120] loss: 0.082\n",
      "[15,   122] loss: 0.087\n",
      "[15,   124] loss: 0.080\n",
      "[15,   126] loss: 0.086\n",
      "[15,   128] loss: 0.061\n",
      "[15,   130] loss: 0.038\n",
      "[15,   132] loss: 0.080\n",
      "[15,   134] loss: 0.087\n",
      "[15,   136] loss: 0.066\n",
      "[15,   138] loss: 0.061\n",
      "[15,   140] loss: 0.061\n",
      "[15,   142] loss: 0.080\n",
      "[15,   144] loss: 0.073\n",
      "[15,   146] loss: 0.089\n",
      "[15,   148] loss: 0.097\n",
      "[15,   150] loss: 0.114\n",
      "[15,   152] loss: 0.096\n",
      "[15,   154] loss: 0.061\n",
      "[15,   156] loss: 0.118\n",
      "[15,   158] loss: 0.053\n",
      "[15,   160] loss: 0.098\n",
      "[15,   162] loss: 0.063\n",
      "[15,   164] loss: 0.062\n",
      "[15,   166] loss: 0.103\n",
      "[15,   168] loss: 0.067\n",
      "[15,   170] loss: 0.065\n",
      "[15,   172] loss: 0.071\n",
      "[15,   174] loss: 0.081\n",
      "[15,   176] loss: 0.083\n",
      "[15,   178] loss: 0.099\n",
      "[15,   180] loss: 0.076\n",
      "[15,   182] loss: 0.098\n",
      "[15,   184] loss: 0.052\n",
      "[15,   186] loss: 0.096\n",
      "[15,   188] loss: 0.078\n",
      "[15,   190] loss: 0.064\n",
      "[15,   192] loss: 0.077\n",
      "[15,   194] loss: 0.056\n",
      "[15,   196] loss: 0.058\n",
      "[15,   198] loss: 0.059\n",
      "[15,   200] loss: 0.065\n",
      "[15,   202] loss: 0.073\n",
      "[15,   204] loss: 0.079\n",
      "[15,   206] loss: 0.074\n",
      "[15,   208] loss: 0.068\n",
      "[15,   210] loss: 0.083\n",
      "[15,   212] loss: 0.094\n",
      "[15,   214] loss: 0.056\n",
      "[15,   216] loss: 0.074\n",
      "[15,   218] loss: 0.064\n",
      "[15,   220] loss: 0.060\n",
      "[15,   222] loss: 0.096\n",
      "[15,   224] loss: 0.083\n",
      "[15,   226] loss: 0.060\n",
      "[15,   228] loss: 0.055\n",
      "[15,   230] loss: 0.059\n",
      "[15,   232] loss: 0.081\n",
      "[15,   234] loss: 0.084\n",
      "[15,   236] loss: 0.070\n",
      "[15,   238] loss: 0.069\n",
      "[15,   240] loss: 0.070\n",
      "[15,   242] loss: 0.060\n",
      "[15,   244] loss: 0.084\n",
      "[15,   246] loss: 0.072\n",
      "[15,   248] loss: 0.064\n",
      "[15,   250] loss: 0.054\n",
      "[15,   252] loss: 0.080\n",
      "[15,   254] loss: 0.071\n",
      "[15,   256] loss: 0.049\n",
      "[15,   258] loss: 0.060\n",
      "[15,   260] loss: 0.089\n",
      "[15,   262] loss: 0.057\n",
      "[15,   264] loss: 0.078\n",
      "[15,   266] loss: 0.088\n",
      "[15,   268] loss: 0.082\n",
      "Testing done\n",
      "------------------------------------------------------------\n",
      "time taken to TEST for DenseOpticalFlow  in seconds 77.360\n"
     ]
    }
   ],
   "source": [
    "### Testing starts\n",
    "test_start_time = time.time()\n",
    "running_test_loss = 0.0\n",
    "test_losses = list()\n",
    "for i, datatest in enumerate(testloader, 0):\n",
    "    #print dataval\n",
    "    inputs, labels = datatest\n",
    "    #print i\n",
    "    #print \"inputs >> \", inputs\n",
    "    outputs = net_val(inputs)\n",
    "    labels=labels.view(-1,1)\n",
    "    #print \"outputs \", outputs\n",
    "    #print \"labels \", labels\n",
    "    test_loss = criterion(outputs, labels)\n",
    "    #print \"test_loss \", test_loss\n",
    "    running_test_loss += test_loss.item()\n",
    "    test_losses.append(test_loss.item())\n",
    "    if (i+1) % 2 == 0:    # print every 10 steps\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "          (epoch + 1, i + 1, running_test_loss / 2000))\n",
    "    running_test_loss = 0.0\n",
    "          \n",
    "print('Testing done')\n",
    "test_end_time = time.time() - test_start_time\n",
    "print('------------------------------------------------------------')\n",
    "print(\"time taken to TEST for DenseOpticalFlow  in seconds {:.3f}\".format(test_end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.769384304\n"
     ]
    }
   ],
   "source": [
    "print np.mean(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
