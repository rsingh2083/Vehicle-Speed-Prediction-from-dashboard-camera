{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paths\n",
    "train1_txt_path = '../data/train/files/train1.txt'\n",
    "train1_csv_path = '../data/train/files/train1.csv'\n",
    "train1_img_path = '../data/train/imgs/'\n",
    "train1_mp4_path = '../data/train/videos/train1.mp4'\n",
    "model_save_path = '../data/models/sprs15-opflw.pkl'\n",
    "\n",
    "test_img_path = '../data/test/imgs/'\n",
    "test_csv_path = '../data/test/files/driving.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper-parameters\n",
    "num_trn_epochs = 15\n",
    "num_batch_size = 32\n",
    "learning_rate = 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400\n"
     ]
    }
   ],
   "source": [
    "with open(train1_txt_path) as train_speed_file:\n",
    "    speed_ground=train_speed_file.readlines()\n",
    "print(len(speed_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>frame</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/train/imgs/0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>28.105569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/train/imgs/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>28.105569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/train/imgs/2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>28.106527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/train/imgs/3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>28.130404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/train/imgs/4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>28.109243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_path  frame      speed\n",
       "0  ../data/train/imgs/0.jpg      0  28.105569\n",
       "1  ../data/train/imgs/1.jpg      1  28.105569\n",
       "2  ../data/train/imgs/2.jpg      2  28.106527\n",
       "3  ../data/train/imgs/3.jpg      3  28.130404\n",
       "4  ../data/train/imgs/4.jpg      4  28.109243"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train1_csv_path)\n",
    "train_df.head(5)\n",
    "#len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>frame</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/test/imgs/0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.022715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/test/imgs/1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2.040872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/test/imgs/2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2.062394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/test/imgs/3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2.076283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/test/imgs/4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.077074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image_path  frame     speed\n",
       "0  ../data/test/imgs/0.jpg      0  2.022715\n",
       "1  ../data/test/imgs/1.jpg      1  2.040872\n",
       "2  ../data/test/imgs/2.jpg      2  2.062394\n",
       "3  ../data/test/imgs/3.jpg      3  2.076283\n",
       "4  ../data/test/imgs/4.jpg      4  2.077074"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sub-set of images for code debug purposes  ****** DEBUG ONLY ******** COMMENT\n",
    "#train_df=train_df.head(322) #161\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIDEO TO (IMAGES AND CSV FILE)\n",
    "# only if images have not been extracted then this code block gets executed to generate jpgs from mp4\n",
    "# make sure that 'train1_img_path' has no jpgs if running for first time \n",
    "\n",
    "def write_image_to_disk(idx, cap, writer, item):\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "    \n",
    "    #read in the image\n",
    "    success, image = cap.read()\n",
    "    print success\n",
    "\n",
    "    if success:\n",
    "        image_path = os.path.join(train1_img_path, str(idx) + '.jpg')\n",
    "\n",
    "        #save image to IMG folder\n",
    "        cv2.imwrite(image_path, image)\n",
    "\n",
    "        #write row to train1.csv\n",
    "        writer.writerow({'image_path': image_path,\n",
    "                  'frame': idx,\n",
    "                  'speed':float(item),\n",
    "                 })\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images extracted..\n"
     ]
    }
   ],
   "source": [
    "last_count = 0\n",
    "if not any(fname.endswith('.jpg') for fname in os.listdir(train1_img_path)):\n",
    "\n",
    "    with open(train1_csv_path, 'w') as csvfile:\n",
    "         fieldnames = ['image_path', 'frame', 'speed']\n",
    "         writer = csv.DictWriter(csvfile, fieldnames = fieldnames)\n",
    "         writer.writeheader()\n",
    "\n",
    "         #Path to raw image folder\n",
    "         abs_path_to_IMG = os.path.join(train1_img_path)\n",
    "\n",
    "         cap = cv2.VideoCapture(train1_mp4_path)\n",
    "         cap.set(cv2.CAP_PROP_FRAME_COUNT, len(speed_ground))\n",
    "\n",
    "         for idx, item in enumerate(speed_ground):\n",
    "            \n",
    "            if idx % 100 == 0:\n",
    "                print idx , 'images extracted .... '\n",
    "            \n",
    "            write_image_to_disk(idx, cap, writer, item)\n",
    "        \n",
    "         last_count = idx\n",
    "         \n",
    "                \n",
    "            \n",
    "print('images extracted..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take care of regenerating the last image 1 more time to fix the pairs of image count\n",
    "\n",
    "if last_count != 0 and idx%2 != 0 :\n",
    "    idx +=1\n",
    "    print idx\n",
    "    shutil.copyfile(train1_img_path+ str(idx-1) + '.jpg', train1_img_path + str(idx) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness_augmentation(img,brightness_factor):\n",
    "    hsv_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "#     print hsv_image.shape\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2]*brightness_factor\n",
    "    img = np.array(hsv_image, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def batch_shuffle(dframe):\n",
    "    dframe_for_split=dframe[:-1]\n",
    "    train_data = []\n",
    "    validation_data = []\n",
    "    \n",
    "    train,validation=train_test_split(dframe_for_split, shuffle=False, test_size=0.2) # shuffle false will ensure the logic below of idx2 = idx + 1  will work\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"train length \", len(train))\n",
    "    print(\"validation length \", len(validation))\n",
    "    print('===================================')\n",
    "    print(\"training data \", train)\n",
    "    print('===================================')\n",
    "    print(\"validation data \", validation)\n",
    "    \n",
    "    print('----------  TRAINING PAIRS --------------------')\n",
    "    for _,row in train.iterrows():\n",
    "        idx1=row['frame']\n",
    "        idx2=idx1+1\n",
    "        #print('idx1 =%s idx2=%s'%(idx1,idx2))\n",
    "        \n",
    "        train_data.append((idx1,idx2))\n",
    "        \n",
    "    print('----------  VALIDATION PAIRS --------------------')\n",
    "    for _,row in validation.iterrows():\n",
    "        idx1=row['frame']\n",
    "        idx2=idx1+1\n",
    "        #print('idx1 =%s idx2=%s'%(idx1,idx2))\n",
    "        \n",
    "        validation_data.append((idx1,idx2))\n",
    "    return train_data, validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "('train length ', 16319)\n",
      "('validation length ', 4080)\n",
      "===================================\n",
      "('training data ',                          image_path  frame      speed\n",
      "0          ../data/train/imgs/0.jpg      0  28.105569\n",
      "1          ../data/train/imgs/1.jpg      1  28.105569\n",
      "2          ../data/train/imgs/2.jpg      2  28.106527\n",
      "3          ../data/train/imgs/3.jpg      3  28.130404\n",
      "4          ../data/train/imgs/4.jpg      4  28.109243\n",
      "5          ../data/train/imgs/5.jpg      5  28.088572\n",
      "6          ../data/train/imgs/6.jpg      6  28.034211\n",
      "7          ../data/train/imgs/7.jpg      7  28.018491\n",
      "8          ../data/train/imgs/8.jpg      8  27.986624\n",
      "9          ../data/train/imgs/9.jpg      9  28.016352\n",
      "10        ../data/train/imgs/10.jpg     10  27.981986\n",
      "11        ../data/train/imgs/11.jpg     11  27.978625\n",
      "12        ../data/train/imgs/12.jpg     12  28.032331\n",
      "13        ../data/train/imgs/13.jpg     13  27.960219\n",
      "14        ../data/train/imgs/14.jpg     14  27.937178\n",
      "15        ../data/train/imgs/15.jpg     15  27.940599\n",
      "16        ../data/train/imgs/16.jpg     16  27.908579\n",
      "17        ../data/train/imgs/17.jpg     17  27.898606\n",
      "18        ../data/train/imgs/18.jpg     18  27.855982\n",
      "19        ../data/train/imgs/19.jpg     19  27.795581\n",
      "20        ../data/train/imgs/20.jpg     20  27.850634\n",
      "21        ../data/train/imgs/21.jpg     21  27.839349\n",
      "22        ../data/train/imgs/22.jpg     22  27.824348\n",
      "23        ../data/train/imgs/23.jpg     23  27.759608\n",
      "24        ../data/train/imgs/24.jpg     24  27.830055\n",
      "25        ../data/train/imgs/25.jpg     25  27.761886\n",
      "26        ../data/train/imgs/26.jpg     26  27.694763\n",
      "27        ../data/train/imgs/27.jpg     27  27.761203\n",
      "28        ../data/train/imgs/28.jpg     28  27.691932\n",
      "29        ../data/train/imgs/29.jpg     29  27.666086\n",
      "...                             ...    ...        ...\n",
      "16289  ../data/train/imgs/16289.jpg  16289  10.978453\n",
      "16290  ../data/train/imgs/16290.jpg  16290  10.905011\n",
      "16291  ../data/train/imgs/16291.jpg  16291  10.910149\n",
      "16292  ../data/train/imgs/16292.jpg  16292  10.866553\n",
      "16293  ../data/train/imgs/16293.jpg  16293  10.787989\n",
      "16294  ../data/train/imgs/16294.jpg  16294  10.793201\n",
      "16295  ../data/train/imgs/16295.jpg  16295  10.701097\n",
      "16296  ../data/train/imgs/16296.jpg  16296  10.685049\n",
      "16297  ../data/train/imgs/16297.jpg  16297  10.662905\n",
      "16298  ../data/train/imgs/16298.jpg  16298  10.603743\n",
      "16299  ../data/train/imgs/16299.jpg  16299  10.584126\n",
      "16300  ../data/train/imgs/16300.jpg  16300  10.573514\n",
      "16301  ../data/train/imgs/16301.jpg  16301  10.483322\n",
      "16302  ../data/train/imgs/16302.jpg  16302  10.492700\n",
      "16303  ../data/train/imgs/16303.jpg  16303  10.427550\n",
      "16304  ../data/train/imgs/16304.jpg  16304  10.360746\n",
      "16305  ../data/train/imgs/16305.jpg  16305  10.386008\n",
      "16306  ../data/train/imgs/16306.jpg  16306  10.289215\n",
      "16307  ../data/train/imgs/16307.jpg  16307  10.229025\n",
      "16308  ../data/train/imgs/16308.jpg  16308  10.165880\n",
      "16309  ../data/train/imgs/16309.jpg  16309  10.178103\n",
      "16310  ../data/train/imgs/16310.jpg  16310  10.114327\n",
      "16311  ../data/train/imgs/16311.jpg  16311  10.082663\n",
      "16312  ../data/train/imgs/16312.jpg  16312  10.087258\n",
      "16313  ../data/train/imgs/16313.jpg  16313  10.041319\n",
      "16314  ../data/train/imgs/16314.jpg  16314   9.979821\n",
      "16315  ../data/train/imgs/16315.jpg  16315   9.985245\n",
      "16316  ../data/train/imgs/16316.jpg  16316   9.897348\n",
      "16317  ../data/train/imgs/16317.jpg  16317   9.817884\n",
      "16318  ../data/train/imgs/16318.jpg  16318   9.839633\n",
      "\n",
      "[16319 rows x 3 columns])\n",
      "===================================\n",
      "('validation data ',                          image_path  frame     speed\n",
      "16319  ../data/train/imgs/16319.jpg  16319  9.759789\n",
      "16320  ../data/train/imgs/16320.jpg  16320  9.713289\n",
      "16321  ../data/train/imgs/16321.jpg  16321  9.715314\n",
      "16322  ../data/train/imgs/16322.jpg  16322  9.621404\n",
      "16323  ../data/train/imgs/16323.jpg  16323  9.604698\n",
      "16324  ../data/train/imgs/16324.jpg  16324  9.558088\n",
      "16325  ../data/train/imgs/16325.jpg  16325  9.525750\n",
      "16326  ../data/train/imgs/16326.jpg  16326  9.513733\n",
      "16327  ../data/train/imgs/16327.jpg  16327  9.428186\n",
      "16328  ../data/train/imgs/16328.jpg  16328  9.375038\n",
      "16329  ../data/train/imgs/16329.jpg  16329  9.275301\n",
      "16330  ../data/train/imgs/16330.jpg  16330  9.283223\n",
      "16331  ../data/train/imgs/16331.jpg  16331  9.215256\n",
      "16332  ../data/train/imgs/16332.jpg  16332  9.099360\n",
      "16333  ../data/train/imgs/16333.jpg  16333  9.123953\n",
      "16334  ../data/train/imgs/16334.jpg  16334  9.029621\n",
      "16335  ../data/train/imgs/16335.jpg  16335  8.935130\n",
      "16336  ../data/train/imgs/16336.jpg  16336  8.960606\n",
      "16337  ../data/train/imgs/16337.jpg  16337  8.838398\n",
      "16338  ../data/train/imgs/16338.jpg  16338  8.725480\n",
      "16339  ../data/train/imgs/16339.jpg  16339  8.763651\n",
      "16340  ../data/train/imgs/16340.jpg  16340  8.663380\n",
      "16341  ../data/train/imgs/16341.jpg  16341  8.585938\n",
      "16342  ../data/train/imgs/16342.jpg  16342  8.615946\n",
      "16343  ../data/train/imgs/16343.jpg  16343  8.478958\n",
      "16344  ../data/train/imgs/16344.jpg  16344  8.406431\n",
      "16345  ../data/train/imgs/16345.jpg  16345  8.323467\n",
      "16346  ../data/train/imgs/16346.jpg  16346  8.294794\n",
      "16347  ../data/train/imgs/16347.jpg  16347  8.249919\n",
      "16348  ../data/train/imgs/16348.jpg  16348  8.096785\n",
      "...                             ...    ...       ...\n",
      "20369  ../data/train/imgs/20369.jpg  20369  3.167466\n",
      "20370  ../data/train/imgs/20370.jpg  20370  3.104029\n",
      "20371  ../data/train/imgs/20371.jpg  20371  3.073875\n",
      "20372  ../data/train/imgs/20372.jpg  20372  3.069786\n",
      "20373  ../data/train/imgs/20373.jpg  20373  3.015492\n",
      "20374  ../data/train/imgs/20374.jpg  20374  2.979671\n",
      "20375  ../data/train/imgs/20375.jpg  20375  2.913276\n",
      "20376  ../data/train/imgs/20376.jpg  20376  2.941836\n",
      "20377  ../data/train/imgs/20377.jpg  20377  2.867819\n",
      "20378  ../data/train/imgs/20378.jpg  20378  2.825360\n",
      "20379  ../data/train/imgs/20379.jpg  20379  2.837424\n",
      "20380  ../data/train/imgs/20380.jpg  20380  2.795000\n",
      "20381  ../data/train/imgs/20381.jpg  20381  2.724942\n",
      "20382  ../data/train/imgs/20382.jpg  20382  2.746720\n",
      "20383  ../data/train/imgs/20383.jpg  20383  2.686178\n",
      "20384  ../data/train/imgs/20384.jpg  20384  2.662286\n",
      "20385  ../data/train/imgs/20385.jpg  20385  2.667574\n",
      "20386  ../data/train/imgs/20386.jpg  20386  2.594662\n",
      "20387  ../data/train/imgs/20387.jpg  20387  2.564792\n",
      "20388  ../data/train/imgs/20388.jpg  20388  2.559002\n",
      "20389  ../data/train/imgs/20389.jpg  20389  2.498684\n",
      "20390  ../data/train/imgs/20390.jpg  20390  2.479404\n",
      "20391  ../data/train/imgs/20391.jpg  20391  2.435836\n",
      "20392  ../data/train/imgs/20392.jpg  20392  2.422405\n",
      "20393  ../data/train/imgs/20393.jpg  20393  2.407294\n",
      "20394  ../data/train/imgs/20394.jpg  20394  2.364811\n",
      "20395  ../data/train/imgs/20395.jpg  20395  2.329180\n",
      "20396  ../data/train/imgs/20396.jpg  20396  2.289795\n",
      "20397  ../data/train/imgs/20397.jpg  20397  2.292917\n",
      "20398  ../data/train/imgs/20398.jpg  20398  2.260600\n",
      "\n",
      "[4080 rows x 3 columns])\n",
      "----------  TRAINING PAIRS --------------------\n",
      "----------  VALIDATION PAIRS --------------------\n",
      "train_pairs\n",
      "16319\n",
      "\n",
      "validation_pairs\n",
      "4080\n"
     ]
    }
   ],
   "source": [
    "x,y = batch_shuffle(train_df)\n",
    "print \"train_pairs\"\n",
    "print len(x)\n",
    "print \"\"\n",
    "print \"validation_pairs\"\n",
    "print len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image_path, brightness_factor=None):\n",
    "    img=cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#\n",
    "    if brightness_factor:\n",
    "        img = brightness_augmentation(img, brightness_factor)\n",
    "    img = cv2.resize(img[100:440, :-90], (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def computeOpticalFlow(img1,img2):  #Sparse Optical Flow\n",
    "    \n",
    "    gray1=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    gray2=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    frame=img1 #gray1\n",
    "    p0 = cv2.goodFeaturesToTrack(gray1, mask = None, **feature_params)\n",
    "    #print('p0 >>> ',p0)\n",
    "    \n",
    "    result = np.zeros((frame.shape[0], frame.shape[1],3), np.uint8)\n",
    "    if p0 is not None:\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(gray1, gray2, p0, None, **lk_params)\n",
    "    \n",
    "        mask = np.zeros_like(gray1)\n",
    "        color = np.random.randint(0,255,(100,3))\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "        # draw the tracks\n",
    "        for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "            a,b = new.ravel()\n",
    "            c,d = old.ravel()\n",
    "            mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "\n",
    "        #print frame.shape\n",
    "        #print mask.shape\n",
    "        #img = cv2.add(frame,mask)\n",
    "        result = cv2.bitwise_and(frame,frame,mask = mask)\n",
    "\n",
    "        #print result.shape\n",
    "        #plt.imshow(result)\n",
    "        #plt.show()\n",
    "        # Now update the previous frame and previous points\n",
    "        #old_gray = gray2.copy()\n",
    "        #p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ..., \n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1=preprocessing('../data/train/imgs/0.jpg')\n",
    "img2=preprocessing('../data/train/imgs/1.jpg')\n",
    "\n",
    "computeOpticalFlow(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading 509 minibatches(=32) of training samples.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "def generate_training_data(tuples, data, batch_size=num_batch_size):\n",
    "    channels=3\n",
    "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    batch_data = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    for j in range(len(tuples) /batch_size): #*2\n",
    "        for i in range(0,batch_size): #,2\n",
    "            idx = np.random.randint(1, len(tuples) - 1)\n",
    "\n",
    "            brightness_factor=0.2 + np.random.uniform()\n",
    "\n",
    "            row1=data.iloc[[tuples[idx][0]]] #idx\n",
    "            row2=data.iloc[[tuples[idx][1]]] #idx\n",
    "            \n",
    "            #print(row1['image_path'])\n",
    "            img1 = preprocessing(row1['image_path'].values[0],brightness_factor)\n",
    "            img2 = preprocessing(row2['image_path'].values[0],brightness_factor)\n",
    "            #print row1['image_path']\n",
    "            #print row2['image_path']\n",
    "            \n",
    "            speed1 = row1['speed'].values[0]\n",
    "            speed2 = row2['speed'].values[0]\n",
    "\n",
    "            resimg = computeOpticalFlow(img1,img2)\n",
    "            speed = np.mean([speed1, speed2])\n",
    "            \n",
    "            image_batch[i] = resimg\n",
    "            label_batch[i] = speed\n",
    "            \n",
    "            # flip the same image and save with same label\n",
    "            \n",
    "            ## flipping the image pair\n",
    "            #aug_img1 = np.flip(img1, 0)\n",
    "            #aug_img2 = np.flip(img2, 0)\n",
    "            #aug_resimg = computeOpticalFlow(aug_img1,aug_img2)\n",
    "\n",
    "            #image_batch[i+1] = aug_resimg\n",
    "            #label_batch[i+1] = speed # speed remains the same\n",
    "            \n",
    "        img_batch=image_batch\n",
    "        img_batch = np.reshape(img_batch, (batch_size, channels, 66, 220))\n",
    "        \n",
    "        \n",
    "            \n",
    "        batch_data.append(copy.deepcopy(torch.from_numpy(img_batch)))\n",
    "        batch_labels.append(copy.deepcopy(torch.DoubleTensor(label_batch)))\n",
    "    \n",
    "    return zip(batch_data, batch_labels)\n",
    "\n",
    "batch_size=num_batch_size\n",
    "\n",
    "trainloader=list(generate_training_data(x,train_df))\n",
    "train_num = len(trainloader)\n",
    "print(\"Finish loading %d minibatches(=%d) of training samples.\" % (train_num, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading 127 minibatches(=32) of validation samples.\n"
     ]
    }
   ],
   "source": [
    "def generate_validation_data(tuples,data,batch_size=num_batch_size):\n",
    "    channels=3\n",
    "    val_image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    val_label_batch = np.zeros((batch_size))\n",
    "    batch_data_val = []\n",
    "    batch_labels_val = []\n",
    "    output = list()\n",
    "    \n",
    "    for j in range(len(tuples)/batch_size):\n",
    "        for i in range(0,batch_size):\n",
    "            idx = np.random.randint(1, len(tuples) - 1)\n",
    "            \n",
    "            brightness_factor=0.2 + np.random.uniform()\n",
    "            \n",
    "            row1=data.iloc[[tuples[idx][0]]] #idx\n",
    "            row2=data.iloc[[tuples[idx][1]]] #idx\n",
    "\n",
    "            img1 = preprocessing(row1['image_path'].values[0],brightness_factor)\n",
    "            img2 = preprocessing(row2['image_path'].values[0],brightness_factor)\n",
    "            \n",
    "            #print row1['image_path']\n",
    "            #print row2['image_path']\n",
    "            speed1 = row1['speed'].values[0]\n",
    "            speed2 = row2['speed'].values[0]\n",
    "            \n",
    "            #print speed1\n",
    "            #print speed2\n",
    "\n",
    "            resimg = computeOpticalFlow(img1,img2)\n",
    "            #resimg = resimg.reshape(1, resimg.shape[0], resimg.shape[1], resimg.shape[2])\n",
    "            \n",
    "            \n",
    "            speed = np.mean([speed1, speed2])\n",
    "            #speed = np.array([[speed]])\n",
    "            #print \"speed \", speed\n",
    "            \n",
    "            val_image_batch[i] = resimg\n",
    "            val_label_batch[i] = speed\n",
    "            \n",
    "            #print i\n",
    "            #print \"resimg \", resimg\n",
    "            #print \"val_image_batch[i] >>>>> \",val_image_batch[i]\n",
    "            #print val_label_batch[i]\n",
    "            #print \"*****************************\"\n",
    "            \n",
    "        \n",
    "        val_img_batch=val_image_batch\n",
    "        val_img_batch = np.reshape(val_img_batch, (batch_size, channels, 66, 220))\n",
    "        #print \"val_img_batch\" ,val_img_batch\n",
    "        \n",
    "        batch_data_val.append(copy.deepcopy(torch.from_numpy(val_img_batch)))\n",
    "        batch_labels_val.append(copy.deepcopy(torch.DoubleTensor(val_label_batch)))\n",
    "        \n",
    "    return zip(batch_data_val, batch_labels_val)\n",
    "\n",
    "batch_size=num_batch_size\n",
    "\n",
    "validatnloader=list(generate_validation_data(y,train_df))\n",
    "validation_num = len(validatnloader)\n",
    "print(\"Finish loading %d minibatches(=%d) of validation samples.\" % (validation_num, batch_size))\n",
    "#print \"validatnloader >> \",validatnloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "img_size=(66,220,3)\n",
    "\n",
    "class NvidiaNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NvidiaNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 24, kernel_size=5,stride=2)\n",
    "        self.conv2 = nn.Conv2d(24, 36, kernel_size=5,stride=2)\n",
    "        self.conv3 = nn.Conv2d(36, 48, kernel_size=5,stride=2)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.conv4 = nn.Conv2d(48, 64, kernel_size=3,stride=1)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3,stride=1)\n",
    "        self.fc1 = nn.Linear(1280, 1164)\n",
    "        self.fc2 = nn.Linear(1164, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        self.fc5 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.conv3_drop(F.elu(self.conv3(x)))\n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = F.elu(self.conv5(x))\n",
    "        x = x.view(-1, 1280)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = F.elu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "net = NvidiaNet()\n",
    "net = net.double()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1,    10] loss: 0.122\n",
      "[1,    20] loss: 0.133\n",
      "[1,    30] loss: 0.083\n",
      "[1,    40] loss: 0.093\n",
      "[1,    50] loss: 0.045\n",
      "[1,    60] loss: 0.043\n",
      "[1,    70] loss: 0.045\n",
      "[1,    80] loss: 0.036\n",
      "[1,    90] loss: 0.035\n",
      "[1,   100] loss: 0.032\n",
      "[1,   110] loss: 0.033\n",
      "[1,   120] loss: 0.026\n",
      "[1,   130] loss: 0.039\n",
      "[1,   140] loss: 0.027\n",
      "[1,   150] loss: 0.032\n",
      "[1,   160] loss: 0.033\n",
      "[1,   170] loss: 0.044\n",
      "[1,   180] loss: 0.023\n",
      "[1,   190] loss: 0.040\n",
      "[1,   200] loss: 0.029\n",
      "[1,   210] loss: 0.043\n",
      "[1,   220] loss: 0.039\n",
      "[1,   230] loss: 0.033\n",
      "[1,   240] loss: 0.031\n",
      "[1,   250] loss: 0.032\n",
      "[1,   260] loss: 0.029\n",
      "[1,   270] loss: 0.043\n",
      "[1,   280] loss: 0.031\n",
      "[1,   290] loss: 0.024\n",
      "[1,   300] loss: 0.036\n",
      "[1,   310] loss: 0.035\n",
      "[1,   320] loss: 0.023\n",
      "[1,   330] loss: 0.027\n",
      "[1,   340] loss: 0.027\n",
      "[1,   350] loss: 0.018\n",
      "[1,   360] loss: 0.034\n",
      "[1,   370] loss: 0.032\n",
      "[1,   380] loss: 0.034\n",
      "[1,   390] loss: 0.028\n",
      "[1,   400] loss: 0.025\n",
      "[1,   410] loss: 0.033\n",
      "[1,   420] loss: 0.018\n",
      "[1,   430] loss: 0.021\n",
      "[1,   440] loss: 0.035\n",
      "[1,   450] loss: 0.030\n",
      "[1,   460] loss: 0.030\n",
      "[1,   470] loss: 0.028\n",
      "[1,   480] loss: 0.034\n",
      "[1,   490] loss: 0.019\n",
      "[1,   500] loss: 0.031\n",
      "1\n",
      "[2,    10] loss: 0.033\n",
      "[2,    20] loss: 0.033\n",
      "[2,    30] loss: 0.018\n",
      "[2,    40] loss: 0.028\n",
      "[2,    50] loss: 0.024\n",
      "[2,    60] loss: 0.032\n",
      "[2,    70] loss: 0.029\n",
      "[2,    80] loss: 0.034\n",
      "[2,    90] loss: 0.031\n",
      "[2,   100] loss: 0.024\n",
      "[2,   110] loss: 0.031\n",
      "[2,   120] loss: 0.030\n",
      "[2,   130] loss: 0.034\n",
      "[2,   140] loss: 0.022\n",
      "[2,   150] loss: 0.030\n",
      "[2,   160] loss: 0.026\n",
      "[2,   170] loss: 0.036\n",
      "[2,   180] loss: 0.018\n",
      "[2,   190] loss: 0.034\n",
      "[2,   200] loss: 0.023\n",
      "[2,   210] loss: 0.032\n",
      "[2,   220] loss: 0.029\n",
      "[2,   230] loss: 0.026\n",
      "[2,   240] loss: 0.025\n",
      "[2,   250] loss: 0.032\n",
      "[2,   260] loss: 0.029\n",
      "[2,   270] loss: 0.031\n",
      "[2,   280] loss: 0.021\n",
      "[2,   290] loss: 0.019\n",
      "[2,   300] loss: 0.027\n",
      "[2,   310] loss: 0.030\n",
      "[2,   320] loss: 0.018\n",
      "[2,   330] loss: 0.025\n",
      "[2,   340] loss: 0.028\n",
      "[2,   350] loss: 0.017\n",
      "[2,   360] loss: 0.022\n",
      "[2,   370] loss: 0.028\n",
      "[2,   380] loss: 0.018\n",
      "[2,   390] loss: 0.022\n",
      "[2,   400] loss: 0.024\n",
      "[2,   410] loss: 0.025\n",
      "[2,   420] loss: 0.011\n",
      "[2,   430] loss: 0.021\n",
      "[2,   440] loss: 0.023\n",
      "[2,   450] loss: 0.020\n",
      "[2,   460] loss: 0.026\n",
      "[2,   470] loss: 0.020\n",
      "[2,   480] loss: 0.026\n",
      "[2,   490] loss: 0.012\n",
      "[2,   500] loss: 0.017\n",
      "2\n",
      "[3,    10] loss: 0.025\n",
      "[3,    20] loss: 0.024\n",
      "[3,    30] loss: 0.012\n",
      "[3,    40] loss: 0.022\n",
      "[3,    50] loss: 0.017\n",
      "[3,    60] loss: 0.018\n",
      "[3,    70] loss: 0.026\n",
      "[3,    80] loss: 0.027\n",
      "[3,    90] loss: 0.026\n",
      "[3,   100] loss: 0.019\n",
      "[3,   110] loss: 0.026\n",
      "[3,   120] loss: 0.023\n",
      "[3,   130] loss: 0.026\n",
      "[3,   140] loss: 0.021\n",
      "[3,   150] loss: 0.019\n",
      "[3,   160] loss: 0.018\n",
      "[3,   170] loss: 0.026\n",
      "[3,   180] loss: 0.010\n",
      "[3,   190] loss: 0.021\n",
      "[3,   200] loss: 0.016\n",
      "[3,   210] loss: 0.029\n",
      "[3,   220] loss: 0.028\n",
      "[3,   230] loss: 0.017\n",
      "[3,   240] loss: 0.016\n",
      "[3,   250] loss: 0.021\n",
      "[3,   260] loss: 0.026\n",
      "[3,   270] loss: 0.031\n",
      "[3,   280] loss: 0.017\n",
      "[3,   290] loss: 0.022\n",
      "[3,   300] loss: 0.019\n",
      "[3,   310] loss: 0.029\n",
      "[3,   320] loss: 0.019\n",
      "[3,   330] loss: 0.019\n",
      "[3,   340] loss: 0.018\n",
      "[3,   350] loss: 0.010\n",
      "[3,   360] loss: 0.017\n",
      "[3,   370] loss: 0.022\n",
      "[3,   380] loss: 0.014\n",
      "[3,   390] loss: 0.016\n",
      "[3,   400] loss: 0.019\n",
      "[3,   410] loss: 0.023\n",
      "[3,   420] loss: 0.011\n",
      "[3,   430] loss: 0.021\n",
      "[3,   440] loss: 0.014\n",
      "[3,   450] loss: 0.014\n",
      "[3,   460] loss: 0.024\n",
      "[3,   470] loss: 0.012\n",
      "[3,   480] loss: 0.022\n",
      "[3,   490] loss: 0.009\n",
      "[3,   500] loss: 0.016\n",
      "3\n",
      "[4,    10] loss: 0.019\n",
      "[4,    20] loss: 0.019\n",
      "[4,    30] loss: 0.010\n",
      "[4,    40] loss: 0.016\n",
      "[4,    50] loss: 0.013\n",
      "[4,    60] loss: 0.014\n",
      "[4,    70] loss: 0.024\n",
      "[4,    80] loss: 0.017\n",
      "[4,    90] loss: 0.015\n",
      "[4,   100] loss: 0.021\n",
      "[4,   110] loss: 0.021\n",
      "[4,   120] loss: 0.025\n",
      "[4,   130] loss: 0.032\n",
      "[4,   140] loss: 0.018\n",
      "[4,   150] loss: 0.018\n",
      "[4,   160] loss: 0.011\n",
      "[4,   170] loss: 0.019\n",
      "[4,   180] loss: 0.012\n",
      "[4,   190] loss: 0.016\n",
      "[4,   200] loss: 0.015\n",
      "[4,   210] loss: 0.027\n",
      "[4,   220] loss: 0.023\n",
      "[4,   230] loss: 0.016\n",
      "[4,   240] loss: 0.011\n",
      "[4,   250] loss: 0.017\n",
      "[4,   260] loss: 0.018\n",
      "[4,   270] loss: 0.025\n",
      "[4,   280] loss: 0.015\n",
      "[4,   290] loss: 0.020\n",
      "[4,   300] loss: 0.013\n",
      "[4,   310] loss: 0.022\n",
      "[4,   320] loss: 0.017\n",
      "[4,   330] loss: 0.016\n",
      "[4,   340] loss: 0.017\n",
      "[4,   350] loss: 0.009\n",
      "[4,   360] loss: 0.013\n",
      "[4,   370] loss: 0.018\n",
      "[4,   380] loss: 0.013\n",
      "[4,   390] loss: 0.018\n",
      "[4,   400] loss: 0.018\n",
      "[4,   410] loss: 0.018\n",
      "[4,   420] loss: 0.010\n",
      "[4,   430] loss: 0.018\n",
      "[4,   440] loss: 0.011\n",
      "[4,   450] loss: 0.011\n",
      "[4,   460] loss: 0.017\n",
      "[4,   470] loss: 0.010\n",
      "[4,   480] loss: 0.018\n",
      "[4,   490] loss: 0.007\n",
      "[4,   500] loss: 0.010\n",
      "4\n",
      "[5,    10] loss: 0.014\n",
      "[5,    20] loss: 0.019\n",
      "[5,    30] loss: 0.007\n",
      "[5,    40] loss: 0.018\n",
      "[5,    50] loss: 0.013\n",
      "[5,    60] loss: 0.012\n",
      "[5,    70] loss: 0.020\n",
      "[5,    80] loss: 0.012\n",
      "[5,    90] loss: 0.013\n",
      "[5,   100] loss: 0.017\n",
      "[5,   110] loss: 0.018\n",
      "[5,   120] loss: 0.023\n",
      "[5,   130] loss: 0.026\n",
      "[5,   140] loss: 0.015\n",
      "[5,   150] loss: 0.013\n",
      "[5,   160] loss: 0.009\n",
      "[5,   170] loss: 0.016\n",
      "[5,   180] loss: 0.010\n",
      "[5,   190] loss: 0.013\n",
      "[5,   200] loss: 0.012\n",
      "[5,   210] loss: 0.025\n",
      "[5,   220] loss: 0.020\n",
      "[5,   230] loss: 0.013\n",
      "[5,   240] loss: 0.010\n",
      "[5,   250] loss: 0.015\n",
      "[5,   260] loss: 0.016\n",
      "[5,   270] loss: 0.019\n",
      "[5,   280] loss: 0.016\n",
      "[5,   290] loss: 0.015\n",
      "[5,   300] loss: 0.013\n",
      "[5,   310] loss: 0.016\n",
      "[5,   320] loss: 0.013\n",
      "[5,   330] loss: 0.014\n",
      "[5,   340] loss: 0.015\n",
      "[5,   350] loss: 0.008\n",
      "[5,   360] loss: 0.011\n",
      "[5,   370] loss: 0.018\n",
      "[5,   380] loss: 0.010\n",
      "[5,   390] loss: 0.016\n",
      "[5,   400] loss: 0.019\n",
      "[5,   410] loss: 0.018\n",
      "[5,   420] loss: 0.008\n",
      "[5,   430] loss: 0.017\n",
      "[5,   440] loss: 0.011\n",
      "[5,   450] loss: 0.013\n",
      "[5,   460] loss: 0.016\n",
      "[5,   470] loss: 0.010\n",
      "[5,   480] loss: 0.014\n",
      "[5,   490] loss: 0.007\n",
      "[5,   500] loss: 0.008\n",
      "5\n",
      "[6,    10] loss: 0.011\n",
      "[6,    20] loss: 0.014\n",
      "[6,    30] loss: 0.007\n",
      "[6,    40] loss: 0.016\n",
      "[6,    50] loss: 0.011\n",
      "[6,    60] loss: 0.011\n",
      "[6,    70] loss: 0.017\n",
      "[6,    80] loss: 0.008\n",
      "[6,    90] loss: 0.011\n",
      "[6,   100] loss: 0.013\n",
      "[6,   110] loss: 0.016\n",
      "[6,   120] loss: 0.016\n",
      "[6,   130] loss: 0.019\n",
      "[6,   140] loss: 0.011\n",
      "[6,   150] loss: 0.010\n",
      "[6,   160] loss: 0.008\n",
      "[6,   170] loss: 0.015\n",
      "[6,   180] loss: 0.009\n",
      "[6,   190] loss: 0.013\n",
      "[6,   200] loss: 0.007\n",
      "[6,   210] loss: 0.020\n",
      "[6,   220] loss: 0.014\n",
      "[6,   230] loss: 0.013\n",
      "[6,   240] loss: 0.007\n",
      "[6,   250] loss: 0.015\n",
      "[6,   260] loss: 0.014\n",
      "[6,   270] loss: 0.014\n",
      "[6,   280] loss: 0.014\n",
      "[6,   290] loss: 0.013\n",
      "[6,   300] loss: 0.011\n",
      "[6,   310] loss: 0.011\n",
      "[6,   320] loss: 0.011\n",
      "[6,   330] loss: 0.011\n",
      "[6,   340] loss: 0.015\n",
      "[6,   350] loss: 0.009\n",
      "[6,   360] loss: 0.008\n",
      "[6,   370] loss: 0.012\n",
      "[6,   380] loss: 0.009\n",
      "[6,   390] loss: 0.013\n",
      "[6,   400] loss: 0.017\n",
      "[6,   410] loss: 0.014\n",
      "[6,   420] loss: 0.008\n",
      "[6,   430] loss: 0.015\n",
      "[6,   440] loss: 0.009\n",
      "[6,   450] loss: 0.010\n",
      "[6,   460] loss: 0.014\n",
      "[6,   470] loss: 0.008\n",
      "[6,   480] loss: 0.013\n",
      "[6,   490] loss: 0.006\n",
      "[6,   500] loss: 0.007\n",
      "6\n",
      "[7,    10] loss: 0.008\n",
      "[7,    20] loss: 0.012\n",
      "[7,    30] loss: 0.005\n",
      "[7,    40] loss: 0.015\n",
      "[7,    50] loss: 0.008\n",
      "[7,    60] loss: 0.009\n",
      "[7,    70] loss: 0.015\n",
      "[7,    80] loss: 0.007\n",
      "[7,    90] loss: 0.011\n",
      "[7,   100] loss: 0.011\n",
      "[7,   110] loss: 0.013\n",
      "[7,   120] loss: 0.012\n",
      "[7,   130] loss: 0.017\n",
      "[7,   140] loss: 0.011\n",
      "[7,   150] loss: 0.010\n",
      "[7,   160] loss: 0.005\n",
      "[7,   170] loss: 0.012\n",
      "[7,   180] loss: 0.010\n",
      "[7,   190] loss: 0.010\n",
      "[7,   200] loss: 0.007\n",
      "[7,   210] loss: 0.012\n",
      "[7,   220] loss: 0.010\n",
      "[7,   230] loss: 0.010\n",
      "[7,   240] loss: 0.007\n",
      "[7,   250] loss: 0.014\n",
      "[7,   260] loss: 0.012\n",
      "[7,   270] loss: 0.011\n",
      "[7,   280] loss: 0.010\n",
      "[7,   290] loss: 0.013\n",
      "[7,   300] loss: 0.009\n",
      "[7,   310] loss: 0.007\n",
      "[7,   320] loss: 0.008\n",
      "[7,   330] loss: 0.009\n",
      "[7,   340] loss: 0.012\n",
      "[7,   350] loss: 0.009\n",
      "[7,   360] loss: 0.005\n",
      "[7,   370] loss: 0.014\n",
      "[7,   380] loss: 0.007\n",
      "[7,   390] loss: 0.008\n",
      "[7,   400] loss: 0.015\n",
      "[7,   410] loss: 0.014\n",
      "[7,   420] loss: 0.007\n",
      "[7,   430] loss: 0.014\n",
      "[7,   440] loss: 0.008\n",
      "[7,   450] loss: 0.009\n",
      "[7,   460] loss: 0.011\n",
      "[7,   470] loss: 0.007\n",
      "[7,   480] loss: 0.009\n",
      "[7,   490] loss: 0.006\n",
      "[7,   500] loss: 0.006\n",
      "7\n",
      "[8,    10] loss: 0.006\n",
      "[8,    20] loss: 0.015\n",
      "[8,    30] loss: 0.005\n",
      "[8,    40] loss: 0.010\n",
      "[8,    50] loss: 0.008\n",
      "[8,    60] loss: 0.008\n",
      "[8,    70] loss: 0.014\n",
      "[8,    80] loss: 0.006\n",
      "[8,    90] loss: 0.010\n",
      "[8,   100] loss: 0.009\n",
      "[8,   110] loss: 0.011\n",
      "[8,   120] loss: 0.010\n",
      "[8,   130] loss: 0.012\n",
      "[8,   140] loss: 0.008\n",
      "[8,   150] loss: 0.006\n",
      "[8,   160] loss: 0.005\n",
      "[8,   170] loss: 0.012\n",
      "[8,   180] loss: 0.006\n",
      "[8,   190] loss: 0.008\n",
      "[8,   200] loss: 0.005\n",
      "[8,   210] loss: 0.009\n",
      "[8,   220] loss: 0.007\n",
      "[8,   230] loss: 0.010\n",
      "[8,   240] loss: 0.006\n",
      "[8,   250] loss: 0.009\n",
      "[8,   260] loss: 0.015\n",
      "[8,   270] loss: 0.007\n",
      "[8,   280] loss: 0.010\n",
      "[8,   290] loss: 0.012\n",
      "[8,   300] loss: 0.009\n",
      "[8,   310] loss: 0.007\n",
      "[8,   320] loss: 0.007\n",
      "[8,   330] loss: 0.008\n",
      "[8,   340] loss: 0.010\n",
      "[8,   350] loss: 0.006\n",
      "[8,   360] loss: 0.006\n",
      "[8,   370] loss: 0.011\n",
      "[8,   380] loss: 0.005\n",
      "[8,   390] loss: 0.008\n",
      "[8,   400] loss: 0.011\n",
      "[8,   410] loss: 0.009\n",
      "[8,   420] loss: 0.005\n",
      "[8,   430] loss: 0.009\n",
      "[8,   440] loss: 0.006\n",
      "[8,   450] loss: 0.006\n",
      "[8,   460] loss: 0.010\n",
      "[8,   470] loss: 0.005\n",
      "[8,   480] loss: 0.009\n",
      "[8,   490] loss: 0.004\n",
      "[8,   500] loss: 0.009\n",
      "8\n",
      "[9,    10] loss: 0.009\n",
      "[9,    20] loss: 0.013\n",
      "[9,    30] loss: 0.004\n",
      "[9,    40] loss: 0.008\n",
      "[9,    50] loss: 0.007\n",
      "[9,    60] loss: 0.007\n",
      "[9,    70] loss: 0.008\n",
      "[9,    80] loss: 0.006\n",
      "[9,    90] loss: 0.010\n",
      "[9,   100] loss: 0.004\n",
      "[9,   110] loss: 0.007\n",
      "[9,   120] loss: 0.007\n",
      "[9,   130] loss: 0.011\n",
      "[9,   140] loss: 0.008\n",
      "[9,   150] loss: 0.007\n",
      "[9,   160] loss: 0.006\n",
      "[9,   170] loss: 0.008\n",
      "[9,   180] loss: 0.006\n",
      "[9,   190] loss: 0.005\n",
      "[9,   200] loss: 0.003\n",
      "[9,   210] loss: 0.006\n",
      "[9,   220] loss: 0.007\n",
      "[9,   230] loss: 0.007\n",
      "[9,   240] loss: 0.005\n",
      "[9,   250] loss: 0.006\n",
      "[9,   260] loss: 0.011\n",
      "[9,   270] loss: 0.005\n",
      "[9,   280] loss: 0.007\n",
      "[9,   290] loss: 0.013\n",
      "[9,   300] loss: 0.007\n",
      "[9,   310] loss: 0.005\n",
      "[9,   320] loss: 0.004\n",
      "[9,   330] loss: 0.006\n",
      "[9,   340] loss: 0.011\n",
      "[9,   350] loss: 0.006\n",
      "[9,   360] loss: 0.005\n",
      "[9,   370] loss: 0.010\n",
      "[9,   380] loss: 0.004\n",
      "[9,   390] loss: 0.006\n",
      "[9,   400] loss: 0.009\n",
      "[9,   410] loss: 0.012\n",
      "[9,   420] loss: 0.005\n",
      "[9,   430] loss: 0.008\n",
      "[9,   440] loss: 0.005\n",
      "[9,   450] loss: 0.005\n",
      "[9,   460] loss: 0.007\n",
      "[9,   470] loss: 0.004\n",
      "[9,   480] loss: 0.007\n",
      "[9,   490] loss: 0.004\n",
      "[9,   500] loss: 0.006\n",
      "9\n",
      "[10,    10] loss: 0.005\n",
      "[10,    20] loss: 0.010\n",
      "[10,    30] loss: 0.003\n",
      "[10,    40] loss: 0.007\n",
      "[10,    50] loss: 0.006\n",
      "[10,    60] loss: 0.005\n",
      "[10,    70] loss: 0.008\n",
      "[10,    80] loss: 0.005\n",
      "[10,    90] loss: 0.006\n",
      "[10,   100] loss: 0.005\n",
      "[10,   110] loss: 0.007\n",
      "[10,   120] loss: 0.008\n",
      "[10,   130] loss: 0.009\n",
      "[10,   140] loss: 0.006\n",
      "[10,   150] loss: 0.007\n",
      "[10,   160] loss: 0.005\n",
      "[10,   170] loss: 0.008\n",
      "[10,   180] loss: 0.006\n",
      "[10,   190] loss: 0.004\n",
      "[10,   200] loss: 0.002\n",
      "[10,   210] loss: 0.005\n",
      "[10,   220] loss: 0.005\n",
      "[10,   230] loss: 0.005\n",
      "[10,   240] loss: 0.004\n",
      "[10,   250] loss: 0.005\n",
      "[10,   260] loss: 0.010\n",
      "[10,   270] loss: 0.003\n",
      "[10,   280] loss: 0.006\n",
      "[10,   290] loss: 0.011\n",
      "[10,   300] loss: 0.006\n",
      "[10,   310] loss: 0.004\n",
      "[10,   320] loss: 0.004\n",
      "[10,   330] loss: 0.009\n",
      "[10,   340] loss: 0.008\n",
      "[10,   350] loss: 0.007\n",
      "[10,   360] loss: 0.004\n",
      "[10,   370] loss: 0.005\n",
      "[10,   380] loss: 0.003\n",
      "[10,   390] loss: 0.007\n",
      "[10,   400] loss: 0.010\n",
      "[10,   410] loss: 0.010\n",
      "[10,   420] loss: 0.004\n",
      "[10,   430] loss: 0.008\n",
      "[10,   440] loss: 0.007\n",
      "[10,   450] loss: 0.003\n",
      "[10,   460] loss: 0.006\n",
      "[10,   470] loss: 0.004\n",
      "[10,   480] loss: 0.006\n",
      "[10,   490] loss: 0.005\n",
      "[10,   500] loss: 0.007\n",
      "10\n",
      "[11,    10] loss: 0.003\n",
      "[11,    20] loss: 0.006\n",
      "[11,    30] loss: 0.003\n",
      "[11,    40] loss: 0.006\n",
      "[11,    50] loss: 0.007\n",
      "[11,    60] loss: 0.006\n",
      "[11,    70] loss: 0.008\n",
      "[11,    80] loss: 0.003\n",
      "[11,    90] loss: 0.008\n",
      "[11,   100] loss: 0.006\n",
      "[11,   110] loss: 0.007\n",
      "[11,   120] loss: 0.006\n",
      "[11,   130] loss: 0.006\n",
      "[11,   140] loss: 0.005\n",
      "[11,   150] loss: 0.005\n",
      "[11,   160] loss: 0.004\n",
      "[11,   170] loss: 0.005\n",
      "[11,   180] loss: 0.005\n",
      "[11,   190] loss: 0.005\n",
      "[11,   200] loss: 0.003\n",
      "[11,   210] loss: 0.004\n",
      "[11,   220] loss: 0.004\n",
      "[11,   230] loss: 0.005\n",
      "[11,   240] loss: 0.003\n",
      "[11,   250] loss: 0.004\n",
      "[11,   260] loss: 0.007\n",
      "[11,   270] loss: 0.004\n",
      "[11,   280] loss: 0.005\n",
      "[11,   290] loss: 0.009\n",
      "[11,   300] loss: 0.005\n",
      "[11,   310] loss: 0.004\n",
      "[11,   320] loss: 0.004\n",
      "[11,   330] loss: 0.005\n",
      "[11,   340] loss: 0.008\n",
      "[11,   350] loss: 0.004\n",
      "[11,   360] loss: 0.003\n",
      "[11,   370] loss: 0.006\n",
      "[11,   380] loss: 0.002\n",
      "[11,   390] loss: 0.006\n",
      "[11,   400] loss: 0.008\n",
      "[11,   410] loss: 0.005\n",
      "[11,   420] loss: 0.003\n",
      "[11,   430] loss: 0.007\n",
      "[11,   440] loss: 0.005\n",
      "[11,   450] loss: 0.004\n",
      "[11,   460] loss: 0.004\n",
      "[11,   470] loss: 0.005\n",
      "[11,   480] loss: 0.005\n",
      "[11,   490] loss: 0.003\n",
      "[11,   500] loss: 0.006\n",
      "11\n",
      "[12,    10] loss: 0.004\n",
      "[12,    20] loss: 0.006\n",
      "[12,    30] loss: 0.004\n",
      "[12,    40] loss: 0.004\n",
      "[12,    50] loss: 0.004\n",
      "[12,    60] loss: 0.003\n",
      "[12,    70] loss: 0.006\n",
      "[12,    80] loss: 0.004\n",
      "[12,    90] loss: 0.008\n",
      "[12,   100] loss: 0.003\n",
      "[12,   110] loss: 0.005\n",
      "[12,   120] loss: 0.006\n",
      "[12,   130] loss: 0.003\n",
      "[12,   140] loss: 0.004\n",
      "[12,   150] loss: 0.004\n",
      "[12,   160] loss: 0.004\n",
      "[12,   170] loss: 0.004\n",
      "[12,   180] loss: 0.005\n",
      "[12,   190] loss: 0.003\n",
      "[12,   200] loss: 0.003\n",
      "[12,   210] loss: 0.003\n",
      "[12,   220] loss: 0.003\n",
      "[12,   230] loss: 0.005\n",
      "[12,   240] loss: 0.003\n",
      "[12,   250] loss: 0.003\n",
      "[12,   260] loss: 0.005\n",
      "[12,   270] loss: 0.003\n",
      "[12,   280] loss: 0.006\n",
      "[12,   290] loss: 0.009\n",
      "[12,   300] loss: 0.005\n",
      "[12,   310] loss: 0.002\n",
      "[12,   320] loss: 0.003\n",
      "[12,   330] loss: 0.005\n",
      "[12,   340] loss: 0.007\n",
      "[12,   350] loss: 0.006\n",
      "[12,   360] loss: 0.004\n",
      "[12,   370] loss: 0.005\n",
      "[12,   380] loss: 0.003\n",
      "[12,   390] loss: 0.004\n",
      "[12,   400] loss: 0.008\n",
      "[12,   410] loss: 0.006\n",
      "[12,   420] loss: 0.003\n",
      "[12,   430] loss: 0.005\n",
      "[12,   440] loss: 0.005\n",
      "[12,   450] loss: 0.004\n",
      "[12,   460] loss: 0.004\n",
      "[12,   470] loss: 0.004\n",
      "[12,   480] loss: 0.005\n",
      "[12,   490] loss: 0.002\n",
      "[12,   500] loss: 0.004\n",
      "12\n",
      "[13,    10] loss: 0.004\n",
      "[13,    20] loss: 0.006\n",
      "[13,    30] loss: 0.002\n",
      "[13,    40] loss: 0.004\n",
      "[13,    50] loss: 0.005\n",
      "[13,    60] loss: 0.004\n",
      "[13,    70] loss: 0.004\n",
      "[13,    80] loss: 0.003\n",
      "[13,    90] loss: 0.005\n",
      "[13,   100] loss: 0.002\n",
      "[13,   110] loss: 0.005\n",
      "[13,   120] loss: 0.005\n",
      "[13,   130] loss: 0.004\n",
      "[13,   140] loss: 0.003\n",
      "[13,   150] loss: 0.003\n",
      "[13,   160] loss: 0.003\n",
      "[13,   170] loss: 0.003\n",
      "[13,   180] loss: 0.004\n",
      "[13,   190] loss: 0.003\n",
      "[13,   200] loss: 0.002\n",
      "[13,   210] loss: 0.004\n",
      "[13,   220] loss: 0.003\n",
      "[13,   230] loss: 0.004\n",
      "[13,   240] loss: 0.003\n",
      "[13,   250] loss: 0.002\n",
      "[13,   260] loss: 0.003\n",
      "[13,   270] loss: 0.003\n",
      "[13,   280] loss: 0.005\n",
      "[13,   290] loss: 0.009\n",
      "[13,   300] loss: 0.005\n",
      "[13,   310] loss: 0.001\n",
      "[13,   320] loss: 0.003\n",
      "[13,   330] loss: 0.004\n",
      "[13,   340] loss: 0.005\n",
      "[13,   350] loss: 0.004\n",
      "[13,   360] loss: 0.003\n",
      "[13,   370] loss: 0.004\n",
      "[13,   380] loss: 0.001\n",
      "[13,   390] loss: 0.003\n",
      "[13,   400] loss: 0.005\n",
      "[13,   410] loss: 0.005\n",
      "[13,   420] loss: 0.002\n",
      "[13,   430] loss: 0.005\n",
      "[13,   440] loss: 0.005\n",
      "[13,   450] loss: 0.004\n",
      "[13,   460] loss: 0.002\n",
      "[13,   470] loss: 0.003\n",
      "[13,   480] loss: 0.004\n",
      "[13,   490] loss: 0.002\n",
      "[13,   500] loss: 0.005\n",
      "13\n",
      "[14,    10] loss: 0.002\n",
      "[14,    20] loss: 0.004\n",
      "[14,    30] loss: 0.003\n",
      "[14,    40] loss: 0.006\n",
      "[14,    50] loss: 0.003\n",
      "[14,    60] loss: 0.002\n",
      "[14,    70] loss: 0.004\n",
      "[14,    80] loss: 0.004\n",
      "[14,    90] loss: 0.005\n",
      "[14,   100] loss: 0.003\n",
      "[14,   110] loss: 0.004\n",
      "[14,   120] loss: 0.004\n",
      "[14,   130] loss: 0.004\n",
      "[14,   140] loss: 0.003\n",
      "[14,   150] loss: 0.002\n",
      "[14,   160] loss: 0.003\n",
      "[14,   170] loss: 0.003\n",
      "[14,   180] loss: 0.004\n",
      "[14,   190] loss: 0.002\n",
      "[14,   200] loss: 0.002\n",
      "[14,   210] loss: 0.002\n",
      "[14,   220] loss: 0.002\n",
      "[14,   230] loss: 0.004\n",
      "[14,   240] loss: 0.003\n",
      "[14,   250] loss: 0.004\n",
      "[14,   260] loss: 0.003\n",
      "[14,   270] loss: 0.002\n",
      "[14,   280] loss: 0.003\n",
      "[14,   290] loss: 0.006\n",
      "[14,   300] loss: 0.004\n",
      "[14,   310] loss: 0.002\n",
      "[14,   320] loss: 0.002\n",
      "[14,   330] loss: 0.004\n",
      "[14,   340] loss: 0.003\n",
      "[14,   350] loss: 0.005\n",
      "[14,   360] loss: 0.002\n",
      "[14,   370] loss: 0.003\n",
      "[14,   380] loss: 0.001\n",
      "[14,   390] loss: 0.003\n",
      "[14,   400] loss: 0.005\n",
      "[14,   410] loss: 0.003\n",
      "[14,   420] loss: 0.003\n",
      "[14,   430] loss: 0.003\n",
      "[14,   440] loss: 0.004\n",
      "[14,   450] loss: 0.001\n",
      "[14,   460] loss: 0.003\n",
      "[14,   470] loss: 0.003\n",
      "[14,   480] loss: 0.004\n",
      "[14,   490] loss: 0.002\n",
      "[14,   500] loss: 0.004\n",
      "14\n",
      "[15,    10] loss: 0.003\n",
      "[15,    20] loss: 0.004\n",
      "[15,    30] loss: 0.002\n",
      "[15,    40] loss: 0.005\n",
      "[15,    50] loss: 0.005\n",
      "[15,    60] loss: 0.003\n",
      "[15,    70] loss: 0.003\n",
      "[15,    80] loss: 0.002\n",
      "[15,    90] loss: 0.005\n",
      "[15,   100] loss: 0.004\n",
      "[15,   110] loss: 0.002\n",
      "[15,   120] loss: 0.004\n",
      "[15,   130] loss: 0.004\n",
      "[15,   140] loss: 0.003\n",
      "[15,   150] loss: 0.002\n",
      "[15,   160] loss: 0.003\n",
      "[15,   170] loss: 0.002\n",
      "[15,   180] loss: 0.004\n",
      "[15,   190] loss: 0.002\n",
      "[15,   200] loss: 0.002\n",
      "[15,   210] loss: 0.004\n",
      "[15,   220] loss: 0.002\n",
      "[15,   230] loss: 0.003\n",
      "[15,   240] loss: 0.003\n",
      "[15,   250] loss: 0.003\n",
      "[15,   260] loss: 0.004\n",
      "[15,   270] loss: 0.001\n",
      "[15,   280] loss: 0.003\n",
      "[15,   290] loss: 0.007\n",
      "[15,   300] loss: 0.004\n",
      "[15,   310] loss: 0.001\n",
      "[15,   320] loss: 0.002\n",
      "[15,   330] loss: 0.003\n",
      "[15,   340] loss: 0.003\n",
      "[15,   350] loss: 0.003\n",
      "[15,   360] loss: 0.004\n",
      "[15,   370] loss: 0.002\n",
      "[15,   380] loss: 0.002\n",
      "[15,   390] loss: 0.003\n",
      "[15,   400] loss: 0.006\n",
      "[15,   410] loss: 0.002\n",
      "[15,   420] loss: 0.001\n",
      "[15,   430] loss: 0.003\n",
      "[15,   440] loss: 0.003\n",
      "[15,   450] loss: 0.001\n",
      "[15,   460] loss: 0.002\n",
      "[15,   470] loss: 0.003\n",
      "[15,   480] loss: 0.003\n",
      "[15,   490] loss: 0.002\n",
      "[15,   500] loss: 0.003\n",
      "('Finished Training .. saved model ', '../data/models/sprs15-opflw.pkl')\n",
      "------------------------------------------------------------\n",
      "time taken to TRAIN for DenseOpticalFlow  in seconds 8415.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shayan_ray/anaconda2/lib/python2.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type NvidiaNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "### Training starts\n",
    "train_start_time = time.time()\n",
    "net.train()\n",
    "trn_losses = list()\n",
    "for epoch in range(num_trn_epochs):  # loop over the dataset multiple times\n",
    "    print epoch\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        labels=labels.view(-1,1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        trn_losses.append(loss.item())\n",
    "        if (i+1) % 10 == 0:    # print every 2000 steps\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "\n",
    "#save the model\n",
    "torch.save(net, model_save_path)\n",
    "print('Finished Training .. saved model ',model_save_path)\n",
    "\n",
    "train_end_time = time.time() - train_start_time\n",
    "print('------------------------------------------------------------')\n",
    "print(\"time taken to TRAIN for DenseOpticalFlow  in seconds {:.3f}\".format(train_end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NvidiaNet(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv2): Conv2d(24, 36, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv3): Conv2d(36, 48, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (conv3_drop): Dropout2d(p=0.5)\n",
       "  (conv4): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=1280, out_features=1164, bias=True)\n",
       "  (fc2): Linear(in_features=1164, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (fc4): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (fc5): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "net_val = torch.load(model_save_path)\n",
    "net_val.eval()\n",
    "#net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y = batch_shuffle(train_df)\n",
    "#print \"train_pairs\"\n",
    "#print train_num * batch_size\n",
    "#print \"\"\n",
    "#print \"validation_pairs\"\n",
    "#print len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss  tensor(111.3891, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(129.8057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,     2] loss: 0.065\n",
      "val_loss  tensor(96.6448, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(102.5843, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,     4] loss: 0.051\n",
      "val_loss  tensor(97.5590, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(104.2528, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,     6] loss: 0.052\n",
      "val_loss  tensor(79.9783, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(106.7059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,     8] loss: 0.053\n",
      "val_loss  tensor(89.9372, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(60.9066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    10] loss: 0.030\n",
      "val_loss  tensor(106.0434, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(124.5763, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    12] loss: 0.062\n",
      "val_loss  tensor(104.9583, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(129.9561, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    14] loss: 0.065\n",
      "val_loss  tensor(145.2963, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(70.9926, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    16] loss: 0.035\n",
      "val_loss  tensor(106.3474, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(158.3049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    18] loss: 0.079\n",
      "val_loss  tensor(85.9241, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(98.2553, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    20] loss: 0.049\n",
      "val_loss  tensor(89.2283, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(84.0244, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    22] loss: 0.042\n",
      "val_loss  tensor(89.2528, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(123.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    24] loss: 0.062\n",
      "val_loss  tensor(117.5313, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(90.7532, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    26] loss: 0.045\n",
      "val_loss  tensor(93.9965, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(110.4863, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    28] loss: 0.055\n",
      "val_loss  tensor(57.8108, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(76.0540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    30] loss: 0.038\n",
      "val_loss  tensor(100.0553, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(109.2745, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    32] loss: 0.055\n",
      "val_loss  tensor(95.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(73.5465, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    34] loss: 0.037\n",
      "val_loss  tensor(87.0813, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(60.0661, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    36] loss: 0.030\n",
      "val_loss  tensor(102.3516, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(86.3737, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    38] loss: 0.043\n",
      "val_loss  tensor(103.8381, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(142.8900, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    40] loss: 0.071\n",
      "val_loss  tensor(71.6972, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(96.1485, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    42] loss: 0.048\n",
      "val_loss  tensor(108.4555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(101.1777, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    44] loss: 0.051\n",
      "val_loss  tensor(85.6437, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(139.4880, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    46] loss: 0.070\n",
      "val_loss  tensor(94.7187, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(110.1605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    48] loss: 0.055\n",
      "val_loss  tensor(96.8257, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(118.7608, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    50] loss: 0.059\n",
      "val_loss  tensor(84.9939, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(92.6331, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    52] loss: 0.046\n",
      "val_loss  tensor(93.7950, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(95.8866, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    54] loss: 0.048\n",
      "val_loss  tensor(116.7245, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(83.8744, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    56] loss: 0.042\n",
      "val_loss  tensor(89.2950, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(111.3885, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    58] loss: 0.056\n",
      "val_loss  tensor(102.4237, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(101.4233, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    60] loss: 0.051\n",
      "val_loss  tensor(126.0462, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(63.5444, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    62] loss: 0.032\n",
      "val_loss  tensor(68.0125, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(70.8984, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    64] loss: 0.035\n",
      "val_loss  tensor(93.7910, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(76.7214, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    66] loss: 0.038\n",
      "val_loss  tensor(90.7539, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(100.4147, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    68] loss: 0.050\n",
      "val_loss  tensor(150.9446, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(96.6071, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    70] loss: 0.048\n",
      "val_loss  tensor(78.9855, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(90.9009, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    72] loss: 0.045\n",
      "val_loss  tensor(79.0297, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(55.0789, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    74] loss: 0.028\n",
      "val_loss  tensor(115.9300, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(88.3162, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    76] loss: 0.044\n",
      "val_loss  tensor(73.4805, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(76.4746, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    78] loss: 0.038\n",
      "val_loss  tensor(116.5664, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(98.2700, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    80] loss: 0.049\n",
      "val_loss  tensor(84.4157, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(95.8099, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    82] loss: 0.048\n",
      "val_loss  tensor(98.8905, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(106.0770, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    84] loss: 0.053\n",
      "val_loss  tensor(103.3130, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(93.5391, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    86] loss: 0.047\n",
      "val_loss  tensor(74.2866, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(88.9730, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    88] loss: 0.044\n",
      "val_loss  tensor(92.4216, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(120.8571, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    90] loss: 0.060\n",
      "val_loss  tensor(94.0152, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(66.0810, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    92] loss: 0.033\n",
      "val_loss  tensor(73.5551, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(93.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    94] loss: 0.047\n",
      "val_loss  tensor(77.5447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(98.9800, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    96] loss: 0.049\n",
      "val_loss  tensor(116.7066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(122.8548, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,    98] loss: 0.061\n",
      "val_loss  tensor(111.1664, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(160.1637, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   100] loss: 0.080\n",
      "val_loss  tensor(98.3796, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(70.9328, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   102] loss: 0.035\n",
      "val_loss  tensor(134.8186, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(85.8117, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   104] loss: 0.043\n",
      "val_loss  tensor(81.7088, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(48.5577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   106] loss: 0.024\n",
      "val_loss  tensor(112.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(123.7365, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   108] loss: 0.062\n",
      "val_loss  tensor(61.6117, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(101.3543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   110] loss: 0.051\n",
      "val_loss  tensor(116.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(96.7962, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   112] loss: 0.048\n",
      "val_loss  tensor(125.7644, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(72.3548, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   114] loss: 0.036\n",
      "val_loss  tensor(111.9665, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(109.8406, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   116] loss: 0.055\n",
      "val_loss  tensor(83.1797, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(107.3415, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   118] loss: 0.054\n",
      "val_loss  tensor(100.7773, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(86.4483, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   120] loss: 0.043\n",
      "val_loss  tensor(56.8050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(98.7407, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   122] loss: 0.049\n",
      "val_loss  tensor(100.1824, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(101.6961, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   124] loss: 0.051\n",
      "val_loss  tensor(120.0785, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "val_loss  tensor(69.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "[15,   126] loss: 0.035\n",
      "val_loss  tensor(97.6054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Validation done\n",
      "------------------------------------------------------------\n",
      "time taken to VALIDATE for DenseOpticalFlow  in seconds 37.548\n"
     ]
    }
   ],
   "source": [
    "### Validation starts\n",
    "val_start_time = time.time()\n",
    "running_val_loss = 0.0\n",
    "val_losses = list()\n",
    "for i, dataval in enumerate(validatnloader, 0):\n",
    "    #print dataval\n",
    "    inputs, labels = dataval\n",
    "    #print i\n",
    "    #print \"inputs >> \", inputs\n",
    "    outputs = net_val(inputs)\n",
    "    labels=labels.view(-1,1)\n",
    "    #print \"outputs \", outputs\n",
    "    #print \"labels \", labels\n",
    "    val_loss = criterion(outputs, labels)\n",
    "    print \"val_loss \", val_loss\n",
    "    running_val_loss += val_loss.item()\n",
    "    val_losses.append(val_loss.item())\n",
    "    if (i+1) % 2 == 0:    # print every 10 steps\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "          (epoch + 1, i + 1, running_val_loss / 2000))\n",
    "    running_val_loss = 0.0\n",
    "          \n",
    "print('Validation done')\n",
    "val_end_time = time.time() - val_start_time\n",
    "print('------------------------------------------------------------')\n",
    "print(\"time taken to VALIDATE for DenseOpticalFlow  in seconds {:.3f}\".format(val_end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print \"training loss \"\n",
    "# print np.mean(trn_losses)\n",
    "# print \"----------------------------------------------------------------------\"\n",
    "\n",
    "# #print \"validation loss\"\n",
    "# #print np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYFNX1//H3kV0FkUVE0ICKCxhAHBfcYjQuEKPRmIiJipCE/OIS1yRoEjV+NSGJUbO5C2qiuOFCjOJCNAomwIDsiIyIcQgIArLKMnB+f9xqumef6ema7p7+vJ6nnqq6fbvqzPRyuqruvWXujoiISDp2yXYAIiKSv5REREQkbUoiIiKSNiURERFJm5KIiIikTUlERETSpiQiIiJpUxIREZG0KYmIiEjammc7gIbo1KmT9+jRI9thiIjklenTp3/q7p0zsa28TiI9evSguLg422GIiOQVM/soU9vS6SwREUmbkoiIiKRNSURERNIW2zURM2sNvAW0ivbzjLvfZGYPA18C1kZVL3H3mWZmwB+AwcCmqHxGXPGJSGZt27aN0tJSNm/enO1QJNK6dWu6d+9OixYtYttHnBfWtwAnu/sGM2sBTDKzl6PHfuzuz1SoPwjoFU1HA/dEcxHJA6WlpbRt25YePXoQfhNKNrk7q1atorS0lJ49e8a2n9hOZ3mwIVptEU013QHrbODR6Hn/AdqbWde44hORzNq8eTMdO3ZUAskRZkbHjh1jPzKM9ZqImTUzs5nACuA1d58SPXSbmc02szvNrFVU1g34OOXppVFZxW2OMLNiMyteuXJlnOGLSD0pgeSWxng9Yk0i7r7d3fsD3YGjzOww4HrgEOBIoAPw03pu8353L3L3os6d0+wrs3UrjBkDujWwiEiDNErrLHf/DHgDOMPdl0WnrLYAY4CjompLgX1TntY9Ksu8l1+G4cNh2rRYNi8ijW/VqlX079+f/v37s/fee9OtW7ed61u3bq3TNoYNG8bChQtrrPOXv/yFxx57LBMhc/zxxzNz5syMbCtb4myd1RnY5u6fmVkb4FTgN2bW1d2XRa2xvg7MjZ4yHrjczJ4gXFBf6+7LYgmuWbMw30UtnEWaio4dO+78Qr755pvZfffdue6668rVcXfcnV2q+eyPGTOm1v1cdtllDQ+2CYnzW7Qr8IaZzQamEa6JvAg8ZmZzgDlAJ+DWqP5LwGKgBHgAuDS2yFatCvN162LbhYjkhpKSEnr37s13vvMd+vTpw7JlyxgxYgRFRUX06dOHW265ZWfdxJFBWVkZ7du3Z+TIkfTr14+BAweyYsUKAH7+859z11137aw/cuRIjjrqKA4++GDeeecdADZu3Mg3vvENevfuzXnnnUdRUVGdjzg+//xzhg4dyhe/+EUGDBjAW2+9BcCcOXM48sgj6d+/P3379mXx4sWsX7+eQYMG0a9fPw477DCeeaZio9f4xXYk4u6zgcOrKD+5mvoONE6KnxJd33/vPTi5ynBEpKFOOqly2ZlnQuLooL6Pv/lm2qG89957PProoxQVFQEwatQoOnToQFlZGV/+8pc577zz6N27d7nnrF27li996UuMGjWKa665htGjRzNy5MhK23Z3pk6dyvjx47nllluYMGECf/rTn9h7770ZN24cs2bNYsCAAXWO9Y9//COtWrVizpw5zJs3j8GDB7No0SLuvvturrvuOs4//3y2bNmCu/PCCy/Qo0cPXn755Z0xNzadzxGRJu+AAw7YmUAAxo4dy4ABAxgwYAALFixg/vz5lZ7Tpk0bBg0aBMARRxzBkiVLqtz2ueeeW6nOpEmTGDJkCAD9+vWjT58+dY510qRJXHjhhQD06dOHffbZh5KSEo499lhuvfVWfvvb3/Lxxx/TunVr+vbty4QJExg5ciSTJ09mjz32qPN+MiWvR/FNW6dOYT5mDFwa31kzkYJW25FDQx+vh912223n8qJFi/jDH/7A1KlTad++PRdeeGGVfSlatmy5c7lZs2aUlZVVue1WrVrVWicTLrroIgYOHMg//vEPzjjjDEaPHs2JJ55IcXExL730EiNHjmTQoEHccMMNscVQlcI8Ehk4MMw1jLxIwVm3bh1t27alXbt2LFu2jFdeeSXj+zjuuON46qmngHAto6ojneqccMIJO1t/LViwgGXLlnHggQeyePFiDjzwQK688krOPPNMZs+ezdKlS9l999256KKLuPbaa5kxo/FHiirMIxERKVgDBgygd+/eHHLIIXzhC1/guOOOy/g+rrjiCi6++GJ69+69c6ruVNPpp5++c2yrE044gdGjR/ODH/yAL37xi7Ro0YJHH32Uli1b8vjjjzN27FhatGjBPvvsw80338w777zDyJEj2WWXXWjZsiX33ntvxv+W2pjncYe7oqIiT+umVH/7G1x0UVjO479fJJcsWLCAQw89NNth5ISysjLKyspo3bo1ixYt4rTTTmPRokU0b974v9urel3MbLq7F1XzlHopzCORdu2yHYGINGEbNmzglFNOoaysDHfnvvvuy0oCaQxN86+qTaKfiIhIDNq3b8/06dOzHUajKMwL67qgLhKLfD493hQ1xutRmElERDKudevWrFq1SokkRyTuJ9K6detY91OYp7MS/UTq0YtURGrWvXt3SktL0S0ackfizoZxKswkkmjSl4U21SJNVYsWLWK9g57kJp3OEhGRtBVmEolG4xQRkYYpzCTStm22IxARaRIKM4msXp3tCEREmoTCTCIF0glIRCRuhZlEREQkIwoziXTuHOb9+mU3DhGRPFeYSeT448N81qzsxiEikudiSyJm1trMpprZLDObZ2a/jMp7mtkUMysxsyfNrGVU3ipaL4ke7xFXbCIikhlxHolsAU52935Af+AMMzsG+A1wp7sfCKwBvhvV/y6wJiq/M6oXj2XLYtu0iEghiS2JeLAhWm0RTQ6cDDwTlT8CfD1aPjtaJ3r8FDOzWIJLud+yiIikL9ZrImbWzMxmAiuA14APgM/cPXE3+1KgW7TcDfgYIHp8LdAxlsDWrIllsyIihSbWJOLu2929P9AdOAo4pKHbNLMRZlZsZsVpjxY6c2ZDwxARERqpdZa7fwa8AQwE2ptZYvTg7sDSaHkpsC9A9PgeQKVbELr7/e5e5O5FnRNNdUVEJCvibJ3V2czaR8ttgFOBBYRkcl5UbSjwQrQ8PlonevyfHtfdbRLJ57DDYtm8iEihiPN+Il2BR8ysGSFZPeXuL5rZfOAJM7sVeBd4KKr/EPBXMysBVgNDYovshBPCfO7c2HYhIlIIYksi7j4bOLyK8sWE6yMVyzcD34wrHhERybzC7LH+0UfZjkBEpEkozCTSpk22IxARaRIKM4mon4iISEYUZhK5445sRyAi0iQUZhIpK6u9joiI1Kowk0jfvtmOQESkSSjMJHL++dmOQESkSSjMJKLWWSIiGVGYSUQDMIqIZERhJpFVlcZ1FBGRNBRmElm3LtsRiIg0CYWZRKZNy3YEIiJNQmEmkZjuuisiUmgKM4n06pXtCEREmoTCTCLf1IjzIiKZUJhJpF27bEcgItIkFGYSObzSvbJERCQNhZlENm7MdgQiIk1CYSaRtWuzHYGISJNQmElkwYJsRyAi0iTElkTMbF8ze8PM5pvZPDO7Miq/2cyWmtnMaBqc8pzrzazEzBaa2elxxSYiIpnRPMZtlwHXuvsMM2sLTDez16LH7nT321Mrm1lvYAjQB9gHeN3MDnL37THGKCIiDRDbkYi7L3P3GdHyemAB0K2Gp5wNPOHuW9z9Q6AEOCqW4Dp0CPNjj41l8yIihaJRromYWQ/gcGBKVHS5mc02s9FmtmdU1g34OOVppdScdNLXuXOYa0h4EZEGiT2JmNnuwDjgKndfB9wDHAD0B5YBv6/n9kaYWbGZFa9cuTK9oHr2DPNNm9J7voiIADEnETNrQUggj7n7swDu/om7b3f3HcADJE9ZLQX2TXl696isHHe/392L3L2oc+KIor7WrEnveSIiUk6crbMMeAhY4O53pJR3Tal2DjA3Wh4PDDGzVmbWE+gFTI0lON1PREQkI+JsnXUccBEwx8wSFx9uAC4ws/6AA0uAHwC4+zwzewqYT2jZdVlsLbPUT0REJCNiSyLuPgmo6sYdL9XwnNuA2+KKSUREMqswe6zrplQiIhlRmEmkY8cwVz8REZEGKcwkstdeYf7uu9mNQ0QkzxVmEvnCF8L888+zG4eISJ4rzCTy6afJ5TlzsheHiEieK8wkktpPJDWhiIhIvRRmElm0KLl88snZi0NEJM8VZhIREZGMUBI58MBsRyAikrcKM4l06pRc7ts3e3GIiOS5wkwiiX4iAN/8ZvbiEBHJc4WZRPZNGXF+3rzsxSEikucKM4msWJFcfvbZ7MUhIpLnCjOJrF+fXF68OHtxiIjkucJMIh98kFzevDl7cYiI5LnCTCIiIpIRSiL77ZftCERE8lZhJpHOnZPLAwZkLw4RkTxXmEmkS5fk8gUXZC8OEZE8V5hJpFu35PKMGdmLQ0Qkz8WWRMxsXzN7w8zmm9k8M7syKu9gZq+Z2aJovmdUbmb2RzMrMbPZZhbfeably5PLTz4Z225ERJq6OI9EyoBr3b03cAxwmZn1BkYCE929FzAxWgcYBPSKphHAPbFFtmFDcnnJkth2IyLS1MWWRNx9mbvPiJbXAwuAbsDZwCNRtUeAr0fLZwOPevAfoL2ZdY0luA8/jGWzIiKFplGuiZhZD+BwYArQxd2XRQ8tBxJXubsBH6c8rTQqq7itEWZWbGbFK1euTC+gffZJ73kiIlJO7EnEzHYHxgFXufu61Mfc3QGvz/bc/X53L3L3os6pTXXr40tfSg0wvW2IiEi8ScTMWhASyGPunhjp8JPEaaponhgNcSmQMrwu3aOyeJ10Uuy7EBFpquJsnWXAQ8ACd78j5aHxwNBoeSjwQkr5xVErrWOAtSmnveJzySWx70JEpKmK80jkOOAi4GQzmxlNg4FRwKlmtgj4SrQO8BKwGCgBHgAujTG2pH/9q1F2IyLSFFm4LJGfioqKvLi4OL0nJ66FtGwJW7ZkLigRkRxnZtPdvSgT26rTkYiZHWBmraLlk8zsR2bWPhMBZN3WrdmOQEQkb9X1dNY4YLuZHQjcT7gA/nhsUYmISF6oaxLZ4e5lwDnAn9z9x0A8HQFFRCRv1DWJbDOzCwitqV6MylrEE5KIiOSLuiaRYcBA4DZ3/9DMegJ/jS+sRqCmvSIiDda8LpXcfT7wI4Bo1N227v6bOAOL3cMPZzsCEZG8V9fWWW+aWTsz6wDMAB4wsztqe56IiDRtdT2dtUc07tW5hJF2jyZ0FBQRkQJW1yTSPBrn6lskL6yLiEiBq2sSuQV4BfjA3aeZ2f7AovjCEhGRfFDXC+tPA0+nrC8GvhFXUCIikh/qemG9u5k9Z2YrommcmXWPOzgREcltdT2dNYYwVPs+0fT3qCx/qZ+IiEiD1TWJdHb3Me5eFk0PA2neVjBH7LdftiMQEcl7dU0iq8zsQjNrFk0XAqviDCx206dnOwIRkbxX1yQynNC8dzmwDDgPuCSmmBrHiSdmOwIRkbxXpyTi7h+5+1nu3tnd93L3r5PvrbMSN6USEZG0NeT2uNdkLIpseFF9JkVEGqohSSS/f8pffnm2IxARyXsNSSI13pzdzEZHfUrmppTdbGZLzWxmNA1Oeex6Mysxs4VmdnoD4qqbs86KfRciIk1djT3WzWw9VScLA9rUsu2HgT8Dj1Yov9Pdb6+wn97AEKAPoR/K62Z2kLtvr2Uf6WvVKrZNi4gUihqTiLu3TXfD7v6WmfWoY/WzgSfcfQvwoZmVAEcB/053/7XauDG2TYuIFIqGnM5K1+VmNjs63bVnVNYN+DilTmlUFp81a2LdvIhIIWjsJHIPcADQn9Df5Pf13YCZjTCzYjMrXrlyZfqRlJWl/1wREQEaOYm4+yfuvt3ddwAPEE5ZASwF9k2p2j0qq2ob97t7kbsXde7cgJFXtsd3uUVEpFA0ahKJbmyVcA6QaLk1HhhiZq3MrCfQC5gaazBeY+MyERGpgzrdTyQdZjYWOAnoZGalwE3ASWbWn9DiawnwAwB3n2dmTwHzgTLgslhbZoWdxrp5EZFCEFsScfcLqih+qIb6twG3xRVPJQ05FSYiIkB2WmflhpYtk8s6KhERSUvhJpHUxHHvvdmLQ0QkjxVuElm7Nrn8/vvZi0NEJI8VbhJJ7bF+6KHZi0NEJI8VbhLZti25rFvlioikpXCTSOo1kWOPzV4cIiJ5TEkEYMqU7MUhIpLHCjeJdOyYXJ45M3txiIjkscJNIqn3EyktzV4cIiJ5rHCTSOvW2Y5ARCTvFW4SSe0noh7rIiJpKdwkknpTqkMOyV4cIiJ5rHCTyObNyWUNxigikpbCTSIHHJBcHjAge3GIiOSxwk0ie+yRXH7nnezFISKSxwo3iaR6661sRyAikpeURAA+/DDbEYiI5CUlEYBPPsl2BCIieUlJBGDHjmxHICKSl5REAIqKsh2BiEheii2JmNloM1thZnNTyjqY2Wtmtiia7xmVm5n90cxKzGy2mTVum9sPPmjU3YmINBVxHok8DJxRoWwkMNHdewETo3WAQUCvaBoB3BNjXJVNntyouxMRaSpiSyLu/hawukLx2cAj0fIjwNdTyh/14D9AezPrGldsIiKSGY19TaSLuy+LlpcDXaLlbsDHKfVKozIREclhWbuw7u4O1Hv4XDMbYWbFZla8cuXKzAVUVpa5bYmIFIjGTiKfJE5TRfMVUflSYN+Uet2jskrc/X53L3L3os6ZHDjxs88yty0RkQLR2ElkPDA0Wh4KvJBSfnHUSusYYG3Kaa/49O6dXG7RIvbdiYg0NXE28R0L/Bs42MxKzey7wCjgVDNbBHwlWgd4CVgMlAAPAJfGFVc5/funBpzeNg47DG67LTPxiIjkGfM8vqtfUVGRFxcXp7+BE0+Et98Oy6tWwaZNMHw4jBwJJ59ct20kkk8e/x9FpLCY2XR3z0gv68Lusb4s5YzZbrvB9Onw2mvwu9+Vr/e//4Vk8fjjjRufiEiOK+wkUvHoYfv2MJ8wIVm2YQM88EBYnjOnceISEckThZ1EDj00ubxuXfmk8vrrsHgxHHkk3HxzKBs1imoNHw7nnQczZsQSqohILmqe7QCy6ogj4MUXw/Jee5V/7NRT4aab4L336ratMWPCfNw4XR8RkYJR2EcibdvW/Pjtt8Pll9dc5/nnYfTo5Hrfvg2PK9Udd8C0aZndpohIhhT2kcjFF8N111X/+MaN4WJ7RffeC127hhZcZ59dvnlw4rpKplx7LXToEFqPiYjkmMJOInvsUXudf/+7/Prtt8OPf1x9/XnzGhZTRbvuCsOGZXabIiIZUtins9K5o2FNCSShY8fQByVT0u0IKSISs8JOInFZvTrZibGhNm0KRz8iIjmosJNInL/wBw+Ge+6BWbMqP7ZwYZi3bg0XXhhfDCIiMSvsJBKnzz+HSy+FRx+FRx4JF8bHjAn3cz/kkJBktmyBxx4Lp9Weew7efLP8NhLNi2trISYikiWFfWE9ziORN94I87FjQzPdil5+Obn8q1/BL34Rlv/+dzjzzLB88cVhXlULMRGRHFDYRyItW8a/j2V1GNE+kUAAHn44uZzox1KxhZiISI4o7CSSi8aNgzVrwvK3v53dWEREaqEkkotKSsK8Z88w/+53sxeLiEgNlERy0ZQpYb5hQ5g/9FDmrt8MHw5f/GJmtiUiBU9JJBc98AD8619w1VU119uyJbQC+/TTMP/+9ysnmwULyneqHDMG5s4Ny889F+rrwr2IpElJZM89sx1BZbNnw0knwYcfVl/n4YdDP5Ndd4XOncMYYA8+WL5OcXG4j3yiddgrr5R//IXoFve6T4qIpElJ5Lnnsh1B3SWGmN+ypfJ4WnffnVz+9NPQTPihh8J6ixbw0kvwwx82PIa1a8NRj4gIWeonYmZLgPXAdqDM3YvMrAPwJNADWAJ8y93XxB7MW2/FvouMSL1Hyfe+V3Pdzp3Lr1d1WuzDD9O770n79uFmXvPn1/+5ItLkZPNI5Mvu3j/lZvEjgYnu3guYGK3H7+OPG2U3DWYWerm3awd/+1vDt7f//slrJWZhrK+nnw6nv2bPrvm5CxbUvv1t22o+HSciTUIunc46G3gkWn4E+Hqj7HXffRtlNxnx8suwfn3mtvfEE2Herl0Ydfhb3woJ4pe/rP45e+0F556bXC8thcsug7Ky8vWuuSYkqhUrMheviOScbCURB141s+lmNiIq6+Luie7dy4EujRLJ9dcXxv06zj0XWrUqX5b44q/LsPXPPw9/+lNICs8+C3feGa69fO974XrMP/8ZtnfNNeH+9InrJlu3ZvbvEJGckq0kcry7DwAGAZeZWblvMXd3QqKpxMxGmFmxmRWvXLmy4ZE0bx5+STd1zz4bLshXpWPHynU7dQrLP/5xON11zjnwox8l61xzDQwdCscfH9YffTQkkTvvDM2IE31RUi/418fbb4eL+CKS07KSRNx9aTRfATwHHAV8YmZdAaJ5ledB3P1+dy9y96LOFS8gp2vz5sxsJ19NmZIcKfiEE8I8cTvemu5lsnZtsmPkY48l76Hy7LPJ5z/9dP1Paa1fH46OUk+biUhOavQkYma7mVnbxDJwGjAXGA8MjaoNBV5otKDSucNhU/L++8kjilS19ZKfPBlefDG5ftppYb55c0geEIZw+cY36nfb4MQpsNou8ItI1mXjSKQLMMnMZgFTgX+4+wRgFHCqmS0CvhKtN46NG8P86xWu5ffpE+7x8de/Nu2+EVOnwpAhYTlTd2RMvc40aRIcdljV9aZMCae8nn8+7HvNGjj44PDYDTck67mHzpTr1oWkX1pa91iuuw5uvrnef4KI1K7R+4m4+2KgXxXlq4BTGjseINlj+4ADwq/o1q3D+rx58KUvheXqriesWlX5mkK++fOfM7/Nis2Q9947zH/xC/jvf8ONutauhWOOKV/vk0+Sp8KaNUuWT5kShnWZODE0Q77xRvjgg9ACrDa//32YK5GIZFwuNfHNnsR1gNNPDy2Y3ENz13HjknWaN4f+/Ss/t0OHxokx31QcSqV9+2T57Nnhf50oS9UlpVGee7hYX1YW7jUPoVlyIilUbFYMYdBKs2Tz5boqKQl9W0SkXpREIPwa3roVTj01Wfbkk+Uv7DZrBl/4Qlg+77ww79Gj0ULMe++9B7/5Tbi//MyZ8OqrtT9n1Sro1w+6dw9JPCHRaitRds89yRt3ffRRmA8bBkcdFU5DHnkkHHdc9fv53/+gV6/Q4kxE6kVJJKFFi9rrLFwY5sOGJRMKhGsmUruRI5P3ja+LOXPCqcUePWDgQDj//PKPr10bpksvhWOPhVmzkneG3LwZpk0LRyS33Rau+VS8uF9UFPq5rF4d1hO3NH7uuXDtJW6DB4d4V60KTaTzZfQEkVTunrfTEUcc4Y3q8cfdwX39evdf/ML9xBOTj/397+533ul+5ZWhTmL64Q/Lr2tKb5o2rXLZr3/tftJJNT/v9dfdf/e7sHzkke47drhv2RJes0Sd+fOTy8XFYX7DDcnX9i9/cT/88Pq9V773Pfef/rTmOhX/tnHj6rcPkTQBxZ6h7+GMbCRbU6MnkbrYscP9D38I/9q+fd23b3ffvDn5hTF8ePa/kJvSdNxxda977LHut94altesSZYvXux+wQVhuXXrMP/Tn5KvaaLet77lPnWq+8qV7jfe6H7mme5lZaHOiy+GhFXxOVV58EH3ffZJ1nnooTC/5JL43pciKZREPIeTiLt7aan7Cy+EI5aElSvDF15pqfunn7p/9JH73ntn/0u4UKeSkpDkE+uLFvnORAPuRx0VfhC4ux9zTPXbWbo01DniCPfBg5Ovd+LxVasqvz9+8Yvk4wMHJpMIhPdFbVavdp8ypeY6//2v+2ef1b4tKUiZTCK6JhKHbt3grLNg992TZZ06hf4S3bqFJsH77QfLl2cvxkLXrFmylReEay6QvEnZ1Kmwyy5wxRXwn/9Uv50nnoA2bcLdIV96CX7+czjwwOTjHTuGPjATJiTLtm8P+9+2LbwnUl15ZdX7mTUr9JOZOhW+8hU4+uia/7799guNEkTilqlslI0pZ49E6irx6/Nf/0ouDx/uftVV5X/tvvde9n+5a0p/KipyP+WU5OtuFsoffdR91qzyRyK33hrqlJWVP5K46aZknQ4dwjxxfWfixFDn2mtD+W9/G+YHHFD+/fb++8mjq7h17Vr+upLkFHQk0kQMHhxaCB10UGhdBHD11ZV7Y6ce0Uj+KS4OnSQTN/JyD/OLLw5HC2++mazbrl14Pxx/fOhHk+gLsybl/myJpug7dsCAAXDKKTBjRvJ985OfhP42H3wQbh8AYYiagw6C++5LbmfHjtAybOzY0Lfmj3/M3N+8bBn86lc119EAm02Ckkg27dgRTpnsvXfy7oNm8MwzyToDB4b7qCd87WuNG6NkzoMPwle/Wrk8tYn4j34EixYlT6GtXFn5Cz4xptmkSclmy6tXh75NCZ98EuaDB4f5okVhnuhPA7BkSTjNOnx4+Tr1tX175YTQrl3No2OPHRuS5IwZ6e1TcoaSSDZNmBDOcUNyzKr//jc51Mquu8I774Tz9BMnhrLUG0YlBio87rjyiUdy0513husm9bHPPpXLEr3xU4fiSe0oW5WWLcO8RYvQuXLixOQXf3WjWL/zThiR4e23Q6KYOjV8+Vd01VUhIaSOL7fLLmGqzhVXhHlNiWv9+rpfN1yxItzfpuLz03XffaEz6/bt6W+jUGTqvFg2pry/JnL33aEPg3tovXXtte7btrlv2uT+ne+477pr7duYPt193bqwfNBBdT9P/+67yWatmpr29OqroR/Tt7/tPnly9fUuuyy0/AL3b3wjXLOpql5Fiffd6tXuf/6z+/PPh/UOHcLjq1cnr+9MmOA+d25yW8XF1b+399+/6v0tW+a+dWtoVr12bShLbG/8+LD+9tth/R//qP0zVNE//pH8bGzdWv/nV7RlS2gtN25csjVfQ9x+e4ht48a0N4Ga+DaRJFKTrl2r/gDVpFev8h/0u+4Ky+ecU/5L4MGh/487AAAONElEQVQHw+Pr11f9RZLtLz1N8UzXXFO/+kcdVblsv/3Kv+fKyty//OWqn3/OOaFOYj2RoFKnadOqfz936RLqLFgQktD//he+OMH9K18J87POKr8PCJ08//rXsHzffeFL96mn6vYZWru2/La2bUs+9stfur/xRlhevDg046+Lin/zmjV1e151En2MSkvT3oSSiBdAEnn+efehQ+v3nERv+aOPDutlZeEIp6TEvVWr8KH+8Y/L/7pKvLGffz60Eqvqg56Ydtml+seuuMJ9wIDK5e3b1++LS1PuT3/7W3K5X7+q63TrFloazpoV1vv2DX1iqqq7bFlooXbwweE9u25dsr9Oxemzz8L84ovD/Mor3X/2s8r1Xn89zFNbPm7fnhy9YPbsqj9DL79cfjsbNyYTSaLMveofeb/5Tfispdq2rXJsiSQydar7c8/V7zPunkwiH39c/+dGlES8AJJIOu68s/ybtC5SPxjuoQlo167u99/vfuqpycfnzy/f877i5O6+fHnl8tqGJdHUdKddd61bvQMOSDZ7hmSCaMj097+H+cSJVT8+eXLyPf/mm8kjjMTRT+rUurX7nDlhuUuX8Dm48EL3du2S21i1Klk/tWn2vfdW3l6zZuE0dGLdPcTTvn1IeglHHhk6sVb0+9+HmDZsqPvnvNLHXkkEdyWRSmbMCInk88/r/pwnn0ye3qrKI4+49+iR7HmdOE1wySXhnDS4N2+erJ/4YCT6tpx/frJs8eLKH6inn676Q544H65JUzrTLbeEeXVj1514YjjNlfqePe202rd7ww3up5+eXL/jjrCNf/+7fL3TTgtHVHWJ1T3ZV6h//5BETz65/OOpTjgh1G8AJRFXEskZv/ud+7x5yfUVK5K/kKZNC6cDTj45/Mpyd7/ttvC2O/bY8GvKPZmYUqfLL3cfMSL+LxtNTX+q6sdLYrrxxuzHt3Ch+w9+UPVju+5avrPx97+fXE40qEmDkogrieSVZs2it5onB0A8+uhwnjzhhhvChcqSkvK9qj/4IJw66NDBfa+9QuufxJhj++0XptQP3bx5yVMPFafUXt+aCmdKHeyyKU2TJqX9kVQScSWRvPLPf4ZTX+7hwunmzQ0bfiPRxPHXvw4tdxIfqtTTcqWlobHA66+7X311uKh6883JuoltgHufPjV/WG+/3f3QQ8Py1Vcny8eMCeess/1loqkwp2HD0v4IKYm4kkhB27w5tPqprxdeCE1DE156KTRPnTQp+cHs2LH8B7V//9DCJnGh9sEHw/zii5PbWb48XOys64f/vvuS58u/+tUwP+aYcCow3S+U6prZamq6U5s2aX+EmnQSAc4AFgIlwMia6iqJSEasWOE+aFA4WlqzJiSOsWPDx+OJJyrXf/XVyp3QduwILWs++sj9tdeSH/T77w/z1KMg92TTz//7v/Lb2bgx9O8544xwJJXoNAfunTqFQRQrfplcc03Yf2L9pz8NrZ02bar+CyhxZKUpf6cbb0z7Ld9kkwjQDPgA2B9oCcwCeldXX0lEctZ3v+s+alT5smHDwhGLezi91q1baFRQm3PPDUkuYcOGkOzmznV/7LFk+fLloUNeqrPOCh/zv/0tJJcuXULT1ClTQvnkye4zZ5b/cpo4MZyCHDSofPmoUaF+6pHbu+9W/nKraiSEYcMqd3qF0E+iIV+kFWNs2bLxv8yzNX3ta+m9N92bdBIZCLySsn49cH119ZVERGpx113uQ4ak99xNm0J/hq1b3R9+OCS+qjz5pPtFF5V//I03whAnqXbsCNeX3n8/XE9K+M9/whHY2LGhX8XDD4cEO25cSJQ7diR7krdoUbkf1NFHu48enVxPfMm++WZIcpMnl2/VlJgmTQqtACEMCXPTTeEa22uvhd7pe+wRRnBIXAdLNBBJTHffXfcv/E6dMp9EEtcZ05DJJGJhe7nBzM4DznD370XrFwFHu/vlVdUvKiry4uLixgxRRLJlyZIwxH2bNjXXW748fM127Vq+fONGGD8+jIT90UfQp0/DY0oM8ti2bRiu/8kn4cILy9++ITFa95YtYQTm0lL47LMwjH+qTZtgw4YQ/5QpcNhhYRTvLVtC7C1bhuVWrRp8ewgzm+7uRQ3aSGJb+ZZEzGwEMAJgv/32O+Kjjz7KSqwiIvkqk0kk14aCXwrsm7LePSrbyd3vd/cidy/q3LlzowYnIiLl5VoSmQb0MrOeZtYSGAKMz3JMIiJSjebZDiCVu5eZ2eXAK4SWWqPdfV6WwxIRkWrkVBIBcPeXgHre/k1ERLIh105niYhIHlESERGRtCmJiIhI2pREREQkbTnV2bC+zGwlkG5vw07ApxkMJ9MUX8MovoZRfOnL5dggxLebu2eko11eJ5GGMLPiTPXYjIPiaxjF1zCKL325HBtkPj6dzhIRkbQpiYiISNoKOYncn+0AaqH4GkbxNYziS18uxwYZjq9gr4mIiEjDFfKRiIiINFBBJhEzO8PMFppZiZmNbMT9jjazFWY2N6Wsg5m9ZmaLovmeUbmZ2R+jGGeb2YCU5wyN6i8ys6EZim1fM3vDzOab2TwzuzLH4mttZlPNbFYU3y+j8p5mNiWK48lo9GfMrFW0XhI93iNlW9dH5QvN7PRMxJey7WZm9q6ZvZhr8ZnZEjObY2Yzzaw4KsuJ1zfabnsze8bM3jOzBWY2MFfiM7ODo/9bYlpnZlflUHxXR5+LuWY2Nvq8NM57L1O3SMyXiXrexz3D+z4RGADMTSn7LTAyWh4J/CZaHgy8DBhwDDAlKu8ALI7me0bLe2Ygtq7AgGi5LfA+0DuH4jNg92i5BTAl2u9TwJCo/F7gh9HypcC90fIQ4MlouXf0mrcCekbvhWYZfI2vAR4HXozWcyY+YAnQqUJZTry+0bYfAb4XLbcE2udSfClxNgOWA1/IhfiAbsCHQJuU99wljfXey9g/Nl8m6nkf9xj234PySWQh0DVa7gosjJbvAy6oWA+4ALgvpbxcvQzG+QJwai7GB+wKzACOJnTqal7xtSXcTmBgtNw8qmcVX+/UehmIqzswETgZeDHaXy7Ft4TKSSQnXl9gD8IXoeVifBViOg2YnCvxEZLIx4TE1Dx6753eWO+9QjydlfiHJ5RGZdnSxd2XRcvLgS7RcnVxxh5/dHh7OOHXfs7EF50qmgmsAF4j/FL6zN3LqtjXzjiix9cCHeOMD7gL+AmwI1rvmGPxOfCqmU23cJtpyJ3XtyewEhgTnQ580Mx2y6H4Ug0BxkbLWY/P3ZcCtwP/BZYR3kvTaaT3XiEmkZzlIf1ntbmcme0OjAOucvd1qY9lOz533+7u/Qm/+I8CDslWLBWZ2ZnACnefnu1YanC8uw8ABgGXmdmJqQ9m+fVtTjjVe4+7Hw5sJJwe2inb7z+A6LrCWcDTFR/LVnzRdZizCYl4H2A34IzG2n8hJpFa7+PeyD4xs64A0XxFVF5dnLHFb2YtCAnkMXd/NtfiS3D3z4A3CIfo7c0scXO11H3tjCN6fA9gVYzxHQecZWZLgCcIp7T+kEPxJX6x4u4rgOcIiThXXt9SoNTdp0TrzxCSSq7ElzAImOHun0TruRDfV4AP3X2lu28DniW8HxvlvVeISSTX7uM+Hki00BhKuBaRKL84auVxDLA2Omx+BTjNzPaMfoGcFpU1iJkZ8BCwwN3vyMH4OptZ+2i5DeF6zQJCMjmvmvgScZ8H/DP6pTgeGBK1UOkJ9AKmNjQ+d7/e3bu7ew/Ce+qf7v6dXInPzHYzs7aJZcLrMpcceX3dfTnwsZkdHBWdAszPlfhSXEDyVFYijmzH91/gGDPbNfocJ/53jfPey+QFp3yZCC0n3iecU/9ZI+53LOGc5TbCL6/vEs5FTgQWAa8DHaK6BvwlinEOUJSyneFASTQNy1BsxxMOxWcDM6NpcA7F1xd4N4pvLnBjVL5/9EYvIZxiaBWVt47WS6LH90/Z1s+iuBcCg2J4nU8i2TorJ+KL4pgVTfMS7/tceX2j7fYHiqPX+HlC66Vcim83wi/2PVLKciI+4JfAe9Fn46+EFlaN8t5Tj3UREUlbIZ7OEhGRDFESERGRtCmJiIhI2pREREQkbUoiIiKSNiURKWhmtiGa9zCzb2d42zdUWH8nk9sXyQVKIiJBD6BeSSSlN3B1yiURdz+2njGJ5DwlEZFgFHCChXtFXB0N9vg7M5sW3Q/iBwBmdpKZvW1m4wm9gjGz56NBDeclBjY0s1FAm2h7j0VliaMei7Y918L9Pc5P2fablrynxmNRD2TMbJSFe73MNrPbG/2/I1KN2n5JiRSKkcB17n4mQJQM1rr7kWbWCphsZq9GdQcAh7n7h9H6cHdfHQ3HMs3Mxrn7SDO73MOAkRWdS+id3Q/oFD3nreixw4E+wP+AycBxZrYAOAc4xN09MfyLSC7QkYhI1U4jjH00kzAkfkfCWEIAU1MSCMCPzGwW8B/CAHa9qNnxwFgPoxJ/AvwLODJl26XuvoMw9EwPwlDdm4GHzOxcYFOD/zqRDFESEamaAVe4e/9o6unuiSORjTsrmZ1EGEV1oLv3I4zv1boB+92SsrydcFOhMsKIu88AZwITGrB9kYxSEhEJ1hNuC5zwCvDDaHh8zOygaPTbivYA1rj7JjM7hHAr1IRtiedX8DZwfnTdpTPhtsnVjpZq4R4ve7j7S8DVhNNgIjlB10REgtnA9ui01MOEe4H0AGZEF7dXAl+v4nkTgP8XXbdYSDillXA/MNvMZngYFj7hOcK9UGYRRk7+ibsvj5JQVdoCL5hZa8IR0jXp/YkimadRfEVEJG06nSUiImlTEhERkbQpiYiISNqUREREJG1KIiIikjYlERERSZuSiIiIpE1JRERE0vb/AQLoCxxlE+1nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33f27e0890>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33f26e7e10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss\n",
      "97.2916427759\n"
     ]
    }
   ],
   "source": [
    "# Get training and validation loss histories\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(trn_losses) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, trn_losses, 'r--')\n",
    "\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n",
    "\n",
    "epoch_count = range(1, len(val_losses) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, val_losses, 'b-')\n",
    "\n",
    "plt.legend(['Validation Loss'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n",
    "\n",
    "\n",
    "print \"validation loss\"\n",
    "print np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "# run validation accuracy\n",
    "# train validation graph\n",
    "# sparse optical flow\n",
    "# images code made to run without commenting \n",
    "# last image regenerated to account for the pairs and last batch success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss\n",
      "23.2692640597\n"
     ]
    }
   ],
   "source": [
    "print \"training loss\"\n",
    "print np.mean(trn_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading 269 minibatches(=32) of validation samples.\n"
     ]
    }
   ],
   "source": [
    "#### TESTING STARTS ###############\n",
    "\n",
    "net_val.eval()\n",
    "def generate_test_data(data,batch_size):\n",
    "    channels=3\n",
    "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    batch_data = []\n",
    "    batch_labels = []\n",
    "\n",
    "    for j in range(len(data)//batch_size):\n",
    "        for i in range(batch_size):\n",
    "            if (i+j*batch_size)+1 == len(data):\n",
    "                break\n",
    "            row1=data.iloc[[i+j*batch_size]]\n",
    "            row2=data.iloc[[(i+j*batch_size)+1]]\n",
    "            \n",
    "            img1 = preprocessing(row1['image_path'].values[0])\n",
    "            img2 = preprocessing(row2['image_path'].values[0])\n",
    "\n",
    "            speed1 = row1['speed'].values[0]\n",
    "            speed2 = row2['speed'].values[0]\n",
    "\n",
    "            resimg = computeOpticalFlow(img1,img2)\n",
    "            resimg = resimg.reshape(1, resimg.shape[0], resimg.shape[1], resimg.shape[2])\n",
    "            \n",
    "            speed = np.mean([speed1, speed2])\n",
    "            speed = np.array([[speed]])\n",
    "            \n",
    "            image_batch[i] = resimg\n",
    "            label_batch[i] = speed\n",
    "        \n",
    "        img_batch=image_batch\n",
    "        img_batch = np.reshape(img_batch, (batch_size, channels, 66, 220))\n",
    "        \n",
    "        batch_data.append(torch.from_numpy(img_batch))\n",
    "        batch_labels.append(torch.DoubleTensor(label_batch))\n",
    "        \n",
    "    return zip(batch_data, batch_labels)\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "testloader=list(generate_test_data(test_df,batch_size))\n",
    "test_num = len(testloader)\n",
    "print(\"Finish loading %d minibatches(=%d) of validation samples.\" % (test_num, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing done\n",
      "------------------------------------------------------------\n",
      "time taken to TEST for DenseOpticalFlow  in seconds 79.182\n",
      "Test MSE :::::: \n",
      "128.53721655\n"
     ]
    }
   ],
   "source": [
    "### Testing\n",
    "test_start_time = time.time()\n",
    "\n",
    "\n",
    "test_start_time = time.time()\n",
    "test_losses = []\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i, datatest in enumerate(testloader, 0):\n",
    "    inputs, labels = datatest\n",
    "    \n",
    "    outputs = net_val(inputs)\n",
    "    labels=labels.view(-1,1)\n",
    "    \n",
    "    test_loss = criterion(outputs, labels)\n",
    "\n",
    "    test_losses.append(test_loss.item())\n",
    "          \n",
    "         \n",
    "print('Testing done')\n",
    "test_end_time = time.time() - test_start_time\n",
    "print('------------------------------------------------------------')\n",
    "print(\"time taken to TEST for DenseOpticalFlow  in seconds {:.3f}\".format(test_end_time))\n",
    "print('Test MSE :::::: ')\n",
    "print np.mean(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.53721655\n"
     ]
    }
   ],
   "source": [
    "print np.mean(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
